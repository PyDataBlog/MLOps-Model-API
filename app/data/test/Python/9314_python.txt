#%% Libraries: Built-In
import numpy as np
#% Libraries: Custom

#%%
class Combiner(object):
    def forward(self, input_array, weights, const):
        ## Define in child
        pass
    
    def backprop(self, error_array, backprop_array, learn_weight = 1e-0):
        ## Define in child
        pass
#%%
class Linear(Combiner):
    def forward(self, input_array, weights, const):
        cross_vals = input_array * weights
        summed_vals = cross_vals.sum(axis = 1, keepdims = True)
        combined_array = summed_vals + const
        return combined_array
    
    def backprop(self, input_array, error_array, backprop_array, weights, prior_coefs, learn_weight):
        #print(input_array.shape, error_array.shape, backprop_array.shape, weights.shape)
        
        gradient_weights, gradient_const = self.gradient(
            input_array,
            error_array,
            backprop_array
        )
        learning_weights, learning_const = self.learning_rate(
            input_array,
            error_array,
            backprop_array,
            weights.shape[1] + weights.shape[2],
            prior_coefs
        )
        
        step_weights = gradient_weights * learning_weights * learn_weight
        step_const = gradient_const * learning_const * learn_weight
        
        new_backprop = self.update_backprop(backprop_array, weights)
        
        return ((step_weights, step_const), new_backprop)
        
    def gradient(self, input_array, error_array, backprop_array):
        error_prop = -(error_array * backprop_array).sum(axis = 2, keepdims = True).swapaxes(1, 2)
        gradient_weights = (input_array * error_prop).mean(axis = 0, keepdims = True)
        gradient_const = error_prop.mean(axis = 0, keepdims = True)
        return (gradient_weights, gradient_const)
    
    def learning_rate(self, input_array, error_array, backprop_array, current_coefs, prior_coefs):
        hessian_items = self.hessian(input_array, backprop_array)
        step_items = self.step_size(hessian_items, current_coefs, prior_coefs)
        return step_items
    
    def hessian(self, input_array, backprop_array):
        square_input = input_array ** 2
        square_backprop = backprop_array.sum(axis = 2, keepdims = True).swapaxes(1, 2) ** 2
        hessian_weights = (square_input * square_backprop).mean(axis = 0, keepdims = True)
        hessian_weights[hessian_weights == 0] = 1
        hessian_const = square_backprop.mean(axis = 0, keepdims = True)
        hessian_const[hessian_const == 0] = 1
        return (hessian_weights, hessian_const)
    
    def step_size(self, hessian_items, current_coefs, prior_coefs):
        step_size = tuple([(1 / hessian) / (current_coefs + prior_coefs) for hessian in hessian_items])
        return step_size
    
    def update_backprop(self, backprop_array, weights):
        new_backprop = weights.dot(backprop_array).squeeze(axis = 3).swapaxes(0, 2)
        return new_backprop
#%%
