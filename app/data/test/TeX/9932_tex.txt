\documentclass[11pt]{article}
\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=2.5cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{array}
\usepackage{xfrac}
\usepackage{lmodern}

\usepackage{chngcntr}
\counterwithin*{equation}{section}

\usepackage[pdftex,
            pdfauthor={Franco Frizzo},
            pdftitle={Probabilidades y Estadística (C)},
            pdfsubject={Resumen de Probabilidades y Estadística (C)},
            pdfkeywords={},
            pdfproducer={},
            pdfcreator={},
            hidelinks]{hyperref}

\theoremstyle{plain}
\newtheorem*{teo}{Teorema}
\newtheorem*{pro}{Proposición}
\newtheorem*{corol}{Corolario}
\newtheorem*{lema}{Lema}
\newtheorem*{lgn}{Ley de los Grandes Números}

\theoremstyle{definition}
\newtheorem*{defi}{Definición}
\newtheorem*{prop}{Propiedad}
\newtheorem*{props}{Propiedades}

\theoremstyle{remark}
\newtheorem*{obs}{Observación}

\newcommand{\deft}[1]{\textbf{#1}}  % Palabra clave en una definición

\newcommand{\proba}{\ensuremath{\operatorname{P}}}  % Probabilidad
\newcommand{\esp}[0]{\ensuremath{\operatorname{E}}}  % Esperanza
\newcommand{\var}[0]{\ensuremath{\operatorname{V}}}  % Varianza
\newcommand{\cov}[0]{\ensuremath{\operatorname{Cov}}}  % Covarianza

\newcommand{\espm}[0]{\ensuremath{\mathcal{S}}}  % Espacio muestral
\newcommand{\indi}[1]{\ensuremath{\mathbbm{1}_{#1}}}  % Función indicatriz
\newcommand{\foralle}{\ensuremath{\forall \ }}  % Para todo + espacio

\newcommand{\dists}[1]{\ensuremath{\operatorname{#1}}}  % Distribución
\newcommand{\dist}[1]{\ensuremath{\sim \operatorname{#1}}}  % Tiene distribución...
\newcommand{\distt}[2]{\ensuremath{\overset{#1}{\sim} \operatorname{#2}}}  % Tiene distribución, con texto sobre el ~
\newcommand{\tiende}[1]{\ensuremath{\xrightarrow{\;\; #1 \;\;}}}  % Flecha con texto arriba

\newcommand{\poisson}[0]{\ensuremath{\mathcal{P}}}  % Distribución de Poisson
\newcommand{\unif}[0]{\ensuremath{\mathcal{U}}}  % Distribución uniforme
\newcommand{\exponen}[0]{\ensuremath{\mathcal{E}}}  % Distribución exponencial

\setlength{\tabcolsep}{25pt}
\renewcommand{\arraystretch}{2}

\begin{document}
\title{Probabilidades y Estadística (C)}
\author{Franco Frizzo \\ \small (Basado en el apunte de Ana M. Bianco y Elena J. Martínez)}
\date{}
\maketitle
\tableofcontents
\newpage

\section{Conceptos básicos de probabilidad}

  \begin{defi}
    Dado un experimento aleatorio (cualquier proceso o acción que genera observaciones y que puede ser repetible), su \deft{espacio muestral} asociado es el conjunto de todos sus resultados posibles. Lo notaremos $\espm$.
  \end{defi}

  \begin{defi}
    Se denomina \deft{suceso} o \deft{evento} a cualquier subconjunto del espacio muestral. Si $\espm$ es finito o infinito numerable, cualquier subconjunto es un evento. Si $\espm$ es infinito, “casi todo” subconjunto de $\espm$ es un evento.

    Un evento es \emph{elemental} o \emph{simple} si consiste de un único resultado individual y \emph{compuesto} si consiste de más de un evento elemental.
  \end{defi}

  \begin{defi}
    Dado un experimento aleatorio y un espacio muestral asociado $\espm$, a cada evento $A$ se le asociará un número que notaremos $\proba(A)$ y que llamaremos \deft{probabilidad} del evento $A$. Esta asignación debe satisfacer los siguientes axiomas:
    \begin{enumerate}
      \item[A1.] $\proba(A) \geq 0$ para todo evento $A$.
      \item[A2.] $\proba(\espm) = 1$.
      \item[A3.] \begin{enumerate}
        \item Si $A_1, A_2, \dots, A_n$ es una colección finita de sucesos mutuamente excluyentes, es decir que $A_i \cap A_j = \varnothing \ \foralle i \neq j$, entonces:
        \[ \proba\left( \bigcup_{i=1}^n A_i \right) = \sum_{i=1}^n \proba(A_i) \]
        \item Si $A_1, A_2, \dots$ es una colección infinita numerable de sucesos mutuamente excluyentes, es decir que $A_i \cap A_j = \varnothing \ \foralle i \neq j$, entonces:
        \[ \proba\left( \bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty \proba(A_i) \]
      \end{enumerate}
    \end{enumerate}
  \end{defi}

  \begin{props} \
    \begin{enumerate}
      \item $\proba(A^C) = 1 - \proba(A)$, para cualquier evento $A$.

      \item $\proba(\varnothing) = 0$.

      \item Si $A \subseteq B \Rightarrow \proba(A) \leq \proba(B)$ y $\proba(B - A) = \proba(B) - \proba(A)$.

      \item Dados dos sucesos cualesquiera $A$ y $B$, $\proba(A \cup B) = \proba(A) + \proba(B) - \proba(A \cap B)$.

      \item Dados dos sucesos cualesquiera $A$ y $B$, $\proba(A \cup B) \leq \proba(A) + \proba(B)$.
    \end{enumerate}
  \end{props}

  \begin{proof} \
    \begin{enumerate}
      \item $1 \underset{\text{A2}}{=} \proba(\espm) = \proba(A \cup A^C) \underset{\text{A3\textit{a}}}{=} \proba(A) + \proba(A^C) \Rightarrow \proba(A^C) = 1 - \proba(A)$.

      \item $\proba(\varnothing) = 1 - \proba(\varnothing^C) = 1 - \proba(\espm) = 1 - 1 = 0$.

      \item Si $A \subseteq B \Rightarrow B = A \cup (B - A)$ y estos dos eventos son excluyentes. Por el axioma A3\textit{a}, $\proba(B) = \proba(A) + \proba(B - A)$. Dado que, por el axioma A1, $\proba(B - A) \geq 0$, resulta $\proba(B) \geq \proba(A)$, y despejando, se obtiene la segunda afirmación.

      \item $A \cup B = A \cup (B - A) = A \cup (B \cap A^C)$, y estos dos eventos son excluyentes. Entonces, por el axioma A3\textit{a},
        \begin{equation} \label{a1} \proba(A \cup B) = \proba(A \cup (B \cap A^C)) = \proba(A) + \proba(B \cap A^C) \end{equation}
        Por otra parte, $B = (B \cap A) \cup (B \cap A^C)$, y estos dos eventos son disjuntos, entonces
        \begin{equation} \label{a2} \proba(B) = \proba(B \cap A) + \proba(B \cap A^C) \Rightarrow \proba(B \cap A^C) = \proba(B) - \proba(B \cap A) \end{equation}
        De \eqref{a1} y \eqref{a2} resulta que $\proba(A \cup B) = \proba(A) + \proba (B) - \proba(A \cap B)$, como queríamos demostrar.

      \item Se deduce inmediatamente de la propiedad anterior y del axioma A1. \qedhere
    \end{enumerate}
  \end{proof}

  \begin{defi}
    Sea un experimento aleatorio cuyo espacio muestral asociado $\espm$ es finito y sea $n = \# \espm$, el cardinal del conjunto. Diremos que el espacio es de \deft{equiprobabilidad} si los $n$ sucesos elementales tienen igual probabilidad, es decir si
    \[ \proba(E_i) = p \ \foralle i \]
  \end{defi}

  Como $1 = \proba(\espm) = \sum_{i=1}^n \proba(E_i) = \sum_{i=1}^n p = np \Rightarrow p = \frac{1}{n} = \frac{1}{\#\espm}$.

  Dado cualquier suceso $A$, $\proba(A) = \sum_{E \in A} \proba(E) = \sum_{E \in A} \frac{1}{n} = \frac{\#A}{\#\espm}$.

  \subsection{Probabilidad condicional}
    \begin{defi}
      Sean $A$ y $B$ eventos tales que $\proba(B) > 0$. La probabilidad del evento $A$ \deft{condicional} a la ocurrencia del evento $B$ es
      \[ \proba(A \mid B) = \frac{\proba(A \cap B)}{\proba(B)} \]
    \end{defi}

    \begin{props} \
      \begin{enumerate}
        \item $\proba(A \mid B) \geq 0$ para todo suceso $A$.
        \item $\proba(\espm \mid B) = 1$.
        \begin{proof}
          $\proba(\espm \mid B) = \frac{\proba(B \cap \espm)}{\proba(B)} = \frac{\proba(B)}{\proba(B)} = 1$
        \end{proof}
        \item Regla del producto: $\proba(A \cap B) = \proba(A \mid B) \proba(B)$. Si además $\proba(A) \neq 0$, entonces $\proba(A \cap B) = \proba(B \mid A) \proba(A)$.
      \end{enumerate}
    \end{props}

    \begin{defi}
      Una colección de eventos $A_1, A_2, \dots, A_k$ constituye una \deft{partición} del espacio muestral $\espm$ si
      \begin{enumerate}
        \item $A_i \cap A_j = \varnothing \ \foralle i \neq j$.
        \item $\proba(A_i) \geq 0 \ \foralle i$.
        \item $\bigcup_{i=1}^k A_i = \espm$.
      \end{enumerate}
    \end{defi}

    \begin{teo}[Probabilidad Total]
      Sea $A_1, A_2, \dots, A_k$ una partición del espacio muestral $\espm$ y sea $B$ un suceso cualquiera, entonces
      \[ \proba(B) = \sum_{i=1}^k \proba(B \mid A_i) \proba(A_i) \]
    \end{teo}

    \begin{proof}
      \[ B = B \cap \espm = B \cap \left( \bigcup_{i=1}^k A_i \right) = \bigcup_{i=1}^k (B \cap A_i) \]

      Como $(B \cap A_i) \cap (B \cap A_j) = \varnothing \ \foralle i \neq j$, entonces:
      \[ \proba(B) = \proba \left( \bigcup_{i=1}^k (B \cap A_i) \right) = \sum_{i=1}^k \proba(B \cap A_i) = \sum_{i=1}^k \proba(B \mid A_i) \proba(A_i)\]
    \end{proof}

    \begin{teo}[Bayes]
      Sea $A_1, A_2, \dots, A_k$ una partición del espacio muestral $\espm$ y sea $B$ un suceso cualquiera tal que $\proba(B) > 0$, entonces
      \[ \proba(A_j \mid B) = \frac{\proba(B \mid A_j) \proba(A_j)}{\sum_{i=1}^k \proba(B \mid A_i) \proba(A_i)} \]
    \end{teo}

    \begin{proof}
      \[ \proba(A_j \mid B) = \frac{\proba(A_j \cap B)}{\proba(B)} = \frac{\proba(B \mid A_j) \proba(A_j)}{\sum_{i=1}^k \proba(B \mid A_i) \proba(A_i)} \]

      En el numerador se aplicó la regla del producto, y en el denominador el Teorema de la Probabilidad Total.
    \end{proof}

  \subsection{Independencia de eventos}
    \begin{defi}
      Los eventos $A$ y $B$ son \deft{independientes} si $\proba(A \cap B) = \proba(A) \proba(B)$. Si la igualdad no se cumple, decimos que los eventos son \deft{dependientes}.
    \end{defi}

    \begin{pro}
      Supongamos $\proba(B) > 0$, $A$ y $B$ son independientes si y sólo si $\proba(A \mid B) = \proba(A)$.
    \end{pro}
    \begin{proof} \
      \begin{itemize}
        \item[$(\Rightarrow)$] Si $\proba(B) > 0 \Rightarrow \proba(A \mid B) = \frac{\proba(A \cap B)}{\proba(B)}$ está bien definida. Por ser $A$ y $B$ independientes, $\proba(A \cap B) = \proba(A) \proba(B)$, entonces
        \[ \proba(A \mid B) = \frac{\proba(A) \proba(B)}{\proba(B)} = \proba(A) \]
        \item[$(\Leftarrow)$] Aplicando la regla del producto, si $\proba(B) > 0$, $\proba(A \cap B) = \proba(A \mid B) \proba(B) = \proba(A) \proba (B)$.
      \end{itemize}
    \end{proof}

    \begin{obs}
      Si $\proba(B) = 0$, como $A \cap B \subseteq B$, $\proba(A \cap B) = 0$, y por lo tanto la igualdad $\proba(A \cap B) = \proba(A) \proba(B)$ siempre se satisface.
    \end{obs}

    \begin{props} \
      \begin{enumerate}
        \item Si los sucesos $A$ y $B$ son excluyentes, es decir si $A \cap B = \varnothing$ y si $\proba(A) > 0$, $\proba(B) > 0$, entonces $A$ y $B$ no son independientes.
        \begin{proof}
          $0 = \proba(A \cap B) \neq \proba(A) \proba(B)$.
        \end{proof}

        \item Si $\proba(B) = 0$, entonces $B$ es independiente de cualquier suceso $A$ tal que $\proba(A) > 0$.
        \begin{proof}
          Como $A \cap B \subseteq B$, $\proba(A \cap B) = 0$, y por lo tanto $\proba(A \cap B) = \proba(A) \proba(B)$, es decir, $A$ y $B$ son independientes.
        \end{proof}

        \item Si $A \subseteq B$ , $\proba(A) > 0$ y $\proba(B) < 1$, $A$ y $B$ no son independientes.
        \begin{proof}
          Como $A \subseteq B \Rightarrow A \cap B = A \Rightarrow \proba(A \cap B) = \proba(A) \neq \proba(A) \proba(B)$. Luego, $A$ y $B$ no son independientes.
        \end{proof}

        \item Si $A$ y $B$ son sucesos independientes, $A$ y $B^C$ también lo son.
        \begin{proof}
          $\proba(A) = \proba(A \cap B) + \proba(A \cap B^C) \Rightarrow \proba(A \cap B^C) = \proba(A) - \proba(A \cap B) = \proba(A) - \proba(A) \proba(B) = \proba(A) (1 - \proba(B)) = \proba(A) \proba(B^C)$.
        \end{proof}
      \end{enumerate}
    \end{props}

    \begin{defi}
      Los eventos $A_1, A_2, \dots, A_n$ son independientes si para todo $k = 2, \dots, n$ y para todo conjunto de índices $\lbrace i_1, i_2, \dots, i_k \rbrace$ tales que $1 \leq i_1 < i_2 < \dots < i_k \leq n$, se verifica
      \[ \proba(\bigcap_{j=1}^k A_{i_j}) = \prod_{j=1}^k \proba(A_{i_j}) \]

      Es decir, es necesario verificar $\sum_{i=2}^n \binom{n}{i} = 2^n - n - 1$ condiciones.
    \end{defi}

    \begin{obs}
      Si los sucesos $A_1, A_2, \dots, A_n$ son independientes entonces son independientes de a pares, pero la recíproca no es cierta.
    \end{obs}

\section{Variables aleatorias}
  \begin{defi}
    Sea $\espm$ un espacio muestral asociado con un experimento aleatorio. Una variable aleatoria $X$ es una función que asocia a cada elemento $w \in \espm$ un número real $X(w) = x$, es decir
    \[ X : \espm \to \mathbb{R} \]
  \end{defi}

    Como se observa, en general representaremos a las v.a. con letras mayúsculas ($X$, $Y$, $Z$, etc.), y a sus valores con letras minúsculas, es decir, $X(w) = x$ significa que $x$ es el número real asociado al resultado $w \in \espm$ a través de $X$.

    Indicaremos con $R_X$ el rango de la v.a. $X$, es decir, el conjunto de sus valores posibles.

  \subsection{Variables aleatorias discretas}

    \begin{defi}
      Una variable aleatoria es \deft{discreta} si toma un número finito o infinito numerable de valores.
    \end{defi}

    \begin{defi}
      La \deft{función de probabilidad puntual} o de \deft{masa} de una v.a. discreta $X$ se define para todo $x \in \mathbb{R}$ como
      \[ p_X(x) = \proba(X = x) = \proba(\lbrace w \in \espm / X(w) = x \rbrace) \]
    \end{defi}

    \begin{props} \
      \begin{enumerate}
        \item $p_x(x) \geq 0 \ \foralle x $.
        \item $\sum_{x \in R_X} p_x(x) = 1 $.
      \end{enumerate}
    \end{props}

    \begin{defi}
      La \deft{función de distribución acumulada} de una v.a. discreta $X$, con función de probabilidad puntual $p_X(x)$, se define para todo $x \in \mathbb{R}$ como
      \[ F_X(x) = \proba(X \leq x) = \sum_{y \leq x,\, y \in R_X} p_X(y) \]
    \end{defi}

    \begin{props} \
      \begin{enumerate}
        \item $\foralle x \in \mathbb{R}, F_X(x) \in [0,1]$.
        \begin{proof}
          $F_X(X) = \proba(X \leq x)$, es decir, $F_X(x)$ es una probabilidad, y toda probabilidad toma valores entre 0 y 1.
        \end{proof}

        \item $F_X(x)$ es monótona no decreciente, es decir, si $x_1 < x_2 \Rightarrow F_X(x_1) \leq F_X(x_2)$.
        \begin{proof}
          Consideremos el suceso
          \[ A = \lbrace w / X(w) \leq x_2 \rbrace = \lbrace w / X(w) \leq x_1 \rbrace \cup \lbrace w / x_1 < X(w) \leq x_2 \rbrace = A_1 \cup A_2 \]
          Como $A_1 \cap A_2 = \varnothing$, $\proba(A) = \proba(A_1) + \proba(A_2)$, es decir
          \[ \proba(X \leq x_2) = \proba(X \leq x_1) + \proba(x_1 < X \leq x_2) \geq \proba(X \leq x_1) \]
          y, por lo tanto,
          \[ F_X(x_2) \geq F_X(x_1) \]
        \end{proof}

        \item $F_X(x)$ es continua a derecha, es decir, $\lim_{h \to 0^+} F_X(x + h) = F_X(x)$.

        \item $\lim_{x \to +\infty} F_X(x) = 1$ y $\lim_{x \to -\infty} F_X(x) = 0$.
        \begin{proof} \
          \begin{itemize}
            \item $\lim_{x \to +\infty} F_X(x) = \lim_{x \to +\infty} \proba(X \leq x) = \lim_{x \to +\infty} \proba(w / X(w) \leq x) = \proba(\espm) = 1$.
            \item $\lim_{x \to -\infty} F_X(x) = \lim_{x \to -\infty} \proba(X \leq x) = \lim_{x \to -\infty} \proba(w / X(w) \leq x) = \proba(\varnothing) = 0$.
          \end{itemize}
        \end{proof}

        \item En cada punto $x$, el valor del salto es la probabilidad puntual, es decir
        \[ p_X(x) = F_X(x) - F_X(x^-) \]
        donde $x^- = \lim_{h \to 0^+} (x - h)$.
        \begin{proof}
          $p_X(x) = \proba(X = x) = \proba(X \leq x) - \proba(X < x) = F_X(x) - F_X(x^-)$.
        \end{proof}

      \end{enumerate}
    \end{props}

    \begin{pro}
      Sean $a$ y $b$ tales que $a \leq b$. Entonces
      \begin{enumerate}
        \item $\proba(a < X \leq b) = F_X(b) - F_X(a)$
        \item $\proba(a \leq X \leq b) = F_X(b) - F_X(a^-)$
        \item $\proba(a < X < b) = F_X(b^-) - F_X(a)$
        \item $\proba(a \leq X < b) = F_X(b^-) - F_X(a^-)$
      \end{enumerate}
    \end{pro}

    \subsubsection{Esperanza de una v.a. discreta}

      \begin{defi}
        Sea $X$ una v.a. discreta que toma valores en $R_X$, con función de probabilidad puntual $p_X(x)$. La \deft{esperanza} o \deft{valor esperado} de $X$ se define como
        \[ \esp(X) = \mu_X = \sum_{x \in R_X} x \, p_X(x) \]
        siempre que $\sum_{x \in R_X} |x| \, p_X(x) < \infty $. Si la serie de los valores absolutos diverge, la esperanza no puede definirse y decimos que no existe.
      \end{defi}

      \begin{pro}
        Si $X$ es discreta y toma valores $x_1, x_2, \dots$, entonces $h(X)$ es discreta con valores $y_1, y_2, \dots$, siendo $y_j = h(x_i)$ para al menos un valor de $i$.
      \end{pro}

      \begin{pro}
        Si la v.a. $X$ tiene función de probabilidad puntual $p_X(x)$ para todo $x \in R_X$, entonces la esperanza de cualquier función real $h(X)$ está dada por
        \[ \esp(h(X)) = \sum_{x \in R_X} h(x) \, p_X(x) \]
        si la serie es absolutamente convergente, es decir, si $\sum_{x \in R_X} |h(x)| \, p_X(x) < \infty $.
      \end{pro}
      \begin{proof}
        Sea $Y = h(x)$. Entonces
        \[ \esp(Y) = \sum_j y_j p_Y(y_j) = \sum_j y_j \left[ \sum_{i \mid h(x_i) = y_j} p_X(x_i) \right] = \sum_j \sum_{i \mid h(x_i) = y_j} y_j p_X(x_i) = \sum_i h(x_i) p_X(x_i) \]
      \end{proof}

      \begin{props} \
        \begin{enumerate}
          \item (\emph{Linealidad}) Si $a$ y $b$ son constantes reales, $\esp(aX + b) = a\esp(X) + b$.
          \begin{proof}
            Sea $h(X) = aX + b$. Entonces,
            \[ \esp(h(X)) = \esp(aX + b) = \sum_{x \in R_X} (ax + b) p_X(x) = a \sum_{x \in R_X} x p_X(x) + b \sum_{x \in R_X} p_X(x) = a \esp(X) + b \]
          \end{proof}

          \item Si $X$ es una v.a. tal que $\proba(X = c) = 1$, entonces $\esp(X) = c$.
          \begin{proof}
            $\esp(X) = c p_X(c) = c$.
          \end{proof}
        \end{enumerate}
      \end{props}

    \subsubsection{Varianza de una v.a. discreta}

      \begin{defi}
        Sea X una v.a. discreta con función de probabilidad puntual $p_X(x)$. La \deft{varianza} de $X$, que se denotará $\var(X)$, $\sigma_X^2$ o $\sigma^2$, es
        \[ \var(X) = \sigma_X^2 = \sum_{x \in R_X} (x - \esp(X))^2 \, p_X(x) = \esp\left[ (X - \esp(X))^2 \right] \]
        y el \deft{desvío estándar} de $X$ es
        \[ \sigma_X = \sqrt{\var(X)} \]
      \end{defi}

      \begin{pro}
        \[ \var(X) = \esp(X^2) - (\esp(X))^2 \]
      \end{pro}
      \begin{proof}
        \[ \begin{split}
        \var(X) &= \esp\left[ (X - \esp(X))^2 \right] = \sum_{x \in R_X} (x - \esp(X))^2 p_X(x) = \sum_{x \in R_X} (x^2 - 2 \esp(X) x + (\esp(X))^2) p_X(x) = \\
        &= \sum_{x \in R_X} x^2 p_X(x) - 2 \esp(X) \sum_{x \in R_X} x p_X(x) + (\esp(X))^2 \sum_{x \in R_X} p_X(x) = \\
        &= \esp(X^2) - 2 \esp(X) \esp(X) + (\esp(X))^2 = \esp(X^2) - (\esp(X))^2
        \end{split}\]
      \end{proof}

      \begin{props} \
        \begin{enumerate}
          \item $\var(aX + b) = a^2 \, \var(X)$ y $\sigma_{aX + b} = |a| \sigma_X$.
          \begin{proof}
            En general, $\var(h(X)) = \sum_{x \in R_X} (h(X) - \esp(h(X)))^2 p_X(x)$.
            Entonces,
            \[ \begin{split}
            \var(aX + b) &= \sum_{x \in R_X} (ax + b - \esp(aX + b))^2 p_X(x) = \sum_{x \in R_X} (ax + b - a \esp(X) - b)^2 p_X(x) \\
            &= \sum_{x \in R_X} (ax - a \esp(X))^2 p_X(x) = a^2 \sum_{x \in R_X} (x - \esp(X))^2 p_X(x) = a^2 \var(X)
            \end{split} \]
            y por lo tanto, $\sigma_{aX + b} = \vert a \vert \sigma_X$.

            En particular, observemos que $\sigma_{aX}^2 = a^2 \sigma_X^2$ y $\sigma_{X + b}^2 = \sigma_X^2$, es decir, un cambio de escala afecta a la varianza, pero una traslación no la afecta.
          \end{proof}

          \item Si $X$ es una v.a. tal que $\proba(X = c) = 1$, entonces $\var(X) = 0$.
          \begin{proof}
            $ \var(X) = \esp(X^2) - (\esp(X))^2 = c^2 p_X(c) - (c p_X(c))^2 = c^2 - c^2 = 0 $.
          \end{proof}
        \end{enumerate}
      \end{props}

  \subsection{Variables aleatorias continuas}

    \begin{defi}
      Una variable aleatoria $X$ es \deft{continua} si existe una función $f_X: \mathbb{R} \to \mathbb{R^+}$, llamada \emph{función de densidad} de la v.a. $X$, tal que
      \[ \proba(X \in A) = \int_A f_X(x) \,dx \quad \foralle A \subseteq \mathbb{R} \]
    \end{defi}

    En particular, si $A = [a,b]$, entonces
    \[ \proba(a \leq X \leq b) = \int_a^b f_X(x) \,dx \]
    y $\proba(X = a) = \proba(a \leq X \leq a) = 0 \ \foralle a \in \mathbb{R}$.

    \begin{prop}
      Para que una función $f(x)$ sea una función de densidad, debe satisfacer
      \begin{itemize}
        \item $f(x) \geq 0 \ \foralle x \in \mathbb{R}$.
        \item $\int_{- \infty}^{+ \infty} f(x) \,dx = 1$.
      \end{itemize}
    \end{prop}

    \begin{defi}
      La \deft{función de distribución acumulada} de una v.a. continua $X$ con función de densidad $f_X(x)$ se define, para todo $x \in \mathbb{R}$, como
      \[ F_X(X) = \proba(X \leq x) = \int_{- \infty}^x f_X(t) \,dt \]
    \end{defi}

    \begin{props} Sea $X$ una v.a. continua.
      \begin{enumerate}
        \item $\foralle x \in \mathbb{R}, F_X(x) \in [0,1]$.
        \item $F_X(x)$ es monótona no decreciente, es decir, si $x_1 < x_2 \Rightarrow F_X(x_1) \leq F_X(x_2)$.
        \item $F_X(x)$ es continua en todo punto.
        \item $\lim_{x \to +\infty} F_X(x) = 1$ y $\lim_{x \to -\infty} F_X(x) = 0$.
      \end{enumerate}
    \end{props}

    \begin{pro}
      Sean $a$ y $b$ tales que $a \leq b$, entonces
      \[ \proba(a \leq X \leq b) = \proba(a < X \leq b) = \proba(a \leq X < b) = \proba(a < X < b) = F_X(b) - F_X(a) \]
    \end{pro}
    \begin{proof}
      Se deduce inmediatamente del hecho de que, si $X$ es continua, $\proba(X = x) = 0$
    \end{proof}

    \begin{pro}
      Si $X$ es una v.a. continua con función de densidad $f_X(x)$ y función de distribución acumulada $F_X(x)$, entonces, en todo punto donde $F_X(x)$ es derivable
      \[ F^\prime(x) = \frac{\partial F_X(x)}{\partial x} = f_X(x) \]
    \end{pro}
    \begin{proof}
      Resulta del Teorema Fundamental del Cálculo Integral y de la definición de $F_X(X)$.
    \end{proof}

    \begin{defi}
      Sea $X$ una v.a. continua con función de densidad $f_X(x)$ y función de distribución acumulada $F_X(x)$, y sea $0 < p < 1$. El \deft{percentil} $(100p)$-ésimo de la distribución de $X$ es el valor $x_p$, tal que
      \[ F_X(x_p) = \proba(X \leq x_p) = \int_{-\infty}^{x_p} f(t) \,dt = p \]

      El 50-percentil de una distribución se denomina \emph{mediana} de la distribución.
    \end{defi}

    \subsubsection{Esperanza de una v.a. continua}

      \begin{defi}
        Sea $X$ una v.a. continua con función de densidad $f_X(x)$. La \deft{esperanza} o \deft{valor esperado} de $X$ se define como
        \[ \esp(X) = \mu_X = \int_{-\infty}^{+\infty} x \, f_X(x) \,dx \]
        siempre que $\int_{-\infty}^{+\infty} |x| \, f_X(x) \,dx < \infty$. Si esta integral no converge, la esperanza no puede definirse y decimos que no existe.
      \end{defi}

      \begin{pro}
        Si la v.a. continua $X$ tiene función de densidad $f_X(x)$, entonces la esperanza de cualquier función real $h(X)$ está dada por
        \[ \esp(h(X)) = \int_{-\infty}^{+\infty} h(x) \, f_X(x) \,dx \]
        si $\int_{-\infty}^{+\infty} |h(x)| \, f_X(x) \,dx < \infty$.
      \end{pro}

      \begin{prop} [Linealidad]
        Si $a$ y $b$ son constantes reales, $\esp(aX + b) = a\esp(X) + b$.
      \end{prop}
      \begin{proof}
        Sea $h(X) = aX + b$, entonces
        \[ \begin{split}
        \esp(h(X)) &= \int_{-\infty}^{+\infty} h(x) f_X(x) \,dx = \int_{-\infty}^{+\infty} (ax + b) f_X(x) \,dx = \\
        &= a \int_{-\infty}^{+\infty} x f_X(x) \,dx + b \int_{-\infty}^{+\infty} f_X(x) \,dx = a \esp(X) + b
        \end{split} \]
      \end{proof}

    \subsubsection{Varianza de una v.a. continua}

      \begin{defi}
        Sea $X$ una v.a. continua con densidad $f_X(x)$. La \deft{varianza} de $X$, que se denotará $\var(X)$, $\sigma_X^2$ o $\sigma^2$, es
        \[ \var(X) = \sigma_X^2 = \esp\left[ (X - \esp(X))^2 \right] = \int_{-\infty}^{+\infty} (x - \esp(X))^2 \, f_X(x) \,dx \]
        y el \deft{desvío estándar} de $X$ es $\sigma_X = \sqrt{\var(X)}$.
      \end{defi}

      \begin{pro}
        \[ \var(X) = \esp(X^2) - (\esp(X))^2 \]
      \end{pro}
      \begin{proof}
        \[ \begin{split}
          \var(X) &= \esp \left[ (X - \esp(X))^2 \right] = \int_{-\infty}^{+\infty} (x - \esp(X))^2 f_X(x) \,dx = \\
          &= \int_{-\infty}^{+\infty} (x^2 - 2x \esp(X) + (\esp(X))^2) f_X(x) \,dx = \\
          &= \int_{-\infty}^{+\infty} x^2 f_X(x) \,dx - 2 \esp(X) \int_{-\infty}^{+\infty} x f_X(x) dx + (\esp(X))^2 \int_{-\infty}^{+\infty} f_X(x) \,dx = \\
          &= \esp(X^2) - 2 \esp(X) \esp(X) + (\esp(X))^2 = \esp(X^2) - (\esp(X))^2
        \end{split} \]
      \end{proof}

      \begin{prop}
        Sea $X$ una v.a. continua con densidad $f_X(x)$, entonces
        \[ \var(aX + b) = a^2 \, \var(X) \qquad \text{y} \qquad \sigma_{aX + b} = |a| \sigma_X \]
      \end{prop}
      \begin{proof}
        En general, $\var(h(X)) = \int_{-\infty}^{+\infty} (h(X) - \esp(h(X)))^2 f_X(x) \,dx$.
        Entonces,
        \[ \begin{split}
        \var(aX + b) &= \int_{-\infty}^{+\infty} (ax + b - \esp(aX + b))^2 f_X(x) \,dx = \int_{-\infty}^{+\infty} (ax + b - a \esp(X) - b)^2 f_X(x) \,dx \\
        &= \int_{-\infty}^{+\infty} (ax - a \esp(X))^2 f_X(x) \,dx = a^2 \int_{-\infty}^{+\infty} (x - \esp(X))^2 f_X(x) \,dx = a^2 \var(X)
        \end{split} \]
        y por lo tanto, $\sigma_{aX + b} = \vert a \vert \sigma_X$.
      \end{proof}

\section{Distribuciones de variables aleatorias}

  \subsection{Distribuciones de variables aleatorias discretas}

    \subsubsection{Distribución binomial}

      Un \emph{experimento binomial} es un experimento aleatorio que satisface las siguientes condiciones
      \begin{itemize}
        \item Consta de $n$ repeticiones, siendo $n$ fijo.
        \item Las repeticiones son idénticas, y en cada una de ellas hay solo dos resultados posibles, que denominaremos éxito (E) y fracaso (F) (a un experimento de este tipo se lo denomina \emph{ensayo de Bernoulli}).
        \item Las repeticiones son independientes, es decir, el resultado de una no influye sobre el de las demás.
        \item La probabilidad de éxito $p = \proba(E)$ se mantiene constante durante las repeticiones.
      \end{itemize}

      \begin{defi}
        Dado un experimento binomial que conste de $n$ repeticiones, con $\proba(E) = p$, consideramos la v.a.
        \[ X : \text{número de éxitos en las $n$ repeticiones} \]

        Decimos que $X$ tiene \deft{distribución binomial} con parámetros $n$ y $p$, y lo notamos $X \dist{Bi}(n, p)$.
      \end{defi}

      \paragraph{Función de probabilidad puntual.}
      Si $X \dist{Bi}(n,p)$, entonces
      \[ p_X(x) = \binom{n}{x} p^x (1 - p)^{n - x} \qquad \foralle x \in {0, 1, \dots, n} \]

      \paragraph{Función de distribución acumulada.}
      Si $X \dist{Bi}(n,p)$, entonces
      \[ F_X(x) = \begin{cases}
        0 & \text{si $x < 0$} \\
        \displaystyle \sum_{k = 0}^{\lfloor x \rfloor} \binom{n}{k} p^k (1 - p)^{n - k} & \text{si $0 \leq x \leq n$} \\
        1 & \text{si $x > n$}
      \end{cases}  \]
      donde $\lfloor x \rfloor$ denota la parte entera de $x$.

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{Bi}(n,p)$.
      \[ \esp(X) = np \qquad \text{y} \qquad \var(X) = np(1 - p) \]
      % \begin{proof}
      %   \[ \begin{split}
      %   \esp(X) &= \sum_{k=0}^n k \binom{n}{k} p^k (1 - p)^{n - k} = \sum_{k = 1}^n k \binom{n}{k} p^k (1 - p)^{n - k} = \sum_{k = 1}^n k \frac{n!}{k!(n - k)!} p^k (1 - p)^{n - k} = \\
      %   &= \sum_{k = 1}^n \frac{n!}{(k - 1)! (n - k)!} p^k (1 - p)^{n - k} = np \sum_{k = 1}^n \frac{(n - 1)!}{(k - 1)! (n - k)!} p^{k - 1} (1 - p)^{n - k} = \\
      %   &= np \sum_{k = 1}^n \binom{n - 1}{k - 1} p^{k - 1} (1 - p)^{(n - 1) (k - 1)} \underset{(k - 1) = j}{=} np \sum_{j = 0}^{n - 1} \binom{n - 1}{j} p^j (1 - p)^{n - 1 - j} = \\
      %   &= np (p + (1 - p))^{n - 1} = np
      %   \end{split} \]
      % \end{proof}

    \subsubsection{Distribución geométrica}

      \begin{defi}
        Supongamos que se realizan repeticiones independientes de un ensayo de Bernoulli con probabilidad de éxito $\proba(E) = p$ constante. Definimos la v.a.
        \[ X : \text{número de repeticiones hasta obtener el primer éxito} \]

        Decimos que $X$ tiene \deft{distribución geométrica} con parámetro $p$, y lo notamos $X \dist{G}(p)$.
      \end{defi}

      \paragraph{Función de probabilidad puntual.}
      Si $X \dist{G}(p)$, entonces
      \[ p_X(x) = p(1 - p)^{x - 1} \qquad \foralle x \in \mathbb{N} \]

      \paragraph{Función de distribución acumulada.}
      Si $X \dist{G}(p)$, entonces
      \[ F_X(x) = \begin{cases}
        0 & \text{si $x < 1$} \\
        \displaystyle 1 - (1 - p)^{\lfloor x \rfloor} & \text{si $x \geq 1$}
      \end{cases}  \]
      donde $\lfloor x \rfloor$ denota la parte entera de $x$.

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{G}(p)$.
      \[ \esp(X) = \frac{1}{p} \qquad \text{y} \qquad \var(X) = \frac{(1 - p)}{p^2} \]

      \begin{pro} [Propiedad de falta de memoria]
        Sea $X \dist{G}(p)$, y sean $n$ y $m$ números naturales cualesquiera.
        \[ \proba(X > n + m \mid X > n) = \proba(X > m) \]
      \end{pro}

    \subsubsection{Distribución binomial negativa}

      \begin{defi}
        Supongamos que se realizan repeticiones independientes de un ensayo de Bernoulli con probabilidad de éxito $\proba(E) = p$ constante. Sea $r \geq 1$. Definimos la v.a.
        \[ X : \text{número de repeticiones hasta obtener el $r$-ésimo éxito} \]

        Decimos que $X$ tiene \deft{distribución binomial negativa} con parámetros $r$ y $p$, y lo notamos $X \dist{BN}(r,p)$.
      \end{defi}

      \paragraph{Función de probabilidad puntual.}
      Si $X \dist{BN}(r,p)$, entonces
      \[ p_X(x) = \binom{x - 1}{r - 1} p^r (1 - p)^{x - r} \qquad \foralle x \in \lbrace r, r + 1, r + 2, \dots \rbrace \]

      \paragraph{Función de distribución acumulada.}
      Si $X \dist{BN}(r,p)$, entonces
      \[ F_X(x) = \begin{cases}
        0 & \text{si $x < r$} \\
        \displaystyle \sum_{k = r}^{\lfloor x \rfloor} \binom{k - 1}{r - 1} p^r (1 - p)^{k - r} & \text{si $x \geq r$}
      \end{cases}  \]
      donde $\lfloor x \rfloor$ denota la parte entera de $x$.

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{BN}(r,p)$.
      \[ \esp(X) = \frac{r}{p} \qquad \text{y} \qquad \var(X) = \frac{r(1 - p)}{p^2} \]

    \subsubsection{Distribución hipergeométrica}

      \begin{defi}
        Consideremos una población de $N$ elementos, en la que cada elemento puede ser clasificado como éxito o fracaso, y entre los cuales hay $D$ éxitos. Supongamos que se extrae una muestra de $n$ elementos de la población, de forma tal que cualquier subconjunto de $n$ elementos tiene igual probabilidad de ser elegido. Definimos la v.a.
        \[ X : \text{número de éxitos en la muestra de tamaño $n$} \]

        Decimos que $X$ tiene \deft{distribución hipergeométrica} con parámetros $n$, $N$ y $D$, y lo notamos $X \dist{H}(n,N,D)$.
      \end{defi}

      \paragraph{Función de probabilidad puntual.}
      Si $X \dist{H}(n,N,D)$, entonces
      \[ p_X(x) = \frac{\binom{D}{x} \binom{N - D}{n - x}}{\binom{N}{n}} \qquad \foralle \max(0, n - (N - D)) \leq x \leq \min(n, D) \]

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{H}(n,N,D)$.
      \[ \esp(X) = n \frac{D}{N} \qquad \text{y} \qquad \var(X) = \left( \frac{N - n}{N - 1} \right) n \frac{D}{N} \left( 1 - \frac{D}{N} \right) \]

      \begin{obs}
        Si $n$ es pequeño en relación a $N$, la distribución hipergeométrica puede ser aproximada por una distribución binomial de parámetros $n$ y $p = \frac{D}{N}$. Observemos que, en este caso, el factor $\left( \frac{N - n}{N - 1}\right)$ que aparece en la varianza (denominado \emph{factor de corrección por población finita}) es aproximadamente 1.
      \end{obs}

    \subsubsection{Distribución Poisson}
      \begin{defi}
        Decimos que la variable aleatoria $X$ tiene \deft{distribución de Poisson} con parámetro $\lambda > 0$, y lo notamos $X \dist{\poisson}(\lambda)$, si su función de probabilidad puntual está dada por
        \[ p_X(x) = \frac{e^{-\lambda} \lambda^x}{x!} \qquad \foralle x \in \mathbb{N} \cup \lbrace 0 \rbrace \]
      \end{defi}

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{\poisson}(\lambda)$.
      \[ \esp(X) = \var(X) = \lambda \]

      \begin{pro} [Aproximación de la distribución binomial por la distribución Poisson]
        Sea $X \dist{Bi}(n,p)$, y supongamos que $n \to \infty$ y $p \to 0$ de forma tal que el producto $np = \lambda$ se mantenga constante. Entonces

        \[ p_X (x) = \binom{n}{x} p^x (1 - p)^{n - k} \longrightarrow \frac{e^{-\lambda} \lambda^x}{x!} \qquad \foralle x \in \mathbb{N} \cup \lbrace 0 \rbrace \]

        Esto quiere decir que, para valores de $n$ grandes y de $p$ pequeños, la distribución binomial es bien aproximada por una distribución Poisson de parámetro $\lambda = np$.

        Algunos autores sugieren que la aproximación es buena para $n \geq 100$, $p \leq 0,01$ y $\lambda \leq 20$.
      \end{pro}
      \begin{proof}
        \[ \begin{split}
          p_X(x) &= \binom{n}{x} p^x (1 - p)^{n - x} = \frac{n!}{x! (n - x)!} \left( \frac{\lambda}{n} \right)^x \left( 1 - \frac{\lambda}{n} \right)^{n - x} = \\
          &= \frac{n (n-1) \dots (n - x + 1)}{n^x} \left( 1 - \frac{\lambda}{n} \right)^n \left( 1 - \frac{\lambda}{n} \right)^{-x} \frac{\lambda^x}{x!} = \\
          &= \left[ \frac{n}{n} \frac{n - 1}{n} \dots \frac{n - x + 1 }{n} \right] \left( 1 - \frac{\lambda}{n} \right)^n \left( 1 - \frac{\lambda}{n} \right)^{-x} \frac{\lambda^x}{x!}
        \end{split} \]

        Observemos que:
        \begin{itemize}
          \item $\displaystyle \lim_{n \to \infty} 1 \frac{n - 1}{n} \dots \frac{n - x +1}{n} = 1$
          \item $\displaystyle \lim_{n \to \infty} \left( 1 - \frac{\lambda}{n} \right)^n = e^{-\lambda}$
          \item $\displaystyle \lim_{n \to \infty} \left( 1 - \frac{\lambda}{n} \right)^{-x} = 1$
        \end{itemize}

        Entonces, $p_X(x) \longrightarrow \frac{e^{-\lambda} \lambda^x}{x!}$, como queríamos demostrar.
      \end{proof}

      \paragraph{Procesos de Poisson.}
      \begin{defi}
        Supongamos que observamos la ocurrencia de un evento que se repite a lo largo del tiempo, y que existe una cantidad $\theta > 0$, tal que:
        \begin{enumerate}
          \item Dado un intervalo pequeño de longitud $\Delta t$, la probabilidad de que ocurra exactamente un evento es aproximadamente igual a $\theta \Delta t$, es decir,
          \[ \proba(\text{ocurra un evento en }\Delta t) = \theta \Delta t + o(\Delta t) \]
          donde $o(h)$ es una función $g(h)$ tal que $\lim_{h \to 0} \frac{g(h)}{h} = 0$.
          \item La probabilidad de que ocurra más de un evento en un intervalo pequeño de longitud $\Delta t$ es pequeña en comparación con la probabilidad de que ocurra un evento, es decir,
          \[ \proba(\text{ocurra más de un evento en }\Delta t) = o(\Delta t) \]
          \item El número de eventos que ocurren en un intervalo es independiente del número de eventos que ocurren en otro intervalo disjunto.
        \end{enumerate}
        Un experimento que cumple con estas características se conoce como \deft{proceso de Poisson}, con \emph{tasa media de ocurrencia} o \emph{intensidad} $\theta$. Se cumple que el número de ocurrencias del evento en un período de longitud $t$ tiene distribución de Poisson de parámetro $\theta t$, es decir, la v.a.
        \[ X_t : \text{número de ocurrencias del evento en el intervalo de longitud $t$} \]
        satisface $X \dist{\poisson}(\theta t)$.
      \end{defi}

  \subsection{Distribuciones de variables aleatorias continuas}

    \subsubsection{Distribución uniforme}

      \begin{defi}
        Sea $X$ una v.a. continua. Decimos que $X$ tiene \deft{distribución uniforme} con parámetros $A$ y $B$, y lo notamos $X \dist{\unif}(A,B)$, si su función de densidad es
        \[ f_X(x) = \frac{1}{B - A} \, \indi{[A,B]}(x) \]
        es decir, si su densidad es constante dentro del intervalo $[A,B]$ y $0$ fuera de él.
      \end{defi}

      \paragraph{Función de distribución acumulada.}
      Sea $X \dist{\unif}(A,B)$, entonces
      \[ F_X(x) = \begin{cases}
        0 & \text{si $x < A$} \\
        \displaystyle \frac{x - A}{B - A} & \text{si $A \leq x \leq B$} \\
        1 & \text{si $x > B$}
      \end{cases} \]

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{\unif}(A,B)$, entonces
      \[ \esp(X) = \frac{A + B}{2} \qquad \text{y} \qquad \var(X) = \frac{(B - A)^2}{12} \]

    \subsubsection{Distribución normal}

      \begin{defi}
        Sea $X$ una v.a. continua. Decimos que $X$ tiene \deft{distribución normal} con parámetros $\mu$ y $\sigma^2$ ($\mu \in \mathbb{R}, \sigma > 0$), y lo notamos $X \dist{N}(\mu,\sigma^2)$, si su función de densidad es
        \[ f_X(x) = \frac{1}{\sqrt{2\pi}\sigma} \, e^{- \frac{1}{2\sigma^2}(x - \mu)^2} \]
      \end{defi}

      El gráfico de la función de densidad normal tiene forma de campana, con eje de simetría en $x = \mu$ y puntos de inflexión en $x = \mu \pm \sigma$.

      La importancia de la distribución normal radica no sólo en que frecuentemente en la práctica se hallan variables que tienen esta distribución (por ejemplo, los errores de medición) sino porque, bajo ciertas condiciones, suele ser una buena aproximación a la distribución de otras variables aleatorias.

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{N}(\mu, \sigma^2)$, entonces
      \[ \esp(X) = \mu \qquad \text{y} \qquad \var(X) = \sigma^2 \]

      \paragraph{Distribución normal estándar.}
      \begin{defi}
        Sea $Z$ una v.a. continua con distribución normal. Decimos que $Z$ tiene \deft{distribución normal estándar} si sus parámetros son $\mu = 0$ y $\sigma^2 = 1$, es decir, $Z \dist{N}(0,1)$. Su función de densidad es
        \[ f_Z(z) = \frac{1}{\sqrt{2\pi}} \, e^{- \frac{z^2}{2}} \]
      \end{defi}

      \paragraph{Función de distribución acumulada.}
      Dada $Z \dist{N}(0,1)$, su función de distribución acumulada se denota $\Phi(z)$, y está dada por
      \[ \Phi(z) = \int_{- \infty}^z \frac{1}{\sqrt{2\pi}} \, e^{\frac{t^2}{2}} \, dt \]

      Esta función no tiene una expresión analítica conocida, por lo que está tabulada.

      \begin{props} \
        \begin{enumerate}
          \item Si $X \dist{N}(\mu,\sigma^2) \Rightarrow Z = \frac{X - \mu}{\sigma}\dist{N}(0,1)$.
          \item Si $Z\dist{N}(0,1)$ y $\sigma > 0 \Rightarrow X = \sigma Z + \mu \dist{N}(\mu,\sigma^2)$.
          \item Sean $X\dist{N}(\mu,\sigma^2)$ y $Z\dist{N}(0,1)$. Si denotamos $x_p$ y $z_p$ a los $100 p$-ésimos percentiles de $X$ y $Z$ respectivamente, entonces $x_p = \sigma z_p + \mu$.
        \end{enumerate}
      \end{props}

    \subsubsection{Distribución gamma}

      \begin{defi}
        Dado $\alpha > 0$, definimos la \deft{función gamma} o \deft{función factorial} como
        \[ \Gamma(\alpha) = \int_0^{+ \infty} x^{\alpha - 1} e^{- x} \, dx \]
      \end{defi}

      \begin{props} \
        \begin{enumerate}
          \item Si $\alpha > 1$, $\Gamma(\alpha) = (\alpha - 1) \Gamma(\alpha - 1)$.
          \item Si $\alpha \in \mathbb{N}$, $\Gamma{\alpha} = (\alpha - 1)!$.
          \item $\Gamma(\frac{1}{2}) = \sqrt{\pi}$.
        \end{enumerate}
      \end{props}

      \begin{defi}
        Sea $X$ una v.a. continua. Decimos que $X$ tiene \deft{distribución gamma} con parámetros $\alpha$ y $\lambda$, y lo notamos $X \dist{\Gamma}(\alpha,\lambda)$, si su función de densidad es
        \[ f_X(x) = \frac{e^{- \lambda x} x^{\alpha - 1} \lambda^\alpha}{\Gamma(\alpha)} \, \indi{(0,+ \infty)}(x) \]
      \end{defi}

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{\Gamma}(\alpha,\lambda)$, entonces
      \[ \esp(X) = \frac{\alpha}{\lambda} \qquad \text{y} \qquad \var(X) = \frac{\alpha}{\lambda^2} \]

      \begin{defi}
        Sea $X$ una v.a. continua con distribución gamma. Decimos que $X$ tiene \deft{distribución gamma estándar} con parámetro $\alpha$ si su parámetro $\lambda = 1$, es decir, $X \dist{\Gamma}(\alpha,1)$. Su función de densidad está dada por
        \[ f_X(x) = \frac{e^{-x} x^{\alpha - 1}}{\Gamma(\alpha)} \, \indi{(0,+\infty)}(x) \]
      \end{defi}

      Esta función de densidad es estrictamente decreciente si $\alpha \leq 1$, y si $\alpha > 1$ alcanza un máximo y después decrece.
      La distribución gamma estándar está tabulada para diferentes valores de $\alpha$.

      \begin{prop}
        Si $X \dist{\Gamma}(\alpha,\lambda)$ y $a > 0$, $a X \dist{\Gamma}(\alpha, \frac{\lambda}{a})$.

        Esta propiedad permite obtener probabilidades para una v. a. con distribución gamma a partir de una distribución gamma estándar. Supongamos que $X \dist{\Gamma}(\alpha,\lambda)$, entonces $\lambda X \dist{\Gamma}(\alpha,1)$ y, por ejemplo,
        \[ \proba(X \leq x) = \proba(\lambda X \leq \lambda x) = F_{\lambda x} (\lambda x) \]
      \end{prop}

    \subsubsection{Distribución exponencial}

      \begin{defi}
        Sea $X$ una v.a. continua. Decimos que $X$ tiene \deft{distribución exponencial} con parámetro $\lambda$, y lo notamos $X \dist{\exponen}(\lambda)$, si su función de densidad es
        \[ f_X(x) = \lambda e^{-\lambda x} \, \indi{(0,+\infty)}(x) \]
      \end{defi}

      \begin{obs}
        Notemos que una distribución exponencial es un caso particular de la distribución gamma con parámetro $\alpha = 1$.
      \end{obs}

      \paragraph{Función de distribución acumulada.}
      Sea $X \dist{\exponen}(\lambda)$, entonces
      \[ F_X(x) = \begin{cases}
        0 & \text{si $x \leq 0$} \\
        1 - e^{-\lambda x} & \text{si $x > 0$}
      \end{cases} \]

      \paragraph{Esperanza y varianza.}
      Sea $X \dist{\exponen}(\lambda)$, entonces
      \[ \esp(X) = \frac{1}{\lambda} \qquad \text{y} \qquad \var(X) = \frac{1}{\lambda^2} \]

      \begin{pro} [Propiedad de falta de memoria]
        Sea $X \dist{\exponen}(\lambda)$, y sean $s$ y $t$ números reales positivos cualesquiera.
        \[ \proba(X > s + t \mid X > s) = \proba(X > t) \]
      \end{pro}

      \begin{pro} [Relación de la distribución exponencial con los procesos de Poisson]
        Dado un proceso de Poisson de intensidad $v$, si se define la v.a.
        \[ T : \text{tiempo hasta la ocurrencia del primer evento} \]
        entonces $T \dist{\exponen}(v)$.
      \end{pro}

      \begin{proof}
        Si $t \leq 0$, $F_T(t) = 0$. Sea $t > 0$:
        \[ F_T(t) = \proba(T \leq t) = 1 - \proba(T > t) = 1 - \proba(X_t = 0) \]
        dado que el tiempo hasta la primera ocurrencia es mayor que $t$ si y solo si no ha ocurrido ningún evento en el intervalo $(0, t)$. Entonces,
        \[ F_T(t) = 1 - \proba(X_t = 0) = 1 \frac{e^{-vt} (vt)^0}{0!} = 1 - e^{-vt} \]
        y, por lo tanto,
        \[ F_T(x) = \begin{cases}
          0 & \text{si $x \leq 0$} \\
          1 - e^{-vx} & \text{si $x > 0$}
        \end{cases} \]
        es decir, $T \dist{\exponen}(v)$.
      \end{proof}

  \subsection{Funciones generadoras de momentos}

    \begin{defi}
      Sea $X$ una variable aleatoria. El \deft{momento} de orden $k$ de $X$ se define como $\esp\left(X^k\right)$, siempre que la esperanza exista.
    \end{defi}

    \begin{defi}
      La \deft{función generadora de momentos} de una variable aleatoria $X$ es una función a valores reales $M_X(t)$, definida como
      \[ M_X(t) = \esp\left(e^{tX}\right) = \begin{cases}
        \displaystyle \sum_{x \in R_X} e^{tx} p_X(x) & \text{si $X$ es discreta} \\
        \displaystyle \int_{-\infty}^{+\infty} e^{tx} f_X(x) \,dx & \text{si $X$ es continua}
      \end{cases} \]
      siempre que la esperanza exista para todo $t \in (-h, h), h > 0$. Esta última es una condición técnica necesaria para que $M_X(t)$ sea diferenciable en $t = 0$.
    \end{defi}

    Enunciaremos, sin demostración, el siguiente lema de cálculo avanzado, a partir del cual puede demostrarse un importante teorema acerca de la función generadora de momentos de una variable aleatoria.
    \begin{lema}
      Si la función $g(t)$, definida por
      \[ g(t) = \sum_x e^{tx} p(x) \qquad \text{o} \qquad g(t) = \int_{-\infty}^{+\infty} e^{tx} f(x) dx \]
      converge para todo $t \in (-h, h)$ para algún $h > 0$, entonces existen las derivadas de orden $n$ de $g(t)$ para todo $t \in (-h,h)$ y para todo $n \in \mathbb{N}$, y se obtienen como
      \[ \frac{\partial^n g(t)}{\partial t^n} = \sum_x \frac{\partial^n e^{tx}}{\partial t^n} p(x) \qquad \text{o} \qquad \frac{\partial^n g(t)}{\partial t^n} = \int_{-\infty}^{+ \infty} \frac{\partial^n e^{tx}}{\partial t^n} f(x) \,dx \]
    \end{lema}

    \begin{teo}
      Sea $X$ una v.a. para la cual existe la función generadora de momentos $M_X(t)$. Entonces
      \[ \esp\left(X^n\right) = \left. \frac{\partial^n M_X(t)}{\partial t^n} \right\vert_{t=0} \]
    \end{teo}

    \begin{proof}
      Si la función generadora de momentos existe para todo $t \in (-h,h)$ para algún $h > 0$, aplicando el lema anterior
      \[ \frac{\partial^n M_X(t)}{\partial t^n} = \sum_x \frac{\partial^n e^{tx}}{\partial t^n} p(x) \qquad \text{o} \qquad \frac{\partial^n M_X(t)}{\partial t^n} = \int_{-\infty}^{+ \infty} \frac{\partial^n e^{tx}}{\partial t^n} f(x) \,dx \]
      \[ \frac{\partial^n M_X(t)}{\partial t^n} = \sum_x x^n e^{tx} p(x) \qquad \text{o} \qquad \frac{\partial^n M_X(t)}{\partial t^n} = \int_{-\infty}^{+ \infty} x^n e^{tx} f(x) \,dx \]

      Evaluando estas derivadas en 0,
      \[ \left. \frac{\partial^n M_X(t)}{\partial t^n} \right\vert_{t=0} = \sum_x x^n p(x) = \esp\left(X^n\right) \qquad \text{o} \qquad \left. \frac{\partial^n M_X(t)}{\partial t^n} \right\vert_{t=0} = \int_{-\infty}^{+ \infty} x^n f(x) \,dx = \esp\left(X^n\right) \]
    \end{proof}

    \begin{prop}
      Sea $X$ una v.a. con función generadora de momentos $M_X(t)$. Entonces, si  $Y = aX + b$, $M_Y(t) = e^{bt} M_X(at)$.
    \end{prop}

    \begin{teo} [Unicidad de la función generadora de momentos]
      Si existe la función generadora de momentos de una variable aleatoria, es única. Además, la función generadora de momentos determina a la función de probabilidad puntual o densidad de la v.a., salvo a lo sumo en un conjunto de probabilidad 0.
    \end{teo}

    \subsubsection{Funciones generadoras de momentos de algunas distribuciones}

      \begin{center}
        \begin{tabular}{c | c}%{c | >{$ \displaystyle}c<{$}}
          Distribución                      & $\displaystyle M_X(t)$ \\ \hline
          $\dists{Bi}(n, p)$                & $\displaystyle \left( e^t p + 1 - p \right)^n$ \\
          $\dists{G}(p)$                    & $\displaystyle \frac{p e^t}{1 - (1 - p)e^t}$ \\
          $\dists{BN}(r,p)$                 & $\displaystyle \left( \frac{p e^t}{1 - (1 - p)e^t} \right)^r$ \\
          $\dists{\poisson}(\lambda)$       & $\displaystyle e^{\lambda(e^t - 1)}$ \\
          $\dists{\unif}(A,B)$                  & $\displaystyle \frac{e^{tb} - e^{ta}}{t(b - a)}$ \\
          $\dists{N}(\mu,\sigma^2)$         & $\displaystyle e^{\frac{\sigma^2 t^2}{2} + \mu t}$ \\
          $\dists{\Gamma}(\alpha,\lambda)$  & $\displaystyle \left( \frac{\lambda}{\lambda - t} \right)^\alpha$ \\
          $\dists{\exponen}(\lambda)$       & $\displaystyle \frac{\lambda}{\lambda - t}$
        \end{tabular}
      \end{center}

  \subsection{Generación de números aleatorios}
    En diversas aplicaciones, es útil disponer de números elegidos al azar. Existen algoritmos que permiten generar números aleatorios que se comportan como si proviniesen de una distribución $\dists{\unif}(0,1)$. El siguiente teorema nos permite afirmar que esto es suficiente para obtener números aleatorios que respeten alguna otra distribución determinada.

    \begin{teo}
      Sean $U$ una variable aleatoria tal que $U \dist{\unif}(0,1)$, y $G$ una función de distribución acumulada continua y estrictamente creciente. Si $X = G^{-1}(U)$ , entonces la función de distribución acumulada de $X$ es $G$, es decir $F_X = G$.
    \end{teo}
    \begin{proof}
      Recordemos que si $U \dist{\unif}(0,1)$, entonces su función de distribución es de la forma
      \[ F_U(u) = \begin{cases}
        0 & \text{si $u < 0$} \\
        \displaystyle u & \text{si $0 \leq u \leq 1$} \\
        1 & \text{si $u > 1$}
      \end{cases} \]

      Por lo tanto, como $G$ es una función estrictamente creciente y su imagen pertenece al intervalo $(0,1)$, entonces
      \[ F_X(x) = \proba(X \leq x) = \proba(G^{-1}(U) \leq x) = \proba(U \leq G(x)) = F_U(G(X)) = G(X) \qedhere \]
    \end{proof}

    Si la distribución $G$ tiene saltos o es constante de a trozos, no existirá su inversa. Sin embargo, se puede demostrar que existe una función $H$ con las propiedades requeridas en el teorema anterior, lo que permite enunciar siguiente resultado.

    \begin{teo}
      Sean $U$ una variable aleatoria tal que $U \dist{\unif}(0,1)$, y $G$ una función de distribución acumulada. Existe una función $H$ tal que $H(U)$ tiene distribución acumulada $G$.
    \end{teo}

\section{Vectores aleatorios}

  \subsection{Vectores aleatorios en dos dimensiones}

    \begin{defi}
      Sean $X$ e $Y$ v.a. discretas definidas sobre un espacio muestral $\espm$. La \deft{función de probabilidad conjunta} del par $(X,Y)$ se define como
      \[ p_{XY}(x,y) = \proba(X = x, Y = y) \]

      El conjunto $R_{XY} = \lbrace (x,y) / x \in R_X, y \in R_Y \rbrace$ es el \deft{rango} o \deft{recorrido} del vector aleatorio $(X,Y)$.
    \end{defi}

    Dado cualquier conjunto $A \subseteq \mathbb{R}^2$,
    \[ \proba((X,Y) \in A) = \mathop{\sum \sum}_{(x,y) \in A} p_{XY}(x,y) \]

    Una función de probabilidad conjunta satisface
    \begin{itemize}
      \item $p_{XY}(x,y) \geq 0 \ \foralle (x,y) \in \mathbb{R}^2$
      \item $\sum_x \sum_y p_{XY}(x,y) = 1$
    \end{itemize}

    \begin{defi}
      Sea $(X,Y)$ un vector aleatorio discreto con función de probabilidad conjunta $p_{XY}(x,y)$. Las \deft{funciones de probabilidad marginal} de $X$ e $Y$ están dadas por
      \[ p_X(x) = \sum_y p_{XY}(x,y) \]
      \[ p_Y(x) = \sum_x p_{XY}(x,y) \]
    \end{defi}

    \begin{defi}
      Sea $(X,Y)$ un vector aleatorio discreto con función de probabilidad conjunta $p_{XY}(x,y)$. La \deft{función de distribución acumulada conjunta} de $(X,Y)$ está dada por
      \[ F_{XY}(x,y) = \sum_{s \leq x} \sum_{t \leq y} p_{XY}(s, t) \qquad \foralle (x,y) \in \mathbb{R}^2 \]
    \end{defi}

    \begin{defi}
      Sea $(X,Y)$ un vector aleatorio discreto con función de probabilidad conjunta $p_{XY}(x,y)$ y marginales $p_X(x)$ y $p_Y(y)$, y sea $x$ tal que $p_X(x) > 0$. La \deft{función de probabilidad condicional} de $Y$ dado $X = x$ está dada por
      \[ p_{Y \mid X = x}(y) = \frac{p_{XY}(x,y)}{p_X(x)} \]

      Análogamente, si $y$ es tal que $p_Y(y) > 0$, la función de probabilidad condicional de $X$ dado $Y = y$ está dada por
      \[ p_{X \mid Y = y}(x) = \frac{p_{XY}(x,y)}{p_Y(y)} \]
    \end{defi}

    \begin{defi}
      Sean $X$ e $Y$ variables aleatorias continuas definidas sobre un espacio muestral $\espm$. El vector aleatorio $(X,Y)$ es continuo si existe una función, denominada \deft{función de densidad conjunta}, $f_{XY} : \mathbb{R}^2 \to \mathbb{R}_{\geq 0}$, tal que
      \[ \proba((X,Y) \in A) = \iint_A f_{XY}(x,y) \,dx \,dy \qquad \foralle A \subseteq \mathbb{R}^2 \]
    \end{defi}

    En particular, si $A = [a,b] \times [c,d]$,
    \[ \proba((X,Y) \in A) = \int_a^b \int_c^d f_{XY}(x,y) \,dy \,dx \]

    Una función de densidad conjunta satisface
    \begin{itemize}
      \item $f_{XY}(x,y) \geq 0 \ \foralle (x,y) \in \mathbb{R}^2$.
      \item $\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f_{XY}(x,y) \,dx \,dy = 1$.
    \end{itemize}

    \begin{defi}
      Sea $(X,Y)$ un vector aleatorio continuo con función de densidad conjunta $f_{XY}(x,y)$. La \deft{función de distribución acumulada conjunta} de $(X,Y)$ está dada por
      \[ F_{XY} (x,y) = \int_{-\infty}^x \int_{-\infty}^y f_{XY}(s,t) \,dt \,ds \qquad \foralle (x,y) \in \mathbb{R}^2 \]
    \end{defi}

    \begin{defi}
      Sea $(X,Y)$ un vector aleatorio continuo con función de densidad conjunta $f_{XY}(x,y)$. Las \deft{funciones de densidad marginal} de $X$ e $Y$ están dadas por
      \[ f_X(x) = \int_{-\infty}^{+\infty} f_{XY}(x,y) \,dy \]
      \[ f_Y(y) = \int_{-\infty}^{+\infty} f_{XY}(x,y) \,dx \]
    \end{defi}

    \begin{defi}
      Sea $(X,Y)$ un vector aleatorio continuo con función de densidad conjunta $f_{XY}(x,y)$ y marginales $f_X(x)$ y $f_Y(y)$, y sea $x$ tal que $f_X(x) > 0$. La \deft{función de densidad condicional} de $Y$ dado $X = x$ está dada por
      \[ f_{Y \mid X = x}(y) = \frac{f_{XY}(x,y)}{f_X(x)} \]

      Análogamente, si $y$ es tal que $f_Y(y) > 0$, la función de densidad condicional de $X$ dado $Y = y$ está dada por
      \[ f_{X \mid Y = y}(x) = \frac{f_{XY}(x,y)}{f_Y(y)} \]
    \end{defi}

    \subsubsection{Independencia de variables aleatorias}

      \begin{defi}
        Las variables aleatorias $X$ e $Y$ son \deft{independientes} si y solo si para todo $a < b$ y $c < d$ se satisface
        \[ \proba(\lbrace a < X < b \rbrace \cap \lbrace c < Y < d \rbrace) = \proba(a < X < b) \proba(c < Y < d) \]
        Si esta condición no se satisface, diremos que $X$ e $Y$ son dependientes.
      \end{defi}

      En el caso de un vector $(X,Y)$ discreto, la condición de independencia equivale a la siguiente: $p_{XY}(x,y) = p_X(x) p_Y(y) \ \foralle (x,y) \in \mathbb{R}^2$. En el caso continuo, $X$ e $Y$ son independientes si y solo si $f_{XY}(x,y) = f_X(x) f_Y(y) \ \foralle (x,y) \in \mathbb{R}^2$.

    \subsubsection{Esperanza de una función de dos variables aleatorias}

      \begin{pro}
        Sean $X$ e $Y$ dos variables aleatorias discretas con función de probabilidad conjunta $p_{XY}$ y sea $h(x,y) : \mathbb{R}^2 \to \mathbb{R}$. Entonces $h(X,Y)$ es una variable aleatoria, y
        \[ \esp(h(X,Y)) = \sum_x \sum_y h(x,y) p_{XY}(x,y) \]
        siempre que esta esperanza exista.
      \end{pro}

      \begin{pro}
        Sean $X$ e $Y$ dos variables aleatorias continuas con función de densidad conjunta $f_{XY}$ y sea $h(x,y) : \mathbb{R}^2 \to \mathbb{R}$. Entonces $h(X,Y)$ es una variable aleatoria, y
        \[ \esp(h(X,Y)) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} h(x,y) f_{XY}(x,y) \,dx \,dy \]
        siempre que esta esperanza exista.
      \end{pro}

      \begin{pro}
        Sean $X$ e $Y$ dos variables aleatorias discretas o continuas, y sean $a$ y $b$ números reales. Entonces
        \[ \esp(aX + bY) = a\esp(X) + b\esp(Y) \]
      \end{pro}
      \begin{proof}
        Haremos la demostración para el caso continuo (el caso discreto es similar). Sea $h(X,Y) = aX + bY$. Entonces
        \[ \begin{split}
        \esp(h(X,Y)) &= \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} h(x,y) f_{XY}(x,y) \,dx \,dy = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} (ax + by) f_{XY}(x,y) \,dx \,dy = \\
        &= a \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x f_{XY}(x,y) \,dx \,dy + b \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} y f_{XY}(x,y) \,dx \,dy = \\
        &= a \int_{-\infty}^{+\infty} x \left( \int_{-\infty}^{+\infty} f_{XY}(x,y) \,dy \right) \,dx + b \int_{-\infty}^{+\infty} y \left( \int_{-\infty}^{+\infty} f_{XY}(x,y) \,dx \right) \,dy = \\
        &= a \int_{-\infty}^{+\infty} x f_X(x) \,dx + b \int_{-\infty}^{+\infty} y f_Y(y) \,dy = a \esp(X) + b \esp(Y)
        \end{split} \]
      \end{proof}

      \begin{pro}
        Si $X$ e $Y$ son dos variables aleatorias independientes, entonces
        \[ \esp(XY) = \esp(X) \esp(Y) \]
      \end{pro}

    \subsubsection{Covarianza y correlación}

      \begin{defi}
        Sean $X$ e $Y$ dos variables aleatorias. La \deft{covarianza} entre $X$ e $Y$ se define como
        \[ \cov(X,Y) = \esp\left[ (X - \esp(X)) (Y - \esp(Y)) \right] = \begin{cases}
          \displaystyle \sum_x \sum_y (x - \esp(X)) (y - \esp(Y)) p_{XY}(x,y) \\
          \displaystyle \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} (x - \esp(X)) (y - \esp(Y)) f_{XY} \,dx \,dy
        \end{cases} \]
        según sean $X$ e $Y$ discretas o continuas, respectivamente.
      \end{defi}

      \begin{obs}
        $\cov(X,X) = \var(X)$.
      \end{obs}

      \begin{pro}
        $\cov(X,Y) = \esp(XY) - \esp(X) \esp(Y)$.
      \end{pro}
      \begin{proof}
        \[ \begin{split}
          \cov(X,Y) &= \esp\left[ (X - \esp(X)) (Y - \esp(Y)) \right] = \sum_x \sum_y (x - \esp(X)) (y - \esp(Y)) p_{XY}(x,y) = \\
          &= \sum_x \sum_y (xy - x \esp(X) - y \esp(X) - \esp(X) \esp(Y)) p_{XY}(x,y) = \\
          &= \sum_x \sum_y xy p_{XY}(x,y) - \esp(X) \sum_x \sum_y x p_{XY}(x,y) \\
          &\qquad \qquad - \esp(X) \sum_x \sum_y y p_{XY}(x,y) - \esp(X) \esp(Y) \sum_x \sum_y p_{XY}(x,y) = \\
          &= \esp(XY) - \esp(Y) \sum_x x \sum_y p_{XY}(x,y) - \esp(X) \sum_y y \sum_x p_{XY}(x,y) + \esp(X) \esp(Y) = \\
          &= \esp(XY) - \esp(Y) \sum_x x p_X(x) - \esp(X) \sum_y y p_Y(y) + \esp(X) \esp(Y) = \\
          &= \esp(XY) - \esp(X) \esp(Y) - \esp(X) \esp(Y) + \esp(X) \esp(Y) = \esp(XY) - \esp(X) \esp(Y) \qedhere
        \end{split} \]
      \end{proof}

      \begin{prop}
        Si $X$ e $Y$ son variables aleatorias independientes, $\cov(X,Y) = 0$. La recíproca no es cierta en general.
      \end{prop}
      \begin{proof}
        Es inmediato a partir del hecho de que si $X$ e $Y$ son independientes, $\esp(XY) = \esp(X) \esp(Y)$.
      \end{proof}

      \begin{pro}
        Sean $X$ e $Y$ dos variables aleatorias discretas o continuas, y sean $a$ y $b$ números reales. Entonces
        \[ \var(aX + bY) = a^2 \var(X) + b^2 \var(Y) + 2ab \cov(X,Y) \]
      \end{pro}
      \begin{proof}
        \[ \begin{split}
          \var(aX + bY) &= \esp \left( [(aX + bY) - \esp(aX + bY)]^2 \right) = \\
          &= \esp \left( [(aX + bY) - (a \esp(X) + b \esp(Y))]^2 \right) = \\
          &= \esp \left( [(aX - a \esp(X)) + (bY - b\esp(Y))]^2 \right) = \\
          &= \esp \left( [a (X - \esp(X))]^2 \right) + \esp \left( [b (Y - \esp(Y))]^2 \right) + 2 \esp[ab (X - \esp(X)) (Y - \esp(Y))] = \\
          &= a^2 \var(X) + b^2 V(Y) + 2 ab \cov(X,Y)
        \end{split} \]
      \end{proof}

      \begin{defi}
        Sean $X$ e $Y$ dos v.a. con varianza positiva. El \deft{coeficiente de correlación} entre $X$ e $Y$ se define como
        \[ \rho(X,Y) = \frac{\cov(X,Y)}{\sigma_X \sigma_Y} \]
        siendo $\sigma_X$ y $\sigma_Y$ los desvíos estándar de $X$ e $Y$, respectivamente.
      \end{defi}

      \begin{pro} \
        \begin{enumerate}
          \item Sean $a$, $b$, $c$ y $d$ números reales, $a \neq 0$, $c \neq 0$, y $X$ e $Y$ dos v.a. cualesquiera con varianza positiva. Entonces
          \[ \rho(aX + b, cY + d) = \operatorname{sg}(ac) \rho(X,Y) \]
          donde $\operatorname{sg}$ denota la función signo.

          \item $-1 \leq \rho(X,Y) \leq 1$.

          \item $\vert \rho(X,Y) \vert = 1 \Leftrightarrow Y = aX + b$ con probabilidad 1, para ciertos valores reales $a \neq 0$ y $b$. Observemos que el coeficiente de correlación mide \emph{relación lineal} entre las variables aleatorias.
        \end{enumerate}
      \end{pro}
      \begin{proof} \
        \begin{enumerate}
          \item Por un lado,
          \[ \begin{split}
            \cov(aX + b,cY + d) &= \esp[(aX + b)(cY + d)] - \esp(aX + b) \esp(cY + d) = \\
            &= \esp[acXY + adX + bcY + bd ] - (a \esp(X) + b)(c \esp(Y) + d) = \\
            &= ac \esp(XY) + ad \esp(X) + bc \esp(Y) \\
            &\qquad \qquad + bd - [ac \esp(X) \esp(Y) + ad \esp(X) + bc \esp(Y) + bd] = \\
            &= ac [\esp(XY) - \esp(X) \esp(Y)] = ac \cov(X,Y)
          \end{split} \]

          Por otra parte, $\sigma_{aX + b} = \vert a \vert \sigma_X$ y $\sigma_{cX + d} = \vert c \vert \sigma_X$, y por lo tanto
          \[ \rho(aX + b,cY + d) = \frac{\cov(aX + b, cY + d)}{\sigma_{aX + b} \sigma_{cY + d}} = \frac{ac \cov(X,Y)}{\vert a \vert \vert c \vert \sigma_X  \sigma_Y} = \operatorname{sg}(ac) \rho(X,Y) \qedhere \]

          \item Consideremos la función real
          \[ q(t) = \esp[(Y - \esp(Y)) - t(X - \esp(X))]^2 = \esp[V - tW]^2 \]
          siendo $V = Y - \esp(Y)$, $W = X - \esp(X)$. Como
          \[ q(t) = \esp[V - tW]^2 = \esp(V^2) - 2t \esp(VW) + t^2 \esp(W^2) \]
          es una función cuadrática en $t$ que toma valores mayores o iguales que 0, o su gráfico no corta al eje $t$ o lo hace en un solo punto. Es decir que la ecuación $q(t) = 0$ tiene a lo sumo una raíz, y por lo tato su discriminante es menor o igual que 0. En nuestro caso, el discriminante es
          \[ 4[\esp(VW)]^2 - 4 \esp(V^2) \esp(W^2) \]
          y, por lo tanto,
          \[ 4[\esp(VW)]^2 - 4 \esp(V^2) \esp(W^2) \leq 0 \Leftrightarrow \frac{[\esp(VW)]^2}{\esp(V^2) \esp(W^2)} \leq 1 \Leftrightarrow\]
          \[ \frac{[\esp((X - \esp(X))(Y - \esp(Y)))]^2}{\esp[(Y - \esp(Y))^2] \esp[(X - \esp(X))^2]} \leq 1 \Leftrightarrow [\rho(X,Y)]^2 \leq 1 \Leftrightarrow -1 \leq \rho(X,Y) \leq 1 \qedhere \]

          \item \begin{itemize}
            \item[$(\Rightarrow)$] Si $\rho^2(X,Y) = 1$, volviendo a la demostración de la propiedad anterior, existe $q_0$ tal que $q(t_0) = 0$, es decir, que $\esp[V - t_0 W]^2 = 0$.
            Pero además, $E(V - t_0 W) = 0$, pues $V$ y $W$ tienen esperanza igual a 0. Entonces, la v.a. $V - t_0 W$ tiene varianza cero y por lo tanto es constante con probabilidad 1, es decir
            \[ \proba(V - t_0 W = \esp(V - t_0 W)) = \proba(V - t_0 W = 0) = 1 \]
            o sea
            \[ \proba((Y - \esp(Y)) - t(X - \esp(X)) = 0) = 1 \Leftrightarrow \proba(Y = t_0X + \esp(Y) - t_0 \esp(X)) = 1\]

            Entonces, $Y = aX + b$ con probabilidad 1, siendo $a = t_0$ y $b = \esp(Y) - t_0 \esp(X)$. Falta verificar que $a = t_0 \neq 0$. En efecto, si $t_0$ fuese igual a 0, esto implicaría que $\esp(V^2) = \var(Y) = 0$.

            \item[$(\Leftarrow)$] Sea $Y = aX + b$ para ciertos valores $a \neq 0$ y $b$. Entonces
            \[ \begin{split}
              \rho(X,Y) &= \rho(X, aX+b) = \frac{\cov(X, aX + b)}{\sigma_X \sigma_{aX + b}} = \frac{\esp(X(aX + b)) - \esp(X) \esp(aX + b)}{\sigma_X \vert a \vert \sigma_X} = \\
              &= \frac{a \esp(X^2) + b \esp(X) - a[\esp(X)]^2 - b \esp(X))}{\vert a \vert \sigma_X^2} = \\
              &= \frac{a(\esp(X^2) - [\esp(X)]^2)}{\vert a \vert \sigma_X^2} = \frac{a \sigma_X^2}{\vert a \vert \sigma_X^2} = \pm 1 \qedhere
            \end{split} \]
          \end{itemize}
        \end{enumerate}
      \end{proof}

  \subsection{Extensión a más de dos dimensiones}

    \subsubsection{Vectores aleatorios discretos}

      \begin{defi}
        Sean $X_1, \dots, X_k$ variables aleatorias discretas. La \deft{función de probabilidad conjunta} del vector aleatorio $(X_1, \dots, X_k)$ se define como
        \[ p_{X_1, \dots, X_k} (x_1, \dots, x_k) = \proba(X_1 = x_1, \dots, X_k = x_k) \]
        y, dado cualquier conjunto $A \subseteq \mathbb{R}^k$,
        \[ \proba((X_1, \dots, X_k) \in A) = \mathop{\sum \dots \sum}_{(x_1, \dots, x_k) \in A} p_{X_1, \dots, X_k} (x_1, \dots, x_k) \]
      \end{defi}

      Esta función satisface las siguientes propiedades
      \begin{itemize}
        \item $p_{X_1, \dots, X_k} (x_1, \dots, x_k) \geq 0 \ \foralle (x_1, \dots, x_k)$.
        \item $\sum_{x_1} \dots \sum_{x_k} p_{X_1, \dots, X_k} (x_1, \dots, x_k) = 1$.
      \end{itemize}

      En forma similar al caso bidimensional, pueden definirse las funciones de probabilidad marginal. Por ejemplo, la función de probabilidad marginal de $X_1$ está dada por
      \[ p_{X_1}(x_1) = \sum_{x_2} \dots \sum_{x_k} p_{X_1, \dots, X_k} (x_1, \dots, x_k) \]
      y la función de probabilidad marginal de $(X_1,X_2)$ está dada por
      \[ p_{X_1,X_2}(x_1,x_2) = \sum_{x_3} \dots \sum_{x_k} p_{X_1, \dots, X_k} (x_1, \dots, x_k) \]

      \paragraph{Distribución multinomial.}

      \begin{defi}
        Un \emph{experimento multinomial} es aquel en el que se repite $n$ veces una experiencia, de forma tal que en cada repetición hay $k \geq 2$ resultados posibles, cada uno de los cuales ocurre con probabilidad $p_i$ ($1 \leq i \leq k$) constante a lo largo de todas las repeticiones.
        Si definimos las variables aleatorias
        \[ X_i : \text{número de veces que ocurre el resultado $i$} \]
        para $1 \leq i \leq k$, decimos que el vector aleatorio $(X_1, \dots, X_k)$ tiene \deft{distribución conjunta multinomial} con parámetros $n$, $p_1, \dots, p_k$, y lo notamos $(X_1, \dots, X_n) \dist{M}(n,p_1,\dots,p_k)$.
      \end{defi}

      Su función de probabilidad conjunta está dada por
      \[ p_{X_1,\dots,X_k}(x_1,\dots,x_k) = \begin{cases}
        \displaystyle \frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k p_i^{x_i} & \text{si $0 \leq x_i \leq n \ \foralle i$, $\sum_{i=1}^k x_i = n$} \\
        0 & \text{en otro caso}
      \end{cases} \]

      \begin{obs}
        La distribución marginal de $X_i$ es binomial de parámetros $n$ y $p_i$ para todo $1 \leq i \leq k$. En general, las marginales de una distribución multinomial son binomiales o multinomiales.
      \end{obs}

    \subsubsection{Vectores aleatorios continuos}

      \begin{defi}
        El vector aleatorio $(X_1,\dots,X_k)$ es continuo si existe una función $f_{X_1,\dots,X_k} : \mathbb{R}^k \to \mathbb{R}_{\geq 0}$, denominada \deft{función de densidad conjunta}, tal que
        \[ \proba((X_1,\dots,X_k) \in A) = \int\dots\int_A f_{X_1,\dots,X_k}(x_1,\dots,x_k) \,dx_1 \,\dots \,dx_k \qquad \foralle A \subseteq \mathbb{R}^k\]
      \end{defi}

      Esta función satisface las siguientes propiedades
      \begin{itemize}
        \item $f_{X_1, \dots, X_k} (x_1, \dots, x_k) \geq 0 \ \foralle (x_1, \dots, x_k)$.
        \item $\int_{-\infty}^{+\infty} \dots \int_{-\infty}^{+\infty} f_{X_1, \dots, X_k} (x_1, \dots, x_k) \,dx_1 \,\dots \,dx_k = 1$.
      \end{itemize}

      En forma similar al caso bidimensional, pueden definirse las funciones de densidad marginal. Por ejemplo, la función de densidad marginal de $X_1$ está dada por
      \[ f_{X_1}(x_1) = \int_{-\infty}^{+\infty} \dots \int_{-\infty}^{+\infty} f_{X_1, \dots, X_k} (x_1, \dots, x_k) \,dx_2 \,\dots \,dx_k \]
      y la función de probabilidad marginal de $(X_1,X_2)$ está dada por
      \[ f_{X_1,X_2}(x_1,x_2) = \int_{-\infty}^{+\infty} \dots \int_{-\infty}^{+\infty} f_{X_1, \dots, X_k} (x_1, \dots, x_k) \,dx_3 \,\dots \,dx_k \]

    \subsubsection{Independencia de variables aleatorias}

      \begin{defi}
        $X_1,\dots,X_k$ son variables aleatorias \deft{independientes} si y solo si
        \begin{itemize}
          \item $p_{X_1,\dots,X_k}(x_1,\dots,x_k) = \prod_{i=1}^k p_{X_i}(x_i) \ \foralle (x_1,\dots,x_k)$ en el caso discreto.
          \item $f_{X_1,\dots,X_k}(x_1,\dots,x_k) = \prod_{i=1}^k f_{X_i}(x_i) \ \foralle (x_1,\dots,x_k)$, salvo a lo sumo en un conjunto de probabilidad cero, en el caso continuo.
        \end{itemize}
      \end{defi}

    \subsubsection{Distribución de la suma de variables aleatorias independientes}

      \begin{pro}
        Sean $X$ e $Y$ dos v.a. independientes. Entonces, la función generadora de momentos de la suma $X + Y$ es el producto de las funciones generadoras de momentos de $X$ e $Y$, es decir
        \[ M_{X + Y}(t) = M_X(t) M_Y(t) \]
      \end{pro}
      \begin{proof}
        En el caso continuo, tenemos que, si $X$ e $Y$ son v.a. independientes
        \[ \begin{split}
          M_{X + Y}(t) &= \esp \left(e^{t(X + Y)} \right) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} e^{t(x + y)} f_{XY}(x,y) \,dx \,dy = \\
          &= \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} e^{tx} e^{ty} f_X(x) f_Y(y) \,dx \,dy = \int_{-\infty}^{+\infty} e^{tx} f_X(x) \,dx \int_{-\infty}^{+\infty} e^{ty} f_Y(y) \,dy = \\
          &= \esp \left(e^{tX} \right) \esp \left(e^{tY} \right) = M_X(t) M_Y(t)
        \end{split} \]
        La demostración en el caso discreto es similar.
      \end{proof}

      \begin{obs}
        Es inmediato verificar que, si $X_1, \dots, X_n$ son v.a. independientes,
        \[ M_{X_1 + \dots + X_n}(t) = \prod_{i=1}^n M_{x_i}(t) \]
      \end{obs}

      A partir del resultado anterior, puede conocerse la distribución de la suma o de combinaciones lineales de ciertas variables aleatorias independientes, dado que la función generadora de momentos determina la distribución de la v.a.

      \begin{enumerate}
        \item Si $X_1, \dots, X_n$ son v.a. independientes tales que $X_i \dist{Bi}(n_i,p)$, entonces
        \[ \sum_{i=1}^n X_i \dist{Bi}\left( \sum_{i=1}^n n_i, p \right) \]
        En particular, si $X_i \dist{Bi}(1,p) \ \foralle i$, entonces $\sum_{i=1}^n X_i \dist{Bi}(n,p)$.

        \item Si $X_1, \dots, X_n$ son v.a. independientes tales que $X_i \dist{\poisson}(\lambda_i)$, entonces
        \[ \sum_{i=1}^n X_i \dist{\poisson}\left( \sum_{i=1}^n \lambda_i \right) \]

        \item Si $X_1, \dots, X_n$ son v.a. independientes tales que $X_i \dist{G}(p)$, entonces
        \[ \sum_{i=1}^n X_i \dist{BN}(n,p) \]

        \item Si $X_1, \dots, X_n$ son v.a. independientes tales que $X_i \dist{\exponen}(\lambda)$, entonces
        \[ \sum_{i=1}^n X_i \dist{\Gamma}(n,\lambda) \]

        \item Si $X_1, \dots, X_n$ son v.a. independientes tales que $X_i \dist{\Gamma}(n_i,\lambda)$, entonces
        \[ \sum_{i=1}^n X_i \dist{\Gamma}\left( \sum_{i=1}^n n_i, \lambda \right) \]

        \item Si $X_1, \dots, X_n$ son v.a. independientes tales que $X_i \dist{N}(\mu_i,\sigma_i^2)$, y $a_1,\dots,a_n$ son números reales, entonces
        \[ \sum_{i=1}^n a_i X_i \dist{N}\left( \sum_{i=1}^n a_i \mu_i, \sum_{i=1}^n a_i^2 \sigma_i^2 \right) \]
        En particular, si $X_1,\dots,X_n$ son v.a. independientes e idénticamente distribuidas tales que $X_i \dist{N}(\mu,\sigma^2) \ \foralle i$, entonces
        \[ \overline{X} = \frac{\sum_{i=1}^n X_i}{n} \dist{N}\left( \mu, \frac{\sigma^2}{n} \right) \qquad \text{y} \quad T = \sum_{i=1}^n X_i \dist{N}(n \mu,n \sigma^2) \]
      \end{enumerate}

    \subsubsection{Sumas y promedios de variables aleatorias}

      \begin{pro}
        Sean $X_1, \dots, X_n$ variables aleatorias cualesquiera, y $a_1,\dots,a_n$ números reales. Entonces
        \[ \esp\left( \sum_{i=1}^n a_i X_i \right) = \sum_{i=1}^n a_i \esp(X_i) \]
        \[ \var\left( \sum_{i=1}^n a_i X_i \right) = \sum_{i=1}^n a_i^2 \var(X_i) + 2 \sum_{i < j} a_i a_j \cov(X_i,X_j) \]
      \end{pro}
      \begin{proof}
        La expresión para la esperanza puede ser probada mediante inducción en $n$. El caso $n = 2$ ya fue demostrado anteriormente. Supongamos ahora que la expresión es cierta para $n = k$ y probémosla para $n = k + 1$.
        \[ \esp \left( \sum_{i=1}^{k+1} a_i X_i \right) = \esp \left( \sum_{i=1}^k a_i X_i + a_{k+1} X_{k+1} \right) = \esp (Y + a_{k+1} X_{k+1}) \]
        siendo $Y = \sum_{i=1}^k a_i X_i$. Como para $n = 2$ la igualdad se cumple, se obtiene
        \[ \esp \left( \sum_{i=1}^{k+1} a_i X_i \right) = \esp(Y + a_{k+1} X_{k+1}) = \esp(Y) + a_{k+1} \esp(X_{k+1}) = \esp \left( \sum_{i=1}^k a_i X_i \right) + a_{k+1} \esp(X_{k+1}) \]
        y, utilizando la hipótesis inductiva,
        \[ \esp \left( \sum_{i=1}^{k+1} a_i X_i \right) = \sum_{i=1}^k a_i \esp(X_i) + a_{k+1} \esp(X_{k+1}) = \sum_{i=1}^{k+1} a_i \esp(X_i) \]
        como queríamos demostrar.

        Probemos ahora la expresión correspondiente a la varianza.
        \[ \begin{split}
          \var \left( \sum_{i=1}^n a_i X_i \right) &= \cov \left( \sum_{i=1}^n a_i X_i, \sum_{i=1}^n a_i X_i \right) = \\
          &= \esp \left( \sum_{i=1}^n a_i X_i \cdot \sum_{j=1}^n a_j X_j \right) - \esp \left( \sum_{i=1}^n a_i X_i \right) \esp \left( \sum_{j=1}^n a_j X_j \right) = \\
          &= \esp \left( \sum_{i=1}^n \sum_{j=1}^n a_i a_j X_i X_j \right) - \left( \sum_{i=1}^n a_i \esp(X_i) \right) \left( \sum_{j=1}^n a_j \esp(X_j) \right) = \\
          &= \left( \sum_{i=1}^n \sum_{j=1}^n a_i a_j \esp (X_i X_j) \right) - \sum_{i=1}^n \sum_{j=1}^n a_i a_j \esp(X_i) \esp(X_j) = \\
          &= \sum_{i=1}^n \sum_{j=1}^n a_i a_j \left( \esp (X_i X_j) - \esp(X_i) \esp(X_j) \right) = \sum_{i=1}^n \sum_{j=1}^n a_i a_j \cov(X_i, X_j)
        \end{split} \]

        Teniendo en cuenta que si $i = j$, $\cov(X_i, X_i) = \var(X_i)$ y que $\cov(X_i, X_j) = \cov(X_j, X_i)$, obtenemos el resultado que queríamos demostrar.
      \end{proof}

      \begin{corol}
        Sean $X_1,\dots,X_n$ variables aleatorias independientes, y $a_1,\dots,a_n$ números reales. Entonces
        \[ \esp\left( \sum_{i=1}^n a_i X_i \right) = \sum_{i=1}^n a_i \esp(x_i) \qquad \text{y} \qquad \var\left( \sum_{i=1}^n a_i X_i \right) = \sum_{i=1}^n a_i^2 \var(X_i)\]
      \end{corol}

      \begin{corol}
        Sean $X_1,\dots,X_n$ variables aleatorias independientes e idénticamente distribuidas, con $\esp(X_i) = \mu$ y $\var(X_i) = \sigma^2$ $\foralle i = 1, \dots, n$, y $a_1,\dots,a_n$ números reales. Entonces
        \[ \esp\left( \sum_{i=1}^n a_i X_i \right) = \mu \sum_{i=1}^n a_i \qquad \text{y} \qquad \var\left( \sum_{i=1}^n a_i X_i \right) = \sigma^2 \sum_{i=1}^n a_i^2 \]
      \end{corol}

      \begin{prop}
        Sean $X_1,\dots,X_n$ variables aleatorias independientes e idénticamente distribuidas, con $\esp(X_i) = \mu$ y $\var(X_i) = \sigma^2$ $\foralle i = 1, \dots, n$. Entonces
          \[ \esp\left( \sum_{i=1}^n X_i \right) = n \mu \qquad \text{y} \qquad \var\left( \sum_{i=1}^n X_i \right) = n \sigma^2 \]
          \[ \esp\left( \overline{X} \right) = \esp\left( \frac{\sum_{i=1}^n X_i}{n} \right) = \mu \qquad \text{y} \qquad \var\left( \overline{X} \right) = \var\left( \frac{\sum_{i=1}^n X_i}{n} \right) = \frac{\sigma^2}{n} \]
      \end{prop}

  \subsection{Desigualdad de Chebyshev}
    \begin{pro}[Desigualdad de Márkov]
      Sea $X$ una v.a. cualquiera que solo toma valores no negativos. Entonces,
      \[ \foralle \varepsilon > 0, \qquad \proba(X \geq \varepsilon) \leq \frac{\esp(X)}{\varepsilon} \]
    \end{pro}

    \begin{proof}
      Dado $\varepsilon > 0$, sea la v.a.
      \[ I = \begin{cases}
        1 & \text{si $X \geq \varepsilon$} \\
        0 & \text{en otro caso}
      \end{cases} \]

      Notemos que, dado que $X \geq 0$,
      \[ I \leq \frac{X}{\varepsilon} \]

      Tomando esperanzas en la desigualdad anterior, resulta
      \[ \esp(I) \leq \frac{\esp(X)}{\varepsilon} \]

      Teniendo en cuenta que $\esp(I) = \proba(X \geq a)$, se obtiene el resultado que queríamos probar.
    \end{proof}

    \begin{pro}[Desigualdad de Chebyshev]
      Sea $X$ una v.a. con $\esp(X) = \mu$ y $\var(X) = \sigma^2 < \infty$. Entonces
      \[ \foralle \varepsilon > 0, \qquad \proba(\vert X - \mu \vert \geq \varepsilon) \leq \frac{\sigma^2}{\varepsilon^2} \]
    \end{pro}
    \begin{proof}
      Dado que $(X - \mu)^2$ es una v.a. no negativa, podemos aplicar la desigualdad de Márkov, obteniendo
      \[ \proba((X - \mu)^2 \geq \varepsilon^2) \leq \frac{\esp \left((X - \mu)^2 \right)}{\varepsilon^2}\]
      lo cual, teniendo en cuenta que $ (X - \mu)^2 \geq \varepsilon^2 \Leftrightarrow \vert X - \mu \vert \geq \varepsilon $, equivale a
      \[ \qquad \proba(\vert X - \mu \vert \geq \varepsilon) \leq \frac{\sigma^2}{\varepsilon^2} \qedhere \]
    \end{proof}
    \begin{proof} [Demostración alternativa]
      En el caso continuo,
      \[ \begin{split}
        \sigma^2 &= \esp \left( (X - \mu)^2 \right) = \int_{-\infty}^{+\infty} (x - \mu)^2 f_X(x) \,dx = \\
        &= \int_{\lbrace X / \vert X - \mu \vert \geq \varepsilon \rbrace} (x - \mu)^2 f_X(x) \,dx + \int_{\lbrace X / \vert X - \mu \vert < \varepsilon \rbrace} (x - \mu)^2 f_X(x) \,dx \geq \\
        &\geq \int_{\lbrace X / \vert X - \mu \vert \geq \varepsilon \rbrace} (x - \mu)^2 f_X(x) \,dx \geq \int_{\lbrace X / \vert X - \mu \vert \geq \varepsilon \rbrace} \varepsilon^2 f_X(x) \,dx = \varepsilon^2 \proba(\vert X - \mu \vert \geq \varepsilon)
      \end{split} \]
      Entonces $\frac{\sigma^2}{\varepsilon^2} \geq \proba(\vert X - \mu \vert \geq \varepsilon)$, como queríamos demostrar.
    \end{proof}

    \begin{obs}
      La desigualdad de Chebyshev provee una cota para la probabilidad de un evento descripto en términos de una variable aleatoria que no depende de la distribución, sino solo de la esperanza y la varianza de la v.a.

      Sin embargo, esta cota puede ser grosera, o incluso no informativa si, por ejemplo, $\varepsilon^2 \leq \sigma^2$.
    \end{obs}

    \subparagraph{Formas equivalentes de la desigualdad de Chebyshev.}
    \begin{itemize}
      \item $\foralle \varepsilon > 0, \quad \proba(\vert X - \mu \vert < \varepsilon) \geq 1 - \frac{\sigma^2}{\varepsilon^2}$.
      \item $\foralle k > 1, \quad \proba(\vert X - \mu \vert \geq k \sigma) \leq \frac{1}{k^2}$.
      \item $\foralle k > 1, \quad \proba(\vert X - \mu \vert < k \sigma) \geq 1 - \frac{1}{k^2}$.
    \end{itemize}
    Las últimas dos formas muestran cómo el desvío estándar mide el grado de concentración de la distribución alrededor de $\mu = \esp(X)$.

  \subsection{Ley de los Grandes Números}
    \begin{defi}
      Sea $(X_n)$, $n \geq 1$, una sucesión de variables aleatorias. Diremos que $X_n$ \deft{converge en probabilidad} a la variable aleatoria $X$, y lo notaremos $X_n \tiende{p} X$, si
      \[ \lim_{n \to \infty} \proba(\vert X_n - X \vert > \varepsilon) = 0 \qquad \foralle \varepsilon > 0 \]
    \end{defi}

    \begin{lgn}
      Sean $X_1, X_2, \dots$ variables aleatorias independientes e idénticamente distribuidas (muestra aleatoria), con $\esp(X) = \mu$ y $\var(X) = \sigma^2 < \infty$. Entonces
      \[ \overline{X}_n \tiende{p} \mu \]
      siendo $ \overline{X}_n = \frac{\sum_{i=1}^n X_i}{n}$ el promedio muestral.
    \end{lgn}
    \begin{proof}
      Sabemos que $\esp(\overline{X}_n) = \mu$ y $\var(\overline{X}_n) = \frac{\sigma^2}{n}$. Aplicando la desigualdad de Chebyshev
      \[ \proba(\vert \overline{X}_n - \mu \vert \geq \varepsilon) \leq \frac{\var(\overline{X}_n)}{\varepsilon^2} = \frac{\sigma^2}{n \varepsilon^2} \qquad \foralle \varepsilon > 0 \]
      y, por lo tanto
      \[ \lim_{n \to \infty} \proba(\vert \overline{X}_n - \mu \vert \geq \varepsilon) \leq \lim_{n \to \infty} \frac{\sigma^2}{n \varepsilon^2} = 0 \qquad \forall \varepsilon > 0 \]

      Luego, $ \overline{X}_n \tiende{p} \mu$, como queríamos demostrar.
    \end{proof}

    \begin{pro}[Versión Bernoulli de la Ley de los Grandes Números]
      Consideremos $n$ repeticiones independientes de un experimento aleatorio, y un suceso $A$ con probabilidad $p$ constante a lo largo de las $n$ repeticiones. Si llamamos $n_A$ al total de veces que ocurre $A$ en las $n$ repeticiones, y $f_A = \frac{n_A}{n}$ a la frecuencia relativa de $A$, tenemos que
      \[ f_A \tiende{p} p \]
      es decir
      \[ \lim_{n \to \infty} \proba(\vert f_A - p \vert > \varepsilon) = 0 \qquad \foralle \varepsilon > 0 \]
    \end{pro}
    \begin{proof}
      Como $n_A \dist{Bi}(n,p)$ con $p = \proba(A)$, entonces $\esp(n_A) = n p$ y $V(n_A) = n p (1 - p)$. Luego
      \[ \esp(f_A) = \esp \left( \frac{n_A}{n} \right) = p \qquad \text{y} \qquad \var(f_A) = \var \left( \frac{n_A}{n} \right) = \frac{p (1 - p)}{n} \]

      Aplicando la desigualdad de Chebyshev
      \[ \proba(\vert f_A - p \vert \geq \varepsilon) \leq \frac{\var(f_A)}{\varepsilon^2} = \frac{p (1 - p)}{n \varepsilon^2} \qquad \foralle \epsilon > 0 \]

      Luego
      \[ \lim_{n \to \infty} \proba(\vert f_A - p \vert \geq \varepsilon) \leq \lim_{n \to \infty} \frac{p (1 - p)}{n \varepsilon^2} = 0 \qquad \forall \varepsilon > 0 \]
      como queríamos demostrar.
    \end{proof}

  \subsection{Teorema Central del Límite}

    \begin{teo}[Central del Límite]
      Sean $X_1,X_2,\dots$ v.a. independientes e idénticamente distribuidas, con $\esp(X_i) = \mu$ y $\var(X_i) = \sigma^2 < \infty$ $\foralle i$. Entonces, si $n$ es suficientemente grande
      \[ \frac{T - n\mu}{\sqrt{n} \sigma} \distt{(a)}{N}(0,1) \qquad \qquad \frac{\sqrt{n} (\overline{X} - \mu)}{\sigma} \distt{(a)}{N}(0,1) \]
      o, dicho de otro modo
      \[ \frac{T - n\mu}{\sqrt{n} \sigma} \tiende{d} Z\dist{N}(0,1) \qquad \qquad \frac{\sqrt{n} (\overline{X} - \mu)}{\sigma} \tiende{d} Z\dist{N}(0,1) \]
      siendo $T = \sum_{i=1}^n X_i$ y $\overline{X} = \frac{T}{n}$, y
      donde la convergencia en distribución ($\tiende{d}$) se interpreta en el siguiente sentido
      \[ \proba\left( \frac{T - n\mu}{\sqrt{n} \sigma} \leq a \right) \cong \Phi(a) \qquad \qquad \proba\left( \frac{\sqrt{n} (\overline{X} - \mu)}{\sigma} \leq a \right) \cong \Phi(a) \]
      es decir, que las funciones de distribución convergen a la función de distribución normal estándar.
    \end{teo}

    \begin{proof}
      Lo demostraremos bajo la hipótesis de que la función generadora de momentos de $X_i$, $M_{X_i}(t)$, existe y es finita.

      Supongamos inicialmente que $\mu = 0$ y $\sigma^2 = 1$. En este caso, la función generadora de momentos de $\frac{T}{\sqrt{n}}$ está dada por
      \[ M_{\frac{T}{\sqrt{n}}}(t) = M_T \left( \frac{t}{\sqrt{n}} \right) = M_{\sum_{i=1}^n X_i} \left( \frac{t}{\sqrt{n}} \right) = \prod_{i=1}^n M_{X_i} \left( \frac{t}{\sqrt{n}} \right)  = \left( M_{X_i} \left(\frac{t}{\sqrt{n}} \right) \right)^n \]
      por ser las $X_i$ independientes. Sea $L(u) = \ln(M_{X_i}(u))$, entonces
      \[ \begin{split}
        L(0) &= \ln(M_{X_i} (0)) = \ln(1) = 0 \\
        L^\prime(0) &= \left. \frac{\partial \ln(M_{X_I}(u))}{\partial u} \right\vert_{u=0} = \left. \frac{M^\prime_{X_i}(u)}{M_{X_i}(u)} \right\vert_{u=0} = \frac{M^\prime_{X_i}(0)}{M_{X_i}(0)} = \frac{\mu}{1} = \mu = 0 \\
        L^{\prime\prime}(0) &= \left. \frac{\partial^2 \ln(M_{X_i}(u))}{\partial u^2} \right\vert_{u=0} = \left. \frac{M^{\prime\prime}_{X_i}(u) M_{X_i}(u) - [M^\prime_{X_i}(u)]^2}{[M_{X_i}(u)]^2} \right\vert_{u=0} = \\
        &= \frac{M^{\prime\prime}_{X_i}(0) M_{X_i}(0) - [M^\prime_{X_i}(0)]^2}{[M_{X_i}(0)]^2} = \esp(X_i^2) = 1
      \end{split} \]

      Ahora, para poder probar el teorema, demostraremos que $M_{\frac{T}{\sqrt{n}}} \to e^{\frac{t^2}{2}}$, o, equivalentemente, que $n L \left( \frac{t}{\sqrt{n}} \right) \to \frac{t^2}{2}$. Aplicando la regla de L'Hospital dos veces
      \[ \begin{split}
        \lim_{n \to \infty} \frac{L\left(\frac{t}{\sqrt{n}} \right)}{\frac{1}{n}} &= \lim_{n \to \infty} \frac{- L^\prime \left(\frac{t}{\sqrt{n}} \right) t n^{-\frac{3}{2}}}{-2 n^{-2}} = \lim_{n \to \infty} \frac{L^\prime \left( \frac{t}{\sqrt{n}} \right) t}{2 n^{- \frac{1}{2}}} = \\
        &= \lim_{n \to \infty} \frac{-L^{\prime\prime} \left( \frac{t}{\sqrt{n}} \right) t^2 n^{-\frac{3}{2}}}{-2n^{-\frac{3}{2}}} = \lim_{n \to \infty} \frac{L^{\prime\prime} \left( \frac{t}{\sqrt{n}} \right) t^2}{2} = \frac{t^2}{2}
      \end{split} \]
      por lo tanto, hemos probado el Teorema Central del Límite para $\mu = 0$ y $\sigma^2 = 1$. El caso general resulta considerando las v.a. estandarizadas, $\frac{X_i - \mu}{\sigma} = X^*_i$.
    \end{proof}

    \subsubsection{Aplicaciones del Teorema Central del Límite}

      \paragraph{Aproximación de la distribución binomial por la normal.}
      Sea $X \dist{Bi}(n,p)$, entonces $X$ es el número de éxitos en $n$ repeticiones de un experimento binomial con probabilidad de éxito igual a $p$, y $\frac{X}{n}$ es la proporción muestral de éxitos. Si definimos las variables aleatorias
      \[ X_i = \begin{cases}
        1 & \text{si se obtuvo éxito en la $i$-ésima repetición} \\
        0 & \text{si se obtuvo fracaso en la $i$-ésima repetición}
      \end{cases} \]
      para $i = 1,\dots,n$, estas v.a. son independientes, con $X_i \dist{Bi}(1,p) \ \foralle i$ y $\sum_{i=1}^n X_i = X$.

      Aplicando el Teorema Central del Límite, si $n$ es suficientemente grande,
      \[ X \distt{(a)}{N}(np, np(1 - p)) \qquad \qquad \frac{X}{n} \distt{(a)}{N}\left( p,\frac{p(1-p)}{n} \right) \]

      Se considera que la aproximación es buena si $np \geq 5$ y $n(1-p) \geq 5$.

      \subparagraph{Corrección por continuidad.}
      Cuando se aproxima una distribución discreta por una continua, como es el caso de la aproximación de la distribución binomial por la normal, es necesario efectuar una corrección. En general, cuando la v.a. es discreta y $x_i - x_{i-1} = 1$, la corrección se realiza en la forma:
      \[ \proba(X \leq a) = \proba(X \leq a + 0,5) \]
      \[ \proba(X \geq a) = \proba(X \geq a - 0,5) \]

      \paragraph{Aproximación de la distribución de Poisson por la normal.}
      Sean $X_1, \dots, X_n$ v.a. independientes e idénticamente distribuidas, con distribución de Poisson de parámetro $(\lambda)$. Entonces
      \[ \sum_{i=1}^n X_i \dist{\poisson}(n \lambda) \]

      Por lo tanto, cualquier v.a. con distribución de Poisson con parámetro suficientemente grande puede ser aproximada por la distribución normal.

      \paragraph{Aproximación de la distribución gamma por la normal.}
      Sean $X_1, \dots, X_n$ v.a. independientes e idénticamente distribuidas, tales que $X_i \dist{\Gamma}(n_i,\lambda)$. Entonces
      \[ \sum_{i=1}^n X_i \dist{\Gamma}\left(\sum_{i=1}^n n_i,\lambda \right) \]

      Por lo tanto, cualquier v.a. con distribución $\dists{\Gamma}(\alpha,\lambda)$ con parámetro $\alpha$suficientemente grande puede ser aproximada por la distribución normal.

\section{Inferencia estadística}

  \subsection{Conceptos básicos de una investigación estadística}

    \begin{description}
      \item[Población:] Conjunto total de los sujetos o unidades de análisis de interés en el estudio
      \item[Muestra:] Cualquier subconjunto de sujetos o unidades de análisis de la población en estudio.
      \item[Unidad de análisis o de observación:] Objeto bajo estudio. Puede ser una persona, una familia, un país, una institución o, en general, cualquier objeto.
      \item[Variable:] Cualquier característica de la unidad de observación que interese registrar y que en el momento de ser registrada puede ser transformada en un número.
      \item[Valor de una variable, dato, observación o medición:] Número que describe a la característica de interés en una unidad de observación particular.
      \item[Caso o registro:] Conjunto de mediciones realizadas sobre una unidad de observación.
    \end{description}

    \subsubsection{Medidas de resumen}
      Son medidas de fácil interpretación que reflejan las características más relevantes de los datos provenientes de variables numéricas.

      \paragraph{Medidas de posición o centrado.} ¿Cuál es el valor central o que mejor representa a los datos?

      Supongamos que disponemos de un conjunto de $n$ datos, que representaremos por $x_1, \dots, x_n$.

      \subparagraph{Promedio o media muestral.} $\displaystyle \overline{x} = \frac{\sum_{i=1}^n x_i}{n}$.

      \subparagraph{Mediana muestral.} Sean los estadísticos de orden muestrales $x_{(1)} \leq x_{(2)} \leq \dots \leq x_{(n)}$. Definimos como mediana $\tilde x = \begin{cases}
        \displaystyle x_{(k+1)} & \text{si $n = 2k + 1$} \\
        \displaystyle \frac{x_{(k)} + x_{(k + 1)}}{2} & \text{si $n = 2k$}
      \end{cases}$.

      \subparagraph{Media $\boldsymbol\alpha$-podada.} $\displaystyle \overline{x}_\alpha = \frac{x_{(\lfloor n \alpha \rfloor + 1)} + \dots + x_{(n - \lfloor n \alpha \rfloor)}}{n - 2 \lfloor n \alpha \rfloor}$.

      \paragraph{Medidas de dispersión o variabilidad.} ¿Cuán dispersos están los datos? ¿Cuán cercanos son los datos al valor típico?

      \subparagraph{Rango muestral.} $\displaystyle R(x) = \max(x_i) - \min(x_i)$.

      \subparagraph{Varianza muestral.} $\displaystyle S^2 = \frac{\sum_{i=1}^n (x_i - \overline{x})^2}{n - 1}$.

      \subparagraph{Desvío estándar muestral.} $S = \sqrt{S^2}$.

      \subparagraph{Distancia intercuartil.} $d_I = \text{cuartil superior} - \text{cuartil inferior} = x_{0.75} - x_{0.25}$, donde $x_\alpha$, $0 \leq \alpha \leq 1$, es el $100 \alpha$-ésimo percentil del la muestra, es decir, el valor por debajo del cual se encuentra el $100 \alpha \%$ de la muestra ordenada.

      \subparagraph{Distancia entre cuartos.} $d_C = \text{cuarto superior} - \text{cuarto inferior}$, donde los cuartos inferior y superior son la mediana de la primera y la segunda mitad de la muestra ordenada, respectivamente (en caso de que el tamaño de la muestra sea impar, se extienden ambas mitades con la mediana de la muestra completa).

      \subparagraph{Desvío absoluto mediano.} $MAD = \operatorname{mediana}(\vert x_i - \tilde x \vert)$.

  \subsection{Estimación puntual}

    La mayoría de las distribuciones de probabilidad dependen de cierto número de parámetros. El objetivo de la \emph{estimación puntual} es usar una muestra para obtener números que representen lo mejor posible a los verdaderos valores de los parámetros de interés.

    Supongamos que se selecciona una muestra de tamaño $n$ de una población. Antes de obtener la muestra, la primera observación puede ser considerada una v.a. $X_1$, la segunda una v.a. $X_2$, etc. Por lo tanto, antes de obtener la muestra denotaremos $X_1, X_2, \dots, X_n$ a las observaciones y, una vez obtenida la muestra, denotaremos $x_1, x_2, \dots, x_n$ a los valores observados.

    \begin{defi}
      Dado un parámetro $\theta$, un \deft{estimador puntal} del parámetro es un valor que se obtiene a partir de alguna función de la muestra y que puede considerarse representativo del parámetro. Lo denotaremos $\hat \theta$.
    \end{defi}

    \subsubsection{Método de estimación por momentos}

      \begin{defi}
        Dada una muestra aleatoria $X_1, \dots, X_n$, se denomina \deft{momento muestral} de orden $k$ a
        \[ \frac{\sum_{i = 1}^n X_i^k}{n} \]
      \end{defi}

      \begin{defi}
        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución cuya función de probabilidad puntual o función de densidad depende de $m$ parámetros $\theta_1, \dots, \theta_m$. Los \deft{estimadores de momentos} de estos parámetros son los valores $\hat \theta_1, \dots, \hat \theta_m$ que se obtienen igualando $m$ momentos poblacionales (los correspondientes la distribución cuyos parámetros se busca estimar) con los correspondientes momentos muestrales. Se obtienen, en general, resolviendo el sistema de ecuaciones
        \[ \frac{\sum_{i=1}^n X_i^k}{n} = \esp(X^k) \qquad \qquad k = 1, \dots, m \]
      \end{defi}

    \subsubsection{Método de estimación de máxima verosimilitud}

      \begin{defi}
        Sean $X_1, \dots, X_n$ v.a. con función de probabilidad conjunta $p_X(x_1,\dots,x_n)$ o función de densidad conjunta $f_X(x_1,\dots,x_n)$ que depende de $m$ parámetros $\theta_1, \dots, \theta_m$. Si $(x_1, \dots, x_n)$ son los valores observados, la \deft{función de verosimilitud} de la muestra es la función $L : \mathbb{R}^m \to \mathbb{R}_{\geq 0}$ que se obtiene al considerar a la función de probabilidad o de densidad conjunta como función de los parámetros $\theta_1, \dots, \theta_m$, y se denota $L(\theta_1,\dots,\theta_m)$.
      \end{defi}

      \begin{defi}
        Los \deft{estimadores de máxima verosimilitud} (EMV) de $\theta_1, \dots, \theta_m$ son los valores $\hat \theta_1, \dots, \hat \theta_m$ que maximizan la función de verosimilitud, es decir
        \[ L(\hat \theta_1, \dots, \hat \theta_m) \geq L(\tilde\theta_1, \dots, \tilde\theta_m) \qquad \foralle \tilde\theta_1, \dots, \tilde\theta_m \]

        La forma general de los EMV se obtiene reemplazando los valores observados $x_i$ por las variables aleatorias $X_i$.
      \end{defi}

      \begin{prop}[Invarianza de los EMV]
        Si $\hat \theta$ es el EMV de un parámetro $\theta$ y $h$ es una función inyectiva con dominio en el rango de valores posibles de $\theta$, entonces el EMV de $h(\theta)$ es $h(\hat \theta)$.
      \end{prop}

    \subsubsection{Propiedades de los estimadores}

      \begin{defi}
        Un estimador puntual $\hat \theta$ del parámetro $\theta$, es \deft{insesgado} si
        \[ \esp_\theta(\hat \theta) = \theta \qquad \foralle \theta \]
        Si $\hat \theta$ no es insesgado, se denomina \deft{sesgo} de $\hat \theta$ a $b(\hat \theta) = \esp_\theta(\hat \theta) - \theta$.
      \end{defi}

      \begin{defi}
        Un estimador puntual $\hat \theta$ del parámetro $\theta$, basado en una muestra $X_1, \dots, X_n$ es \deft{asintóticamente insesgado} si
        \[ \lim_{n \to \infty} \esp_\theta(\hat \theta) = \theta \qquad \foralle \theta \]
      \end{defi}

      \paragraph{Principio de estimación insesgada de mínima varianza.} Entre todos los estimadores insesgados de $\theta$, conviene elegir el de menor varianza. Este estimador se denomina IMVU (insesgado de mínima varianza uniformemente).

      \begin{teo}
        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{N}(\mu,\sigma^2)$. Entonces $\overline{X}$ es estimador IMVU de $\mu$.
      \end{teo}

      \begin{defi}
        El \deft{error estándar} de un estimador $\hat \theta$ es su desvío estándar, es decir
        \[ \sigma_{\hat \theta} = \sqrt{\var_\theta(\hat \theta)} \]

        En caso de depender de parámetros desconocidos, estos se reemplazan por un estimador y se obtiene el error estándar estimado.
      \end{defi}

      \begin{defi}
        Sea $\hat \theta$ un estimador de $\theta$. Su error cuadrático medio es
        \[ \operatorname{ECM}_\theta(\hat \theta) = \esp_\theta \left[ (\hat \theta - \theta)^2 \right] \]

        Si el estimador $\hat \theta$ es insesgado, el error cuadrático medio es igual a la varianza del estimador.
      \end{defi}

      \begin{pro}
        \[ \operatorname{ECM}_\theta(\hat \theta) = \var_\theta(\hat \theta) + \left[ b(\hat \theta)^2 \right] \]
        siendo $b(\hat \theta) = \esp_\theta(\hat \theta) - \theta$ el sesgo del estimador.
      \end{pro}
      \begin{proof}
        \[ \begin{split}
          \operatorname{ECM}_\theta(\hat \theta) &= \esp_\theta \left[ (\hat \theta - \theta)^2 \right] = \esp_\theta \left[ (\hat \theta - \esp_\theta(\hat \theta) + \esp_\theta(\hat \theta) - \theta)^2 \right] = \\
          &= \esp_\theta \left[ (\hat \theta - \esp_\theta(\hat \theta))^2 + (\esp_\theta(\hat \theta) - \theta)^2 + 2 (\hat \theta - \esp_\theta(\hat \theta)) (\esp_\theta(\hat \theta) - \theta) \right] = \\
          &= \esp_\theta \left[ (\hat \theta - \esp_\theta(\hat \theta))^2 \right] + \esp_\theta \left[ (\esp_\theta(\hat \theta) - \theta)^2 \right] + 2 \esp_\theta \left[ (\hat \theta - \esp_\theta(\hat \theta)) (\esp_\theta(\hat \theta) - \theta) \right]
        \end{split} \]

        Usando que la esperanza de una v.a. es una constante y la esperanza de una constante es igual a esta, se obtiene
        \[ \operatorname{ECM}_\theta(\hat \theta) = \underbrace{\esp_\theta \left[ (\hat \theta - \esp_\theta(\hat \theta))^2 \right]}_{\var_\theta(\hat \theta)} + \underbrace{(\esp_\theta(\hat \theta) - \theta)^2}_{(b(\hat \theta))^2} + 2 (\esp_\theta(\hat \theta) - \theta) \underbrace{(\esp_\theta(\hat \theta) - \esp_\theta(\hat \theta))}_{0} \]
        y, por lo tanto, $\operatorname{ECM}_\theta(\hat \theta) = \var_\theta(\hat \theta) + [b(\hat \theta)]^2$, como queríamos demostrar.
      \end{proof}

      \paragraph{Principio de estimación de menor error cuadrático medio.} Dados dos o más estimadores del parámetro $\theta$, conviene elegir el de menor error cuadrático medio.

      \begin{defi}
        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución que depende de un parámetro $\theta$, y sea $\hat \theta_n$ un estimador puntual de $\theta$ basado en esa muestra. Diremos que $\lbrace \hat \theta_n \rbrace$ es una sucesión \deft{consistente}, o más brevemente, que $\hat \theta_n$ es un estimador consistente de $\theta$, si
        \[ \hat \theta_n \tiende{p} \theta \]
        es decir, si $\foralle \varepsilon > 0, \lim_{n \to \infty} \proba(\vert \hat \theta_n - \theta \vert > \varepsilon) = 0$.
      \end{defi}

      \begin{pro}
        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución que depende de un parámetro $\theta$, y sea $\hat \theta_m$ un estimador de $\theta$ basado en esta muestra. Si
        \begin{enumerate}
          \item $\lim_{n \to \infty} \esp_\theta(\hat \theta_n) = \theta $ (es decir, si el estimador es asintóticamente insesgado), y
          \item $\lim_{n \to \infty} \var_\theta(\hat \theta_n) = 0$
        \end{enumerate}
        entonces $\hat \theta_n$ es un estimador consistente de $\theta$.
      \end{pro}
      \begin{proof}
        Si el estimador es insesgado, la demostración es inmediata a partir de la desigualdad de Chebyshev. No daremos la demostración en el caso general.
      \end{proof}

  \subsection{Intervalos de confianza}
    \begin{defi}
      Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución que depende de un parámetro $\theta$. Dadas dos funciones de la muestra $a(X_1,\dots,X_n)$ y $b(X_1,\dots,X_n)$, tales que
      \[ \proba(a(X_1,\dots,X_n) \leq \theta \leq b(X_1,\dots,X_n)) = 1 - \alpha \]
      con $\alpha$ pequeño, el intervalo $[a(X_1,\dots,X_n), b(X_1,\dots,X_n)]$ se denomina \deft{intervalo de confianza} de nivel 1 - $\alpha$ para el parámetro $\theta$.
    \end{defi}

    \subsubsection{Intervalos de confianza para los parámetros de una distribución normal}

      \begin{defi}
        Sean dos v.a. $Z \dist{N}(0,1)$ y $U\dist{\chi}_n^2 = \dists{\Gamma}\left( \frac{n}{2},\frac{1}{2} \right)$ independientes, entonces
        \[ T = \frac{Z}{\sqrt{\frac{U}{n}}} \dist{t}_n \]
        tiene \deft{distribución t de Student} con $n$ grados de libertad.
      \end{defi}

      Esta distribución está tabulada para diferentes valores de $n$. Su distribución es simétrica con respecto al 0 y tiene forma de campana, pero con colas más pesadas que la distribución normal estándar. Cuando $n$ tiende a infinito, la distribución t de Student tiende a la distribución normal estándar.

      \begin{pro}
        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{N}(\mu,\sigma^2)$. Entonces
        \begin{enumerate}
          \item $\displaystyle \overline{X} \dist{N}\left( \mu, \frac{\sigma^2}{n} \right) \Leftrightarrow \sqrt{n} \frac{\overline{X} - \mu}{\sigma} \dist{N}(0,1)$.
          \item $\displaystyle \frac{(n - 1) S^2}{\sigma^2} \dist{\chi}_{n - 1}^2$, donde $S^2$ es la varianza muestral.
          \item $\overline{X}$ y $S^2$ son independientes.
          \item $\displaystyle \sqrt{n} \frac{\overline{X} - \mu}{S} \dist{t}_{n-1}$.
        \end{enumerate}
      \end{pro}
      \begin{proof} \
        \begin{enumerate}
          \item[1.] Ya hemos visto que cualquier combinación lineal de v.a. normales independientes es normal, y el promedio es una combinación lineal particular.
          \item[2 y 3.] Están fuera del alcance de este curso.
          \item[4.] Resulta de 1, 2 y 3, pues
          \[ \sqrt{n} \frac{\overline{X} - \mu}{\sigma} \dist{N}(0,1) \qquad \text{y} \qquad \frac{(n - 1) S^2}{\sigma^2} \dist{\chi}^2_{n - 1} \]
          son v.a. independientes. Entonces, por la definición de la distribución t de Student
          \[ \frac{\sqrt{n} \frac{\overline{X} - \mu}{\sigma}}{\sqrt{\frac{(n - 1) S^2}{\sigma^2 (n - 1)}}} = \sqrt{n} \frac{\overline{X} - \mu}{S} \dist{t}_{n-1} \qedhere \]
        \end{enumerate}
      \end{proof}

      A partir de los resultados anteriores, podemos construir intervalos de confianza para los parámetros de una distribución normal.

      \paragraph{Media de una distribución normal con varianza conocida.} Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{N}(\mu,\sigma_0^2)$, con varianza $\sigma_0^2$ conocida. Entonces
      \[ \sqrt{n} \frac{\overline{X} - \mu}{\sigma_0} \dist{N} (0,1) \Rightarrow \proba \left( -z_{\frac{\alpha}{2}} \leq \sqrt{n} \frac{\overline{X} - \mu}{\sigma_0} \leq z_{\frac{\alpha}{2}} \right) = 1 - \alpha \]
      de donde se deduce el siguiente intervalo de confianza de nivel $1 - \alpha$ para $\mu$
      \[ \left[ \overline{X} - z_{\frac{\alpha}{2}} \frac{\sigma_0}{\sqrt{n}}, \overline{X} + z_{\frac{\alpha}{2}} \frac{\sigma_0}{\sqrt{n}} \right] \]

      \paragraph{Media de una distribución normal con varianza desconocida.} Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{N}(\mu,\sigma^2)$. Entonces
      \[ \sqrt{n} \frac{\overline{X} - \mu}{S} \dist{t}_{n-1} \Rightarrow \proba \left( -t_{n - 1, \frac{\alpha}{2}} \leq \sqrt{n} \frac{\overline{X} - \mu}{S} \leq t_{n - 1, \frac{\alpha}{2}} \right) = 1 - \alpha \]
      de donde se deduce el siguiente intervalo de confianza de nivel $1 - \alpha$ para $\mu$
      \[ \left[ \overline{X} - t_{n - 1, \frac{\alpha}{2}} \frac{S}{\sqrt{n}}, \overline{X} + t_{n - 1, \frac{\alpha}{2}} \frac{S}{\sqrt{n}} \right] \]

      \paragraph{Varianza de una distribución normal con media conocida.} Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{N}(\mu_0,\sigma^2)$, con media $\mu_0$ conocida. Entonces
      \[ \frac{X_i - \mu_0}{\sigma} \dist{N}(0,1) \quad \foralle 1 \leq i \leq n \Rightarrow \left( \frac{X_i - \mu_0}{\sigma} \right)^2 \dist{\chi}_1^2 = \dists{\Gamma}\left( \frac{1}{2}, \frac{1}{2} \right) \quad \foralle 1 \leq i \leq n \]
      Como además las variables aleatorias son independientes,
      \[ \sum_{i = 1}^n \left( \frac{X_i - \mu_0}{\sigma} \right)^2 \dist{\chi}_n^2 = \dists{\Gamma}\left( \frac{n}{2}, \frac{1}{2} \right) \Rightarrow \proba\left( \chi_{n, 1 - \frac{\alpha}{2}}^2 \leq \frac{\sum_{i=1}^n (X_i - \mu_0)^2}{\sigma^2} \leq \chi_{n, \frac{\alpha}{2}}^2 \right) = 1 -\alpha \]
      de donde se obtiene el siguiente intervalo de confianza de nivel $1 - \alpha$ para $\sigma^2$
      \[ \left[ \frac{\sum_{i = 1}^n (X_i - \mu_0)^2}{\chi_{n,\frac{\alpha}{2}}^2} , \frac{\sum_{i = 1}^n (X_i - \mu_0)^2}{\chi_{n,1 - \frac{\alpha}{2}}^2} \right] \]

      \paragraph{Varianza de una distribución normal con media desconocida.} Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{N}(\mu,\sigma^2)$. Entonces
      \[ \frac{(n - 1) S^2}{\sigma^2} \dist{\chi}_{n-1}^2 \Rightarrow \proba\left( \chi^2_{n - 1, 1 - \frac{\alpha}{2}} \leq \frac{(n - 1) S^2}{\sigma^2} \leq \chi^2_{n - 1, \frac{\alpha}{2}} \right) = 1 - \alpha \]
      de donde se deduce el siguiente intervalo de confianza de nivel $1 - \alpha$ para $\sigma^2$
      \[ \left[ \frac{(n-1) S^2}{\chi^2_{n - 1, \frac{\alpha}{2}}} , \frac{(n-1) S^2}{\chi^2_{n - 1, 1 - \frac{\alpha}{2}}} \right] \]

    \subsubsection{Método general para obtener intervalos de confianza}

      \begin{defi}
        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución que depende de un parámetro $\theta$. Una función \deft{pivote} una función $T(X_1,\dots,X_n,\theta)$, cuya distribución no depende de $\theta$ ni de ningún otro parámetro desconocido. Si existe un pivote para $\theta$, entonces existen dos valores $a$ y $b$ tales que
        \[ \proba(a \leq T(X_1,\dots,X_n,\theta) \leq b) = 1 - \alpha \]
        de donde es posible obtener un intervalo de confianza de nivel $1 - \alpha$ para $\theta$.
      \end{defi}

    \subsubsection{Intervalos de confianza de nivel asintótico}

      En muchos problemas no es posible encontrar intervalos de confianza de nivel exacto $1 - \alpha$, o son de muy difícil construcción, ya sea porque no es posible encontrar una función pivote que no dependa del parámetro, o porque no se conoce la distribución exacta de la función pivote. En estos casos, cuando la muestra es grande, es posible obtener intervalos de confianza de nivel aproximado.

      \begin{defi}
        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución que depende de un parámetro $\theta$. Dadas dos sucesiones $\lbrace a_n(X_1,\dots,X_n) \rbrace$ y $\lbrace b_n(X_1,\dots,X_n) \rbrace$, tales que
        \[ \lim_{n \to \infty} \proba(a_n(X_1,\dots,X_n) \leq \theta \leq b_n(X_1,\dots,X_n)) = 1 - \alpha \]
        la sucesión de intervalos $[a_n(X_1,\dots,X_n), b_n(X_1,\dots,X_n)]$ es una sucesión de \deft{intervalos de confianza de nivel asintótico} $1 - \alpha$ para el parámetro $\theta$. También se dice que, si $n$ es suficientemente grande, el intervalo $[a_n(X_1,\dots,X_n), b_n(X_1,\dots,X_n)]$ tiene nivel aproximado $1 - \alpha$.
      \end{defi}

      \paragraph{Intervalo de confianza de nivel aproximado para la media de una distribución cualquiera.}

        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución con media $\mu$ y varianza $\sigma^2 < \infty$.

        Sabemos que $\overline{X}$ es un estimador insesgado y consistente de $\mu$. Si bien no conocemos su distribución exacta, sabemos que
        \[ \sqrt{n} \frac{\overline{X} - \mu}{\sigma} \tiende{d} \dists{N}(0,1) \]

        Si $\sigma^2$ es conocido, puede usarse esta función como pivote para obtener un intervalo de nivel aproximado. Si $\sigma^2$ es desconocido, podemos aplicar la siguiente propiedad

        \begin{prop}
          \[ \left. \begin{array}{l} Y_n \tiende{d} Y \\ U_n \tiende{p} a \end{array} \right\rbrace \quad \Longrightarrow \quad U_n Y_n \tiende{d} a Y \]
        \end{prop}

        Como $S$ es un estimador consistente de $\sigma$, $S \tiende{p} \sigma$, y por lo tanto $\frac{\sigma}{S} \tiende{p} 1$. Luego,
        \[ \left. \begin{array}{l}
        \displaystyle \sqrt{n} \frac{\overline{X} - \mu}{\sigma} \tiende{d} \dists{N}(0,1) \\
        \displaystyle \frac{\sigma}{S} \tiende{p} 1
        \end{array} \right\rbrace \quad \Longrightarrow \quad \sqrt{n} \frac{\overline{X} - \mu}{\sigma} \tiende{d} \dists{N}(0,1) \]
        si $n$ es lo suficientemente grande
        \[ \sqrt{n} \frac{\overline{X} - \mu}{\sigma} \distt{(a)}{N}(0,1) \]

        A partir de este resultado, para $n$ suficientemente grande
        \[ \proba \left( -z_{\frac{\alpha}{2}} \leq \sqrt{n} \frac{\overline{X} - \mu}{S} \leq z_{\frac{\alpha}{2}} \right) \cong 1 - \alpha \]
        de donde se deduce el siguiente intervalo de confianza de nivel aproximado $1 - \alpha$ para $\mu$
        \[ \left[ \overline{X} - z_{\frac{\alpha}{2}} \frac{S}{\sqrt{n}}, \overline{X} + z_{\frac{\alpha}{2}} \frac{S}{\sqrt{n}} \right] \]

      \paragraph{Intervalo de confianza de nivel asintótico para una proporción.}

        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{Bi}(1,p)$. Entonces $X = \sum_{i=1}^n X_i \dist{Bi}(n,p)$. Queremos construir un intervalo de confianza de nivel asintótico $1 - \alpha$ para $p$.

        Por el Teorema Central del Límite, tenemos que
        \[ \hat p = \frac{X}{n} = \frac{\sum_{i=1}^n X_i}{n} \distt{(a)}{N}\left( p,\frac{p(1 - p)}{n} \right) \]
        y, por lo tanto
        \[ \proba \left( -z_{\frac{\alpha}{2}} \leq \frac{\frac{X}{n} - p}{\sqrt{\frac{p(1 - p)}{n}}} \leq z_{\frac{\alpha}{2}} \right) \cong 1 - \alpha \]

        Hay dos formas de obtener un intervalo de confianza para $p$ a partir de esta expresión.

        \begin{enumerate}
          \item Como, por la Ley de los Grandes Números, $\frac{X}{n} = \frac{\sum_{i=1}^{n} X_i}{n} \tiende{p} p$, podemos aplicar la propiedad enunciada antes, reemplazando $p$ por su estimador $\frac{X}{n}$ en el denominador del pivote. Entonces
          \[ \proba \left( \frac{X}{n} - z_{\frac{\alpha}{2}} \sqrt{\frac{\frac{X}{n} \left( 1 - \frac{X}{n} \right)}{n}} \leq p \leq \frac{X}{n} + z_{\frac{\alpha}{2}} \sqrt{\frac{\frac{X}{n} \left( 1 - \frac{X}{n} \right)}{n}} \right) \cong 1 - \alpha \]
          obteniendo un intervalo para $p$ de nivel aproximado $1 - \alpha$.
          \item Podemos reescribir la expresión de la forma
          \[ \proba \left( \left| \frac{\frac{X}{n} - p}{\sqrt{\frac{p(1 - p)}{n}}} \right| \leq z_{\frac{\alpha}{2}} \right) \cong 1 - \alpha \qquad \Leftrightarrow \qquad \proba \left( \frac{\left( \frac{X}{n} - p \right)^2}{\frac{p(1 - p)}{n}} \leq z_{\frac{\alpha}{2}}^2 \right) \cong 1 - \alpha \]

          Observemos que
          \[ \frac{\left( \frac{X}{n} - p \right)^2}{\frac{p(1 - p)}{n}} \leq z_{\frac{\alpha}{2}}^2 \qquad \Leftrightarrow \qquad \left( \frac{X}{n} - p \right)^2 \leq z_{\frac{\alpha}{2}}^2 \frac{p(1 - p)}{n} \]
          \[ \Leftrightarrow \qquad \left( \frac{X}{n} \right)^2 - 2 p \frac{X}{n} + p^2 - z_{\frac{\alpha}{2}} \frac{p(1 - p)}{n} \leq 0 \]
          \[ \Leftrightarrow \qquad p^2 \left( 1 + \frac{z_{\frac{\alpha}{2}}}{n} \right) - p \left( \frac{2X}{n} + \frac{z_{\frac{\alpha}{2}}}{n} \right) + \left( \frac{X}{n} \right)^2 \leq 0 \]

          Buscando las raíces de esta ecuación de segundo grado, que llamaremos $\hat p_1$ y $\hat p_2$, obtenemos un intervalo para $p$ de nivel aproximado $1 - \alpha$ dado por
          \[ [\hat p_1, \hat p_2] \]

        \end{enumerate}

  \subsection{Tests de hipótesis}

    \begin{defi}
      Un \deft{test de hipótesis} es una regla que permite decidir, basándose en una muestra, entre dos hipótesis referidas a un parámetro de una distribución. La hipótesis que implica que no hay cambio con respecto a la situación inicial se denomina \emph{hipótesis nula} y se designa $H_0$. La segunda hipótesis se denomina \emph{hipótesis alternativa} y se designa $H_1$.
      El test se basa en un \emph{estadístico}, que es una función o función de la muestra, y en una \emph{zona de rechazo}, que es un conjunto de valores del estadístico para los cuales se rechaza la hipótesis $H_0$ en favor de $H_1$.
    \end{defi}

    \begin{defi}
      En un test que contrasta las hipótesis $H_0$ y $H_1$, llamamos \deft{nivel de significación} del test, y denotamos $\alpha$, a la probabilidad de cometer un error de tipo I, es decir, de rechazar $H_0$ cuando es verdadera.

      Por otra parte, denotamos $\beta$ a la probabilidad de cometer un error de tipo II, es decir, de no rechazar $H_0$ cuando es falsa.
    \end{defi}

    \begin{defi}
      Dados un test de hipótesis y una muestra aleatoria, llamamos \deft{p-valor} de la muestra a la probabilidad, bajo el supuesto de que $H_0$ es verdadera, de obtener un valor del estadístico al menos tan extremo como el que fue observado.
    \end{defi}

    \begin{defi}
      La \deft{función de potencia} de un test, $\pi(\mu)$, es la probabilidad de rechazar la hipótesis nula cuando el verdadero valor del parámetro es $\mu$. Permite obtener una expresión general para los dos tipos de errores, pues
      \[ \pi(\mu) = \begin{cases}
      \alpha(\mu) & \text{si $\mu \in H_0$} \\
      1 - \beta(\mu) & \text{si $\mu \in H_1$}
      \end{cases} \]
      donde $\alpha(\mu)$ y $\beta(\mu)$ denotan las probabilidades de error de tipo I y II, respectivamente, cuando el verdadero valor del parámetro es $\mu$.
    \end{defi}

    \paragraph{Tipos de hipótesis a testear.} La forma de la región de rechazo dependerá de la hipótesis alternativa a testear.
    \subparagraph{Hipótesis unilaterales.}
    \[ H_0 : \theta = \theta_0 \text{ (o $\theta \leq \theta_0$)} \qquad \text{vs.} \qquad H_1 : \theta > \theta_0 \]
    \[ H_0 : \theta = \theta_0 \text{ (o $\theta \geq \theta_0$)} \qquad \text{vs.} \qquad H_1 : \theta < \theta_0 \]
    \subparagraph{Hipótesis bilaterales.}
    \[ H_0 : \theta = \theta_0 \qquad \text{vs.} \qquad H_1 : \theta \neq \theta_0 \]

      \subsubsection{Test de hipótesis para los parámetros de una distribución normal}

        \paragraph{Media de una distribución normal con varianza conocida.}
          Supongamos que $\sigma^2 = \sigma^2_0$ es conocida, y consideremos la siguientes hipótesis
          \begin{enumerate}
            \item $ H_0 : \mu = \mu_0 \text{ (o $\mu \leq \mu_0$)} \qquad \text{vs.} \qquad H_1 : \mu > \mu_0 $.
            \item $ H_0 : \mu = \mu_0 \text{ (o $\mu \geq \mu_0$)} \qquad \text{vs.} \qquad H_1 : \mu < \mu_0 $.
            \item $ H_0 : \mu = \mu_0 \qquad \text{vs.} \qquad H_1 : \mu \neq \mu_0 $.
          \end{enumerate}

          \subparagraph{Estadístico del test.}
          \[ T = \sqrt{n} \frac{\overline{X} - \mu_0}{\sigma_0} \]

          Bajo $H_0 : \mu = \mu_0$, $T \dist{N}(0,1)$.

          \subparagraph{Región de rechazo.} Según la hipótesis alternativa, está dada en cada caso por
          \begin{enumerate}
            \item $T \geq z_\alpha$.
            \item $T \leq - z_\alpha$.
            \item $\vert T \vert \geq z_\frac{\alpha}{2}$.
          \end{enumerate}

          \subparagraph{Función de potencia.} Está dada, en cada caso, por
          \begin{enumerate}
            \item $\displaystyle \pi(\mu) = 1 - \Phi\left( z_\alpha + \frac{\mu_0 - \mu}{\frac{\sigma_0}{\sqrt{n}}} \right)$.
            \item $\displaystyle \pi(\mu) = \Phi\left( - z_\alpha + \frac{\mu_0 - \mu}{\frac{\sigma_0}{\sqrt{n}}} \right)$.
            \item $\displaystyle \pi(\mu) = 1 - \Phi\left( z_{\frac{\alpha}{2}} + \frac{\mu_0 - \mu}{\frac{\sigma_0}{\sqrt{n}}} \right) + \Phi\left( - z_{\frac{\alpha}{2}} + \frac{\mu_0 - \mu}{\frac{\sigma_0}{\sqrt{n}}} \right)$.
          \end{enumerate}

        \paragraph{Media de una distribución normal con varianza desconocida.}
          Supongamos ahora que la varianza es desconocida, y consideremos las mismas hipótesis sobre $\mu$
          \begin{enumerate}
            \item $ H_0 : \mu = \mu_0 \text{ (o $\mu \leq \mu_0$)} \qquad \text{vs.} \qquad H_1 : \mu > \mu_0 $.
            \item $ H_0 : \mu = \mu_0 \text{ (o $\mu \geq \mu_0$)} \qquad \text{vs.} \qquad H_1 : \mu < \mu_0 $.
            \item $ H_0 : \mu = \mu_0 \qquad \text{vs.} \qquad H_1 : \mu \neq \mu_0 $.
          \end{enumerate}

          \subparagraph{Estadístico del test.}
          \[ T = \sqrt{n} \frac{\overline{X} - \mu_0}{S} \]

          Bajo $H_0 : \mu = \mu_0$, $T \dist{t}_{n - 1}$.

          \subparagraph{Región de rechazo.} Según la hipótesis alternativa, está dada en cada caso por
          \begin{enumerate}
            \item $T \geq t_{n - 1,\alpha}$.
            \item $T \leq - t_{n - 1,\alpha}$.
            \item $\vert T \vert \geq t_{n - 1,\frac{\alpha}{2}}$.
          \end{enumerate}

        \paragraph{Varianza de una distribución normal con media desconocida.}
          Consideremos las siguientes hipótesis
          \begin{enumerate}
            \item $ H_0 : \sigma^2 = \sigma^2_0 \text{ (o $\sigma^2 \leq \sigma^2_0$)} \qquad \text{vs.} \qquad H_1 : \sigma^2 > \sigma^2_0 $.
            \item $ H_0 : \sigma^2 = \sigma^2_0 \text{ (o $\sigma^2 \geq \sigma^2_0$)} \qquad \text{vs.} \qquad H_1 : \sigma^2 < \sigma^2_0 $.
            \item $ H_0 : \sigma^2 = \sigma^2_0 \qquad \text{vs.} \qquad H_1 : \sigma^2 \neq \sigma^2_0 $.
          \end{enumerate}

            \subparagraph{Estadístico del test.}
            \[ U = \frac{(n - 1) S^2}{\sigma_0^2} \]

            Bajo $H_0 : \sigma^2 = \sigma^2_0$, $U \dist{\chi}^2_{n - 1}$.

            \subparagraph{Región de rechazo.} Según la hipótesis alternativa, está dada en cada caso por
            \begin{enumerate}
              \item $U \geq \chi^2_{n - 1,\alpha}$.
              \item $U \leq \chi^2_{n - 1,1 - \alpha}$.
              \item $U \geq \chi^2_{n - 1,\frac{\alpha}{2}}$ o $U \leq \chi^2_{n - 1,1 - \frac{\alpha}{2}}$.
            \end{enumerate}

      \subsubsection{Tests de hipótesis de nivel aproximado}

        \paragraph{Test de nivel aproximado para la media de una distribución cualquiera.}

        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución con media $\mu$ y varianza $\sigma^2 < \infty$. Como ya enunciamos anteriormente, $\sqrt{n} \frac{\overline{X} - \mu}{\sigma} \tiende{d} \dists{N}(0,1)$.

        Supongamos que se desea testear a nivel aproximado $\alpha$ alguna de las siguientes hipótesis
        \begin{enumerate}
          \item $ H_0 : \mu = \mu_0 \text{ (o $\mu \leq \mu_0$)} \qquad \text{vs.} \qquad H_1 : \mu > \mu_0 $.
          \item $ H_0 : \mu = \mu_0 \text{ (o $\mu \geq \mu_0$)} \qquad \text{vs.} \qquad H_1 : \mu < \mu_0 $.
          \item $ H_0 : \mu = \mu_0 \qquad \text{vs.} \qquad H_1 : \mu \neq \mu_0 $.
        \end{enumerate}
        y que $n$ es suficientemente grande. Utilizando como estadístico
        \[ T = \sqrt{n} \frac{\overline{X} - \mu_0}{S} \]
        las siguientes regiones de rechazo proveen tests de nivel aproximado $\alpha$ para cada una de las hipótesis
        \begin{enumerate}
          \item $T \geq z_\alpha$.
          \item $T \leq - z_\alpha$.
          \item $\vert T \vert \geq z_\frac{\alpha}{2}$.
        \end{enumerate}

        \paragraph{Test de hipótesis de nivel aproximado para una proporción.}

        Sea $X_1, \dots, X_n$ una muestra aleatoria de una distribución $\dists{Bi}(1,p)$. Entonces $X = \sum_{i=1}^n X_i \dist{Bi}(n,p)$.  Por el Teorema Central del Límite, tenemos que, si $n$ es suficientemente grande
        \[ \frac{\overline{X} - p}{\sqrt{\frac{p (1 - p)}{n}}} \tiende{d} Z \dist{N}(0,1) \]
        siendo $\overline{X}$ la proporción muestral o frecuencia relativa de éxitos.

        Un test de nivel aproximado $\alpha$ para las hipótesis
        \begin{enumerate}
          \item $ H_0 : p = p_0 \qquad \text{vs.} \qquad H_1 : p > p_0 $
          \item $ H_0 : p = p_0 \qquad \text{vs.} \qquad H_1 : p < p_0 $
          \item $ H_0 : p = p_0 \qquad \text{vs.} \qquad H_1 : p \neq p_0 $
        \end{enumerate}
        se basa en el estadístico
        \[ \frac{\overline{X} - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}} \]
        que, bajo $H_0$, tiene distribución aproximada $\dists{N}(0,1)$.

        Las regiones de rechazo están dadas por
        \begin{enumerate}
          \item $\displaystyle \frac{\overline{X} - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}} \geq z_\alpha$.
          \item $\displaystyle \frac{\overline{X} - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}} \leq - z_\alpha$.
          \item $\displaystyle \left| \frac{\overline{X} - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}} \right| \geq z_\frac{\alpha}{2}$.
        \end{enumerate}

      \subsubsection{Relación entre tests de hipótesis bilaterales e intervalos de confianza}

        \begin{pro}
          Sea $IC(X_1,\dots,X_n)$ un intervalo de confianza de nivel $1 - \alpha$ para un parámetro $\theta$, obtenido a partir de una muestra aleatoria $X_1,\dots,X_n$. Consideremos el problema de testear las hipótesis
          \[ H_0 : \theta = \theta_0 \qquad \text{vs.} \qquad H_1 : \theta \neq \theta_0 \]

          El test que rechaza $H_0$ cuando $\theta_0 \notin IC(X_1,\dots,X_n)$ tiene nivel $\alpha$.
        \end{pro}

  \section[Cadenas de Márkov]{Cadenas de Márkov\footnote{Esta sección es un breve resumen del capítulo sobre cadenas de Márkov del libro \emph{A First Course in Probability}, de Sheldon Ross, que aparece en la bibliografía sugerida por la cátedra. Lo incluí dado que en el tema se enseñó en la cursada del segundo cuatrimestre de 2014, aunque no puedo asegurar que los contenidos se correspondan exactamente con los del programa de la materia.}}
    \renewcommand{\arraystretch}{1}

    \begin{defi}
      Consideremos una secuencia de variables aleatorias $X_0, X_1, \dots$, que toman valores en un conjunto $\espm$ finito o infinito numerable. Si interpretamos $X_n$ como el estado de un sistema en el momento $n$, asumiendo que el sistema se encuentra en el estado $i$ en el momento $n$ si $X_n = i$, dicha sucesión es un \emph{proceso estocástico}. Decimos que la secuencia de variables aleatorias es una \deft{cadena de Márkov} si, cada vez que el sistema se encuentra en el estado $i$, existe una probabilidad fija $p_{ij}$ de que el siguiente estado del sistema sea $j$. Es decir, para todo $i_0, \dots, i_{n-1}, i, j$
      \[ \proba(X_{n + 1} = j \mid X_n = i, X_{n - 1} = i_{n - 1}, \dots, X_1 = i_1, X_0 = i_0) = \proba(X_{n + 1} = j \mid X_n = i) = p_{ij} \]

      Los valores $p_{ij}$, $i, j \in \espm$ se denominan \emph{probabilidades de transición} de la cadena de Márkov. Las probabilidades de transición satisfacen
      \[ p_{ij} \geq 0 \quad \foralle i, j \in \espm \qquad \text{y} \qquad \sum_{j \in \espm} p_{ij} = 1 \quad \foralle i \in \espm \]
      y conforman una \emph{matriz de transición}, $P = \left( \begin{array}{c c c}
        p_{00} & p_{01} & \cdots \\
        p_{10} & p_{11} & \\
        \vdots & & \ddots
      \end{array} \right)$.
    \end{defi}

    \begin{pro}[Ecuaciones de Chapman-Kolmogorov]
      En general, definimos las \emph{probabilidades de transición en $n$ pasos} de la cadena de Márkov como
      \[ p_{ij}^{(n)} = \proba(X_{n+m} = j \mid X_m = i) \]

      Las ecuaciones de Chapman-Kolmogorov muestran cómo estas probabilidades pueden ser calculadas
      \[ p_{ij}^{(n)} = \sum_{k \in \espm} p_{ik}^{(r)} p_{kj}^{(n - r)} \qquad \foralle 0 < r < n \]
    \end{pro}
    \begin{proof}
      \[ \begin{split}
        p_{ij}^{(n)} &= \proba(X_n = j \mid X_0 = i) \\
        &= \sum_k \proba(X_n = j, X_r = k \mid X_0 = i) \\
        &= \sum_k \proba(X_n = j \mid X_r = k, X_0 = i) \proba(X_r = k \mid X_0 = i) \\
        &= \sum_k P_{kj}^{(n - r)} p_{ik}^{(r)} \qedhere
      \end{split} \]
    \end{proof}

    Aunque las $p_{ij}^{(n)}$ denotan probabilidades condicionales, podemos usarlas para derivar expresiones para probabilidades incondicionales, condicionando el estado inicial. Por ejemplo
    \[ \proba(X_n = j) = \sum_i \proba(X_n = j \mid X_0 = i) \proba(X_0 = i) = \sum_i p_{ij}^{(n)} \proba(X_0 = i) \]

    \begin{pro}
      Las probabilidades de transición en $n$ pasos de una cadena de Márkov conforman una \emph{matriz de transición en $n$ pasos}, $P^{(n)}$, que es igual a la $n$-ésima potencia de la matriz de transición. Es decir, $P^{(n)} = P^n$.
    \end{pro}
    \begin{proof}
      Lo probaremos por inducción en $n$. Si $n = 1$, no hay nada que probar, puesto que como $p_{ij} = p^{(1)}_{ij} \ \foralle i, j$, $P = P^{(1)}$. Supongamos ahora que la expresión es cierta para $n = m$, y probemos que también vale para $n = m + 1$.
      Los elementos de $P^{(m + 1)}$ son las probabilidades $p_{ij}^{(m + 1)}$. Por las ecuaciones de Chapman-Kolmogorov, con $r = 1$
      \[ \lbrace P^{(m + 1)} \rbrace_{ij} = p_{ij}^{(m + 1)} = \sum_{k \in \espm} p_{ik} p_{kj}^{(m)} \]

      Utilizando la hipótesis inductiva
      \[ \lbrace P^{(m + 1)} \rbrace_{ij} = p_{ij}^{(m + 1)} = \sum_{k \in \espm} \lbrace P \rbrace_{ik} \lbrace P^m \rbrace_{kj} = \lbrace P \cdot P^m \rbrace_{ij} = \lbrace P^{m + 1} \rbrace_{ij} \]

      Luego, los elementos de $P^{(m + 1)}$ y $P^{m + 1}$ son los mismos, es decir, $P^{(m + 1)} = P^{m + 1}$, lo cual completa la demostración.
    \end{proof}

    Para un gran número de cadenas de Márkov, si $n \to \infty$, la probabilidad $P_{ij}^{(n)}$ converge a un valor $\pi_j$ que depende solo de $j$. Es decir, para valores grandes de $n$, la probabilidad de que el sistema se encuentre en el estado $j$ luego de $n$ transiciones es aproximadamente igual a $\pi_j$, independientemente del estado inicial.

    Puede demostrarse que es condición suficiente para que esto suceda que, para algún $n > 0$, $p_{ij}^{(n)} > 0 \ \foralle i, j \in \espm$. Las cadenas de Márkov que satisfacen esta condición se denominan \emph{ergódicas}. Dado que
    \[ p_{ij}^{(n+1)} = \sum_{k \in \espm} P_{ij}^{(n)} P_{kj} \]
    resulta que, para una cadena ergódica, si $n \to \infty$
    \begin{equation} \label{markov-erg-1} \pi_j = \sum_{k \in \espm} \pi_k p_{kj} \end{equation}
    y, como $1 = \sum_{j \in \espm} P_{ij}^{(n)}$, obtenemos que si $n \to \infty$
    \begin{equation} \label{markov-erg-2} \sum_{j \in \espm} \pi_j = 1 \end{equation}
    De hecho, puede probarse que las únicas soluciones no negativas de las ecuaciones \eqref{markov-erg-1} y \eqref{markov-erg-2} son los $\pi_j$, $j \in \espm$. Al vector $\pi = (\pi_1, \pi_2, \dots)$ se lo denomina \emph{medida invariante} de la cadena de Márkov.

    La cantidad $\pi_j$ también es igual a la proporción de tiempo que pasa el sistema, a largo plazo, en el estado $j$. En efecto, sea $P_j$ esta proporción. Entonces, como la proporción de tiempo que el sistema pasa en el estado $k$ es $P_k$, y la cadena pasa del estado $k$ al estado $j$ con probabilidad $p_{kj}$, tenemos que la proporción de tiempo que la cadena de Márkov pasa entrando al estado $j$ desde el estado $k$ es igual a $P_k p_{kj}$. Sumando sobre $k$, tenemos que $P_j = \sum_k P_k p_{kj}$. Como es claro que
    \[ \sum_j P_j = 1 \]
    y dado que los $\pi_j$ son solución única de la ecuación anterior, deducimos que $P_j = \pi_j \ \foralle j \in \espm$.

    Esta interpretación de los valores $\pi_j$ es válida en general, incluso para cadenas no ergódicas.

    De la ecuación \eqref{markov-erg-1}, podemos deducir que la medida invariante de la cadena es un autovector a la izquierda de la matriz de transición con autovalor $1$, es decir, $ \pi P = \pi $. Esto quiere decir que
    \[ \sum_i \pi_i \proba(X_1 = j \mid X_0 = i) = \pi_j \]
    y en general, para todo $n \in \mathbb{N}$, $\pi P^n = \pi$:
    \[ \sum_i \pi_i \proba(X_n = j \mid X_0 = i) = \pi_j \]

    Es decir, si la distribución de $X_0$ es $\pi$, la distribución de $X_n$ es $\pi \ \foralle n \geq 0$.

\end{document}
