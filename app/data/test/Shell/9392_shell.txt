#!/bin/bash
#
# This script is designed to run within the spark-master container
#

source /opt/spark/configure_spark.sh

env

echo "SPARK_MASTER_IP:=$IP"

echo "preparing Spark"
prepare_spark $IP

echo 'export SPARK_JAVA_OPTS="-Dspark.deploy.defaultCores=1"' >> /opt/spark-1.0.0/conf/spark-env.sh

echo "starting Spark Master"
/opt/spark-1.0.0/sbin/start-master.sh

function on_exit() {
	kill -TERM $SPARK_MASTER_PID
	wait $SPARK_MASTER_PID 2>/dev/null
	exit 0
}
trap on_exit INT TERM

while [ 1 ];
do
	tail -f /opt/spark-${SPARK_VERSION}/logs/*.out
        sleep 1
done
