
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{How2ReadData}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{data-analysis-and-machine-learning-introduction-and-representing-data}{%
\section{Data Analysis and Machine Learning: Introduction and
Representing
data}\label{data-analysis-and-machine-learning-introduction-and-representing-data}}

\textbf{Morten Hjorth-Jensen}, Department of Physics, University of Oslo
and Department of Physics and Astronomy and National Superconducting
Cyclotron Laboratory, Michigan State University

Date: \textbf{Dec 6, 2017}

Copyright 1999-2017, Morten Hjorth-Jensen. Released under CC
Attribution-NonCommercial 4.0 license

\hypertarget{what-is-machine-learning}{%
\subsection{What is Machine Learning?}\label{what-is-machine-learning}}

Machine learning is the science of giving computers the ability to learn
without being explicitly programmed. The idea is that there exist
generic algorithms which can be used to find patterns in a broad class
of data sets without having to write code specifically for each problem.
The algorithm will build its own logic based on the data.

Machine learning is a subfield of computer science, and is closely
related to computational statistics. It evolved from the study of
pattern recognition in artificial intelligence (AI) research, and has
made contributions to AI tasks like computer vision, natural language
processing and speech recognition. It has also, especially in later
years, found applications in a wide variety of other areas, including
bioinformatics, economy, physics, finance and marketing.

\hypertarget{types-of-machine-learning}{%
\subsection{Types of Machine Learning}\label{types-of-machine-learning}}

The approaches to machine learning are many, but are often split into
two main categories. In \emph{supervised learning} we know the answer to
a problem, and let the computer deduce the logic behind it. On the other
hand, \emph{unsupervised learning} is a method for finding patterns and
relationship in data sets without any prior knowledge of the system.
Some authours also operate with a third category, namely
\emph{reinforcement learning}. This is a paradigm of learning inspired
by behavioural psychology, where learning is achieved by
trial-and-error, solely from rewards and punishment.

Another way to categorize machine learning tasks is to consider the
desired output of a system. Some of the most common tasks are:

\begin{itemize}
\item
  Classification: Outputs are divided into two or more classes. The goal
  is to produce a model that assigns inputs into one of these classes.
  An example is to identify digits based on pictures of hand-written
  ones. Classification is typically supervised learning.
\item
  Regression: Finding a functional relationship between an input data
  set and a reference data set. The goal is to construct a function that
  maps input data to continuous output values.
\item
  Clustering: Data are divided into groups with certain common traits,
  without knowing the different groups beforehand. It is thus a form of
  unsupervised learning.
\end{itemize}

\hypertarget{different-algorithms}{%
\subsection{Different algorithms}\label{different-algorithms}}

In this course we will build our machine learning approach on a
statistical foundation, with elements from data analysis, stochastic
processes etc before we proceed with the following machine learning
algorithms

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Linear regression and its variants
\item
  Decision tree algorithms, from simpler to more complex ones
\item
  Nearest neighbors models
\item
  Bayesian statistics
\item
  Support vector machines and finally various variants of
\item
  Artifical neural networks
\end{enumerate}

Before we proceed however, there are several practicalities with data
analysis and software tools we would like to present. These tools will
help us in our understanding of various machine learning algorithms.

Our emphasis here is on understanding the mathematical aspects of
different algorithms, however, where possible we will emphasize the
importance of using available software.

\hypertarget{software-and-needed-installations}{%
\subsection{Software and needed
installations}\label{software-and-needed-installations}}

We will make intensive use of python as programming language and the
myriad of available libraries. Furthermore, you will find
IPython/Jupyter notebooks invaluable in your work. You can run
\textbf{R} codes in the Jupyter/IPython notebooks, with the immediate
benefit of visualizing your data.

If you have Python installed (we recommend Python3) and you feel pretty
familiar with installing different packages, we recommend that you
install the following Python packages via \textbf{pip} as 1. pip install
numpy scipy matplotlib ipython scikit-learn mglearn sympy pandas pillow

For Python3, replace \textbf{pip} with \textbf{pip3}.

For OSX users we recommend also, after having installed Xcode, to
install \textbf{brew}. Brew allows for a seamless installation of
additional software via for example 1. brew install python3

For Linux users, with its variety of distributions like for example the
widely popular Ubuntu distribution you can use \textbf{pip} as well and
simply install Python as 1. sudo apt-get install python3 (or python for
pyhton2.7)

etc etc.

\hypertarget{python-installers}{%
\subsection{Python installers}\label{python-installers}}

If you don't want to perform these operations separately, we recommend
two widely used distrubutions which set up all relevant dependencies for
Python, namely 1. \href{https://docs.anaconda.com/}{Anaconda} Anaconda
is an open source distribution of the Python and R programming languages
for large-scale data processing, predictive analytics, and scientific
computing, that aims to simplify package management and deployment.
Package versions are managed by the package management system
\textbf{conda}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \href{https://www.enthought.com/product/canopy/}{Enthought canopy} is
  a Python distribution for scientific and analytic computing
  distribution and analysis environment, available for free and under a
  commercial license.
\end{enumerate}

\hypertarget{installing-r-c-cython-or-julia}{%
\subsection{Installing R, C++, cython or
Julia}\label{installing-r-c-cython-or-julia}}

You will also find it convenient to utilize R. Jupyter/Ipython notebook
allows you run \textbf{R} code interactively in your browser. The
software library \textbf{R} is tuned to statistically analysis and
allows for an easy usage of the tools we will discuss in these texts.

To install \textbf{R} with Jupyter notebook
\href{https://mpacer.org/maths/r-kernel-for-ipython-notebook}{following
the link here}

\hypertarget{installing-r-c-cython-or-julia-1}{%
\subsection{Installing R, C++, cython or
Julia}\label{installing-r-c-cython-or-julia-1}}

For the C++ affecianodas, Jupyter/IPython notebook allows you also to
install C++ and run codes written in this language interactively in the
browser. Since we will emphasize writing many of the algorithms
yourself, you can thus opt for either Python or C++ as programming
languages.

To add more entropy, \textbf{cython} can also be used when running your
notebooks. It means that Python with the Jupyter/IPython notebook setup
allows you to integrate widely popular softwares and tools for
scientific computing. With its versatility, including symbolic
operations, Python offers a unique computational environment. Your
Jupyter/IPython notebook can easily be converted into a nicely rendered
\textbf{PDF} file or a Latex file for further processing.

This never ends. If you use the light mark-up language \textbf{doconce}
you can convert a standard ascii text file into various HTML formats,
ipython notebooks, latex files, pdf files etc.

\hypertarget{introduction-to-jupyter-notebook-and-available-tools}{%
\subsection{Introduction to Jupyter notebook and available
tools}\label{introduction-to-jupyter-notebook-and-available-tools}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{sparse}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{display}
        \PY{n}{eye} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{eye}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{eye}\PY{p}{)}
        \PY{n}{sparse\PYZus{}mtx} \PY{o}{=} \PY{n}{sparse}\PY{o}{.}\PY{n}{csr\PYZus{}matrix}\PY{p}{(}\PY{n}{eye}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{sparse\PYZus{}mtx}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sin}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        \PY{n}{data} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{John}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Anna}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Peter}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linda}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Location}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Nairobi}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Napoli}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{London}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Buenos Aires}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+m+mi}{51}\PY{p}{,} \PY{l+m+mi}{21}\PY{p}{,} \PY{l+m+mi}{34}\PY{p}{,} \PY{l+m+mi}{45}\PY{p}{]}\PY{p}{\PYZcb{}}
        \PY{n}{data\PYZus{}pandas} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{data}\PY{p}{)}
        \PY{n}{display}\PY{p}{(}\PY{n}{data\PYZus{}pandas}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[[ 1.  0.  0.  0.]
 [ 0.  1.  0.  0.]
 [ 0.  0.  1.  0.]
 [ 0.  0.  0.  1.]]
  (0, 0)	1.0
  (1, 1)	1.0
  (2, 2)	1.0
  (3, 3)	1.0

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{How2ReadData_files/How2ReadData_1_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    
    \begin{verbatim}
   Age      Location   Name
0   51       Nairobi   John
1   21        Napoli   Anna
2   34        London  Peter
3   45  Buenos Aires  Linda
    \end{verbatim}

    
    \hypertarget{representing-data-more-examples}{%
\subsection{Representing data, more
examples}\label{representing-data-more-examples}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{sparse}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{display}
        \PY{k+kn}{import} \PY{n+nn}{mglearn}
        \PY{k+kn}{import} \PY{n+nn}{sklearn}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LinearRegression}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{DecisionTreeRegressor}
        \PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{mglearn}\PY{o}{.}\PY{n}{datasets}\PY{o}{.}\PY{n}{make\PYZus{}wave}\PY{p}{(}\PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{line} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1000}\PY{p}{,}\PY{n}{endpoint}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{reg} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{line}\PY{p}{,} \PY{n}{reg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{line}\PY{p}{)}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decision tree}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{regline} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{line}\PY{p}{,} \PY{n}{regline}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{line}\PY{p}{)}\PY{p}{,} \PY{n}{label}\PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Rgression}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.
  warnings.warn(mesg, RuntimeWarning)

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{How2ReadData_files/How2ReadData_3_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{predator-prey-model-from-ecology}{%
\subsection{Predator-Prey model from
ecology}\label{predator-prey-model-from-ecology}}

The population dynamics of a simple predator-prey system is a classical
example shown in many biology textbooks when ecological systems are
discussed. The system contains all elements of the scientific method:

\begin{itemize}
\item
  The set up of a specific hypothesis combined with
\item
  the experimental methods needed (one can study existing data or
  perform experiments)
\item
  analyzing and interpreting the data and performing further experiments
  if needed
\item
  trying to extract general behaviors and extract eventual laws or
  patterns
\item
  develop mathematical relations for the uncovered regularities/laws and
  test these by per forming new experiments
\end{itemize}

\hypertarget{case-study-from-hudson-bay}{%
\subsection{Case study from Hudson
bay}\label{case-study-from-hudson-bay}}

Lots of data about populations of hares and lynx collected from furs in
Hudson Bay, Canada, are available. It is known that the populations
oscillate. Why? Here we start by

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  plotting the data
\item
  derive a simple model for the population dynamics
\item
  (fitting parameters in the model to the data)
\item
  using the model predict the evolution other predator-pray systems
\end{enumerate}

\hypertarget{hudson-bay-data}{%
\subsection{Hudson bay data}\label{hudson-bay-data}}

Most mammalian predators rely on a variety of prey, which complicates
mathematical modeling; however, a few predators have become highly
specialized and seek almost exclusively a single prey species. An
example of this simplified predator-prey interaction is seen in Canadian
northern forests, where the populations of the lynx and the snowshoe
hare are intertwined in a life and death struggle.

One reason that this particular system has been so extensively studied
is that the Hudson Bay company kept careful records of all furs from the
early 1800s into the 1900s. The records for the furs collected by the
Hudson Bay company showed distinct oscillations (approximately 12 year
periods), suggesting that these species caused almost periodic
fluctuations of each other's populations. The table here shows data from
1900 to 1920.

Year

Hares (x1000)

Lynx (x1000)

1900

30.0

4.0

1901

47.2

6.1

1902

70.2

9.8

1903

77.4

35.2

1904

36.3

59.4

1905

20.6

41.7

1906

18.1

19.0

1907

21.4

13.0

1908

22.0

8.3

1909

25.4

9.1

1910

27.1

7.4

1911

40.3

8.0

1912

57

12.3

1913

76.6

19.5

1914

52.3

45.7

1915

19.5

51.1

1916

11.2

29.7

1917

7.6

15.8

1918

14.6

9.7

1919

16.2

10.1

1920

24.7

8.6

\hypertarget{plotting-the-data}{%
\subsection{Plotting the data}\label{plotting-the-data}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{from}  \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot} \PY{k}{as} \PY{n}{plt}
        
        \PY{c+c1}{\PYZsh{} Load in data file}
        \PY{n}{data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{loadtxt}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{src/Hudson\PYZus{}Bay.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delimiter}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{skiprows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Make arrays containing x\PYZhy{}axis and hares and lynx populations}
        \PY{n}{year} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{hares} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{lynx} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{]}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{year}\PY{p}{,} \PY{n}{hares} \PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b\PYZhy{}+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{year}\PY{p}{,} \PY{n}{lynx}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZhy{}o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1900}\PY{p}{,}\PY{l+m+mi}{1920}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{100.0}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Year}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Numbers of hares and lynx }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hares}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Lynx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Population of hares and lynx from 1900\PYZhy{}1920 (x1000)\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hudson\PYZus{}Bay\PYZus{}data.pdf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hudson\PYZus{}Bay\PYZus{}data.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{How2ReadData_files/How2ReadData_5_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{hares-and-lynx-in-hudson-bay-from-1900-to-1920}{%
\subsection{Hares and lynx in Hudson bay from 1900 to
1920}\label{hares-and-lynx-in-hudson-bay-from-1900-to-1920}}

\hypertarget{why-now-create-a-computer-model-for-the-hare-and-lynx-populations}{%
\subsection{Why now create a computer model for the hare and lynx
populations?}\label{why-now-create-a-computer-model-for-the-hare-and-lynx-populations}}

We see from the plot that there are indeed fluctuations. We would like
to create a mathematical model that explains these population
fluctuations. Ecologists have predicted that in a simple predator-prey
system that a rise in prey population is followed (with a lag) by a rise
in the predator population. When the predator population is sufficiently
high, then the prey population begins dropping. After the prey
population falls, then the predator population falls, which allows the
prey population to recover and complete one cycle of this interaction.
Thus, we see that qualitatively oscillations occur. Can a mathematical
model predict this? What causes cycles to slow or speed up? What affects
the amplitude of the oscillation or do you expect to see the
oscillations damp to a stable equilibrium? The models tend to ignore
factors like climate and other complicating factors. How significant are
these?

\begin{itemize}
\item
  We see oscillations in the data
\item
  What causes cycles to slow or speed up?
\item
  What affects the amplitude of the oscillation or do you expect to see
  the oscillations damp to a stable equilibrium?
\item
  With a model we can better \emph{understand the data}
\item
  More important: we can understand the ecology dynamics of
  predator-pray populations
\end{itemize}

\hypertarget{the-traditional-top-down-approach}{%
\subsection{The traditional (top-down)
approach}\label{the-traditional-top-down-approach}}

The classical way (in all books) is to present the Lotka-Volterra
equations:

    \[
\begin{align*}
\frac{dH}{dt} &= H(a - b L)\\
\frac{dL}{dt} &= - L(d - c  H)
\end{align*}
\]

    Here,

\begin{itemize}
\item
  \(H\) is the number of preys
\item
  \(L\) the number of predators
\item
  \(a\), \(b\), \(d\), \(c\) are parameters
\end{itemize}

Most books quickly establish the model and then use considerable space
on discussing the qualitative properties of this \emph{nonlinear system
of ODEs} (which cannot be solved)

\hypertarget{basic-mathematics-notation}{%
\subsection{Basic mathematics
notation}\label{basic-mathematics-notation}}

\begin{itemize}
\item
  Time points: \(t_0,t_1,\ldots,t_m\)
\item
  Uniform distribution of time points: \(t_n=n\Delta t\)
\item
  \(H^n\): population of hares at time \(t_n\)
\item
  \(L^n\): population of lynx at time \(t_n\)
\item
  We want to model the changes in populations, \(\Delta H=H^{n+1}-H^n\)
  and \(\Delta L=L^{n+1}-L^n\) during a general time interval
  \([t_{n+1},t_n]\) of length \(\Delta t=t_{n+1}-t_n\)
\end{itemize}

\hypertarget{basic-dynamics-of-the-population-of-hares}{%
\subsection{Basic dynamics of the population of
hares}\label{basic-dynamics-of-the-population-of-hares}}

The population of hares evolves due to births and deaths exactly as a
bacteria population:

    \[
\Delta H = a \Delta t H^n
\]

    However, hares have an additional loss in the population because they
are eaten by lynx. All the hares and lynx can form \(H\cdot L\) pairs in
total. When such pairs meet during a time interval \(\Delta t\), there
is some small probablity that the lynx will eat the hare. So in fraction
\(b\Delta t HL\), the lynx eat hares. This loss of hares must be
accounted for. Subtracted in the equation for hares:

    \[
\Delta H = a\Delta t H^n - b \Delta t H^nL^n
\]

    \hypertarget{basic-dynamics-of-the-population-of-lynx}{%
\subsection{Basic dynamics of the population of
lynx}\label{basic-dynamics-of-the-population-of-lynx}}

We assume that the primary growth for the lynx population depends on
sufficient food for raising lynx kittens, which implies an adequate
source of nutrients from predation on hares. Thus, the growth of the
lynx population does not only depend of how many lynx there are, but on
how many hares they can eat. In a time interval \(\Delta t HL\) hares
and lynx can meet, and in a fraction \(b\Delta t HL\) the lynx eats the
hare. All of this does not contribute to the growth of lynx, again just
a fraction of \(b\Delta t HL\) that we write as \(d\Delta t HL\). In
addition, lynx die just as in the population dynamics with one isolated
animal population, leading to a loss \(-c\Delta t L\).

The accounting of lynx then looks like

    \[
\Delta L = d\Delta t H^nL^n - c\Delta t L^n
\]

    \hypertarget{evolution-equations}{%
\subsection{Evolution equations}\label{evolution-equations}}

By writing up the definition of \(\Delta H\) and \(\Delta L\), and
putting all assumed known terms \(H^n\) and \(L^n\) on the right-hand
side, we have

    \[
H^{n+1} = H^n + a\Delta t H^n - b\Delta t H^n L^n
\]

    \[
L^{n+1} = L^n + d\Delta t H^nL^n - c\Delta t L^n
\]

    Note:

\begin{itemize}
\item
  These equations are ready to be implemented!
\item
  But to start, we need \(H^0\) and \(L^0\) (which we can get from the
  data)
\item
  We also need values for \(a\), \(b\), \(d\), \(c\)
\end{itemize}

\hypertarget{adapt-the-model-to-the-hudson-bay-case}{%
\subsection{Adapt the model to the Hudson Bay
case}\label{adapt-the-model-to-the-hudson-bay-case}}

\begin{itemize}
\item
  As always, models tend to be general - as here, applicable to ``all''
  predator-pray systems
\item
  The critical issue is whether the \emph{interaction} between hares and
  lynx is sufficiently well modeled by \(\hbox{const}HL\)
\item
  The parameters \(a\), \(b\), \(d\), and \(c\) must be estimated from
  data
\item
  Measure time in years
\item
  \(t_0=1900\), \(t_m=1920\)
\end{itemize}

\hypertarget{the-program}{%
\subsection{The program}\label{the-program}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        
        \PY{k}{def} \PY{n+nf}{solver}\PY{p}{(}\PY{n}{m}\PY{p}{,} \PY{n}{H0}\PY{p}{,} \PY{n}{L0}\PY{p}{,} \PY{n}{dt}\PY{p}{,} \PY{n}{a}\PY{p}{,} \PY{n}{b}\PY{p}{,} \PY{n}{c}\PY{p}{,} \PY{n}{d}\PY{p}{,} \PY{n}{t0}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Solve the difference equations for H and L over m years}
        \PY{l+s+sd}{    with time step dt (measured in years.\PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{n}{num\PYZus{}intervals} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{m}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n}{dt}\PY{p}{)}\PY{p}{)}
            \PY{n}{t} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{n}{t0}\PY{p}{,} \PY{n}{t0} \PY{o}{+} \PY{n}{m}\PY{p}{,} \PY{n}{num\PYZus{}intervals}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
            \PY{n}{H} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{t}\PY{o}{.}\PY{n}{size}\PY{p}{)}
            \PY{n}{L} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{t}\PY{o}{.}\PY{n}{size}\PY{p}{)}
        
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Init:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{H0}\PY{p}{,} \PY{n}{L0}\PY{p}{,} \PY{n}{dt}\PY{p}{)}
            \PY{n}{H}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{H0}
            \PY{n}{L}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{L0}
        
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
                \PY{n}{H}\PY{p}{[}\PY{n}{n}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{H}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{+} \PY{n}{a}\PY{o}{*}\PY{n}{dt}\PY{o}{*}\PY{n}{H}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{b}\PY{o}{*}\PY{n}{dt}\PY{o}{*}\PY{n}{H}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{*}\PY{n}{L}\PY{p}{[}\PY{n}{n}\PY{p}{]}
                \PY{n}{L}\PY{p}{[}\PY{n}{n}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{L}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{+} \PY{n}{d}\PY{o}{*}\PY{n}{dt}\PY{o}{*}\PY{n}{H}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{*}\PY{n}{L}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{c}\PY{o}{*}\PY{n}{dt}\PY{o}{*}\PY{n}{L}\PY{p}{[}\PY{n}{n}\PY{p}{]}
            \PY{k}{return} \PY{n}{H}\PY{p}{,} \PY{n}{L}\PY{p}{,} \PY{n}{t}
        
        \PY{c+c1}{\PYZsh{} Load in data file}
        \PY{n}{data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{loadtxt}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{src/Hudson\PYZus{}Bay.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delimiter}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{skiprows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Make arrays containing x\PYZhy{}axis and hares and lynx populations}
        \PY{n}{t\PYZus{}e} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{H\PYZus{}e} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{L\PYZus{}e} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{} Simulate using the model}
        \PY{n}{H}\PY{p}{,} \PY{n}{L}\PY{p}{,} \PY{n}{t} \PY{o}{=} \PY{n}{solver}\PY{p}{(}\PY{n}{m}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{H0}\PY{o}{=}\PY{l+m+mf}{34.91}\PY{p}{,} \PY{n}{L0}\PY{o}{=}\PY{l+m+mf}{3.857}\PY{p}{,} \PY{n}{dt}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
                         \PY{n}{a}\PY{o}{=}\PY{l+m+mf}{0.4807}\PY{p}{,} \PY{n}{b}\PY{o}{=}\PY{l+m+mf}{0.02482}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{l+m+mf}{0.9272}\PY{p}{,} \PY{n}{d}\PY{o}{=}\PY{l+m+mf}{0.02756}\PY{p}{,}
                         \PY{n}{t0}\PY{o}{=}\PY{l+m+mi}{1900}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Visualize simulations and data}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{t\PYZus{}e}\PY{p}{,} \PY{n}{H\PYZus{}e}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b\PYZhy{}+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{t\PYZus{}e}\PY{p}{,} \PY{n}{L\PYZus{}e}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZhy{}o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{t}\PY{p}{,} \PY{n}{H}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{t}\PY{p}{,} \PY{n}{L}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Year}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Numbers of hares and lynx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1900}\PY{p}{,} \PY{l+m+mi}{1920}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{140}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Population of hares and lynx 1900\PYZhy{}1920 (x1000)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{H\PYZus{}e}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{L\PYZus{}e}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{H}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{L}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hudson\PYZus{}Bay\PYZus{}sim.pdf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hudson\PYZus{}Bay\PYZus{}sim.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Init: 34.91 3.857 0.1

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{How2ReadData_files/How2ReadData_18_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{the-plot}{%
\subsection{The plot}\label{the-plot}}

If we perform a least-square fitting, we can find optimal values for the
parameters \(a\), \(b\), \(d\), \(c\). The optimal parameters are
\(a=0.4807\), \(b=0.02482\), \(d=0.9272\) and \(c=0.02756\). These
parameters result in a slightly modified initial conditions, namely
\(H(0) = 34.91\) and \(L(0)=3.857\). With these parameters we are now
ready to solve the equations and plot these data together with the
experimental values.

\hypertarget{linear-regression-in-python}{%
\subsection{Linear regression in
Python}\label{linear-regression-in-python}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{display}
        \PY{k+kn}{import} \PY{n+nn}{sklearn}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LinearRegression}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{DecisionTreeRegressor}
        
        
        \PY{n}{data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{loadtxt}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{src/Hudson\PYZus{}Bay.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delimiter}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{skiprows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{y} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{line} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{1900}\PY{p}{,}\PY{l+m+mi}{1920}\PY{p}{,}\PY{l+m+mi}{1000}\PY{p}{,}\PY{n}{endpoint}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{reg} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{y}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{line}\PY{p}{,} \PY{n}{reg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{line}\PY{p}{)}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decision tree}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{regline} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{y}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{line}\PY{p}{,} \PY{n}{regline}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{line}\PY{p}{)}\PY{p}{,} \PY{n}{label}\PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{label}\PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{How2ReadData_files/How2ReadData_20_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{linear-least-squares-in-r}{%
\subsection{Linear Least squares in R}\label{linear-least-squares-in-r}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{HudsonBay} \PY{o}{=} \PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{src/Hudson\PYZus{}Bay.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{n}{T}\PY{p}{)}
        \PY{n}{fix}\PY{p}{(}\PY{n}{HudsonBay}\PY{p}{)}
        \PY{n}{dim}\PY{p}{(}\PY{n}{HudsonBay}\PY{p}{)}
        \PY{n}{names}\PY{p}{(}\PY{n}{HudsonBay}\PY{p}{)}
        \PY{n}{plot}\PY{p}{(}\PY{n}{HudsonBay}\PY{err}{\PYZdl{}}\PY{n}{Year}\PY{p}{,} \PY{n}{HudsonBay}\PY{err}{\PYZdl{}}\PY{n}{Hares}\PY{o}{.}\PY{o}{.}\PY{n}{x1000}\PY{o}{.}\PY{p}{)}
        \PY{n}{attach}\PY{p}{(}\PY{n}{HudsonBay}\PY{p}{)}
        \PY{n}{plot}\PY{p}{(}\PY{n}{Year}\PY{p}{,} \PY{n}{Hares}\PY{o}{.}\PY{o}{.}\PY{n}{x1000}\PY{o}{.}\PY{p}{)}
        \PY{n}{plot}\PY{p}{(}\PY{n}{Year}\PY{p}{,} \PY{n}{Hares}\PY{o}{.}\PY{o}{.}\PY{n}{x1000}\PY{o}{.}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{varwidth}\PY{o}{=}\PY{n}{T}\PY{p}{,} \PY{n}{xlab}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Years}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{ylab}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Haresx 1000}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{summary}\PY{p}{(}\PY{n}{HudsonBay}\PY{p}{)}
        \PY{n}{summary}\PY{p}{(}\PY{n}{Hares}\PY{o}{.}\PY{o}{.}\PY{n}{x1000}\PY{o}{.}\PY{p}{)}
        \PY{n}{library}\PY{p}{(}\PY{n}{MASS}\PY{p}{)}
        \PY{n}{library}\PY{p}{(}\PY{n}{ISLR}\PY{p}{)}
        \PY{n}{scatter}\PY{o}{.}\PY{n}{smooth}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{Year}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{Hares}\PY{o}{.}\PY{o}{.}\PY{n}{x1000}\PY{o}{.}\PY{p}{)}
        \PY{n}{linearMod} \PY{o}{=} \PY{n}{lm}\PY{p}{(}\PY{n}{Hares}\PY{o}{.}\PY{o}{.}\PY{n}{x1000}\PY{o}{.} \PY{o}{\PYZti{}} \PY{n}{Year}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{linearMod}\PY{p}{)}
        \PY{n}{summary}\PY{p}{(}\PY{n}{linearMod}\PY{p}{)}
        \PY{n}{plot}\PY{p}{(}\PY{n}{linearMod}\PY{p}{)}
        \PY{n}{confint}\PY{p}{(}\PY{n}{linearMod}\PY{p}{)}
        \PY{n}{predict}\PY{p}{(}\PY{n}{linearMod}\PY{p}{,}\PY{n}{data}\PY{o}{.}\PY{n}{frame}\PY{p}{(}\PY{n}{Year}\PY{o}{=}\PY{n}{c}\PY{p}{(}\PY{l+m+mi}{1910}\PY{p}{,}\PY{l+m+mi}{1914}\PY{p}{,}\PY{l+m+mi}{1920}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{interval}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{confidence}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}

    \hypertarget{non-linear-least-squares-in-r}{%
\subsection{Non-Linear Least squares in
R}\label{non-linear-least-squares-in-r}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n+nb}{set}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{1485}\PY{p}{)}
        \PY{n+nb}{len} \PY{o}{=} \PY{l+m+mi}{24}
        \PY{n}{x} \PY{o}{=} \PY{n}{runif}\PY{p}{(}\PY{n+nb}{len}\PY{p}{)}
        \PY{n}{y} \PY{o}{=} \PY{n}{x}\PY{o}{\PYZca{}}\PY{l+m+mi}{3}\PY{o}{+}\PY{n}{rnorm}\PY{p}{(}\PY{n+nb}{len}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.06}\PY{p}{)}
        \PY{n}{ds} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{frame}\PY{p}{(}\PY{n}{x} \PY{o}{=} \PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{y}\PY{p}{)}
        \PY{n+nb}{str}\PY{p}{(}\PY{n}{ds}\PY{p}{)}
        \PY{n}{plot}\PY{p}{(} \PY{n}{y} \PY{o}{\PYZti{}} \PY{n}{x}\PY{p}{,} \PY{n}{main} \PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Known cubic with noise}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{s}  \PY{o}{=} \PY{n}{seq}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{length} \PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{lines}\PY{p}{(}\PY{n}{s}\PY{p}{,} \PY{n}{s}\PY{o}{\PYZca{}}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{lty} \PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{col} \PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{m} \PY{o}{=} \PY{n}{nls}\PY{p}{(}\PY{n}{y} \PY{o}{\PYZti{}} \PY{n}{I}\PY{p}{(}\PY{n}{x}\PY{o}{\PYZca{}}\PY{n}{power}\PY{p}{)}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{ds}\PY{p}{,} \PY{n}{start} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{power}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{trace} \PY{o}{=} \PY{n}{T}\PY{p}{)}
        \PY{n}{class}\PY{p}{(}\PY{n}{m}\PY{p}{)}
        \PY{n}{summary}\PY{p}{(}\PY{n}{m}\PY{p}{)}
        \PY{n}{power} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{summary}\PY{p}{(}\PY{n}{m}\PY{p}{)}\PY{err}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
        \PY{n}{power}\PY{o}{.}\PY{n}{se} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{summary}\PY{p}{(}\PY{n}{m}\PY{p}{)}\PY{err}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
        \PY{n}{plot}\PY{p}{(}\PY{n}{y} \PY{o}{\PYZti{}} \PY{n}{x}\PY{p}{,} \PY{n}{main} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fitted power model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{sub} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Blue: fit; green: known}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{s} \PY{o}{=} \PY{n}{seq}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{length} \PY{o}{=} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{lines}\PY{p}{(}\PY{n}{s}\PY{p}{,} \PY{n}{s}\PY{o}{\PYZca{}}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{lty} \PY{o}{=} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{col} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{lines}\PY{p}{(}\PY{n}{s}\PY{p}{,} \PY{n}{predict}\PY{p}{(}\PY{n}{m}\PY{p}{,} \PY{n+nb}{list}\PY{p}{(}\PY{n}{x} \PY{o}{=} \PY{n}{s}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{lty} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{col} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{text}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{paste}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y =x\PYZca{} (}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{power}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ +/\PYZhy{} }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{power}\PY{o}{.}\PY{n}{se}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{n}{pos} \PY{o}{=} \PY{l+m+mi}{4}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

          File "<ipython-input-6-71172e3bc360>", line 7
        plot( y \textasciitilde{} x, main ="Known cubic with noise")
                \^{}
    SyntaxError: invalid syntax


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} 
\end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
