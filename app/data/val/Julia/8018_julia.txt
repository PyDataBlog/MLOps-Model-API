import Calculus

"""
**minimize(objectives, x0; kwargs...)**

Uses a proximal methods (Parikh & Boyd, 2014) to minimize an objective function
that can be decomposed into a sum of subproblems. In other words, minimize
f(x) = Σᵢ(fᵢ(x)).

Required Arguments:
-------------------

* **objectives** -- an array specifying the subproblems (fᵢ, above)
* **x0** -- an array containing the initial guess for the optimization

Keyword Arguments (Optional):
-----------------------------

* **method** -- symbol specifying optimization algorithm. Defaults to
**:consensus**, options are {**:consensus, :prox_descent, :apd**}
* Other keyword arguments are passed to the optimization routine.

References:
-----------

* Parikh N, S Boyd (2014). Proximal Algorithms. Foundations and Trends in
Optimization, 1(3):123-231.
"""
function minimize(objectives::Vector,
	              x0::AbstractArray;
	              method::Symbol = :consensus,
	              check_gradients::Bool = false,
	              kwargs...)

	if check_gradients && method in (:prox_descent,:apd)
		f = objectives[1]
		g_check = Calculus.gradient(f.f)
		grad = zeros(length(x0))
		f.g!(x0,grad) # updates grad to contain gradient
		
		if any(abs(g_check(x0) - grad) .> 1e-4)
			warn("provided gradient does not agree with finite differencing calculation")
		else
			println("provided gradient checks out at x0")
		end
	end 

	if method == :consensus
		result = consensus(objectives, x0; kwargs...)
	elseif method == :par_consensus
		result = parallel_consensus(objectives, x0; kwargs...)
	elseif method == :prox_descent
		result = prox_descent(objectives[1],objectives[2], x0; kwargs...)
	elseif method == :apd || method == :acc_prox_descent
		result = acc_prox_descent(objectives[1],objectives[2], x0; kwargs...)
	else
		error("Specified algorithm not recognized.")
	end

	return result
end

## Wrapper function, convert objectives into a vector
function minimize(objectives,x0::AbstractArray;kwargs...)
	minimize([objectives], x0; kwargs...)
end
