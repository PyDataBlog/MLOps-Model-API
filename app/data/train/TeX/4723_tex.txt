\documentclass[../main.tex]{subfiles}

\begin{document}

This chapter covers qss previously used for the examination of the course.

\section{Schemata Theorem}

\begin{question}
Explain Holland's schema theorem. Which assumptions that are made in this theorem and are somewhat unlikely?
\end{question}
\begin{solution}
The schema theorem considers the canonical GA with binary string representation of individuals with an alphabet
$\{0,1,\#\}$ where the latter is a wild card symbol.

The \textbf{fitness} of a schema $H$ at generation (time) $t$ is the average fitness of the strings representing schema
$H$ in the population.

\begin{equation}
\text{fitness} = f_{H}(t)
\end{equation}

The \textbf{defining length} $\delta(H)$ is the distance between the first and the last \emph{fixed} string position.
Here is $l$ the length of the string $s$.

\begin{equation}
    \text{defining length} = \delta(H) < l
\end{equation}

The \textbf{order} of a schema $H$ is is given by the length minus the number of wild card symbols.

\begin{equation}
    \text{order} = o(H) = l - |\{ \# \in s \}|
\end{equation}

The probability of survival of schema $H$ after \emph{cross-over} (recombination) is given by the formula:

\begin{equation}
    \text{probability of survival} \geq 1 - p_c \cdot \frac{\delta(H)}{l-1}
\end{equation}

The probability of survival of schema $H$ after \emph{mutation} is given by the formula:

\begin{equation}
    \text{probability of survival} \geq (1-p_m)^{o(H)} \approx 1 - o(H)p_m
\end{equation}

The schemata theorem is given by the formula:

\begin{equation}
    m(H,t+1) \geq m(H,t) \frac{f_H(t)}{f(t)} [1 - p_c \frac{\delta(H) }{l-1} - o(H)p_m]
\end{equation}

The result essentially says that the number of short schemata with low order and above average quality grows
exponentially in subsequent generations of a genetic algorithm. This result is obtained by considering the influence of
replication, crossover and mutation.

Still, even if the schema theorem is a very important result in GA theory, it is obtained under idealized conditions
that do not hold for most practical GA applications. Furthermore, the theorem depends on the representation and on the
genetic operators, more specifically on the Canonical GA. It is easy to find or to construct problems for which it is
not verified. Such problem are called \textbf{deceptive}.
\end{solution}

\section{OS \& RAPGA}
\begin{question}
Explain, chapter 4, page 69, the sentence ``Both algorithms are self-adaptive \textellipsis'' (About Offspring
Selection and RAPGA)
\end{question}
\begin{solution}
The extended selection concepts, OS and RAPGA, are self adaptive in the sense that they operate based on the current
state of the population. More specifically, they introduce selection after reproduction in a way that checks whether or
not crossover and mutation were able to produce a new solution candidate that outperforms its own parents.

This is done to tackle the problem of premature converges, which occurs when the  genetic information stored in the
individuals of a population does not contain that genetic information which would be necessary to further improve
solution quality, resulting in such a suboptimal state that the genetic operators are no longer able to produce
offspring that outperform their parents.

Offspring selection works by requiring a certain percentage of children to outperform their parents. RAPGA on the
other hand increases and decreases the population size, relative to the amount of children that both outperform their
parents and contain new genetic information.

\end{solution}

\section{Objective Function}
\begin{question}
Suppose you want to solve an optimization problem, for which the objective function (function to be maximized) is
known. Why it is usually not appropriate to use the objective function as the fitness function? Give several reasons if
possible. How can you construct a good fitness function? Give an example of such a construction of a fitness function
in one of the texts that we have discussed.
\end{question}
\begin{solution}
The problem when using the regular fitness function is that in the early stages, there may be individuals with a very
high fitness value, causing bias towards them. On the other hand, near the end of a run, when population is converging,
the individuals might have closely related fitness value.

The solution to this problem is \textbf{scaling} of the fitness function. Different approaches exist, of which we
introduce the linear variant introduced in \cite{4075583}. Here, a performance function $u(x)$ is introduced.

\begin{equation}
    u(x) = f(x) - f_\text{min}
\end{equation}

This function guarantees the performance to be positive. It is usually possible to reduce selection pressure and stagnation more, by using $f'_\text{min}$ instead of $f_\text{min}$. $f'_\text{min}$ is the minimal fitness value observed in the last generation (or the last $n$ generations). Using this observed minimum instead of the absolute minimum makes values easier to distinguish. This approach is called scaling and is guided by a parameter called the scaling window. The only drawback is that special measures have to be taken when new offspring has a fitness value lower than $f'_\text{min}$.

Three scaling modes are considered in \cite{4075583}, based on the parameter $W$.
\begin{itemize}
    \item If $W = 0$, then $f'_{\text{min}}$ is set to the minimum $f(x)$ in the first generation. In succeeding
    generations, all structure that evaluate to less than $f'_{\text{min}}$  are ignored. The value of
    $f'_{\text{min}}$ is updated when \textbf{all} structures in the population have evaluations greater than
    $f'_{\text{min}}$.
    \item If $0 < W < 7$, then we set $f'_{\text{min}}$ to the least value of $f(x)$ in the last $W$ generations.
    \item If $W = 7$, an infinite window is specified and no scaling is performed.
\end{itemize}
\end{solution}

\section{GABIL}
\begin{question}
Given the charts in the article on GABIL, can you say that the tree based concept learner (ID5R) outperforms the
genetic algorithm? Discuss figures 1 -- 7 in detail.
\end{question}
\begin{solution}
Preliminary results from the paper support that GABIL is competitive with ID5R as the target concept increases in
complexity.
\emph{Figure~1} compares the two with easier concepts, with 1 or 2 disjunct concepts. Here, the predictive
performance of ID5R improves more rapidly than that of GABIL. As concepts get more complex, ID5R starts to degrade in
performance. For the case of 3 disjunctions, performance is comparable for  1 conjunction and 3 conjunctions
(\emph{Figure~2} and \emph{Figure~6}. The exception is the case for 2 disjunctions in combination with 2
conjunctions in \emph{Figure~4}, where GABIL is being outperformed. For the case of 4 disjunctions, GABIl is the
winner. Because the complexity of a target concept corresponds roughly to the size of its decision tree, the authors
expect GABIL to keep outperforming ID5R as the difficulty increases.
\end{solution}

\section{Epistasis \& Deception}
\begin{question}
Explain the terms ``epistasis'' and ``deception''. What is the difference?
\end{question}
\begin{solution}
\emph{Epistatis} indicates that there is a nonlinear interaction among the bits of the string. This means that the
effect of one gene is being dependent on the presence of another.

A search function is \emph{deceptive} when the low- order high-fitness value schemata do not contain the optimal string
as an instance. An example is the minimal deceptive problem is given below.

\begin{equation}
    \begin{array}{lcl}
        f(11)  & > & f(\#\#) \\
        f(\#0) & > & f(\#1) \\
        f(0\#) & > & f(1\#)
    \end{array}
\end{equation}

\end{solution}

\section{Rank-Based Selection}
\begin{question}
Discussion of rank-based selection. Which parameters can be used to adapt the behavior of these methods? When would you
want to use a rank-based selection method?
\end{question}
\begin{solution}
In the context of linear-rank selection, the individuals of the population are ordered according to their fitness.
Copies are assigned in such a way that the best individual receives a pre-determined multiple of the number of copies
the worst one receives.

On the one hand rank selection implicitly reduces the dominating effects of ``super
individuals'' in populations (i.e., individuals that are assigned a significantly better fitness value than all other
individuals), but on the other hand it warps the difference between close fitness values, thus increasing the selection
pressure in stagnant populations. Even if linear-rank selection has been used with some success, it ignores the
information about fitness differences of different individuals and violates the schema theorem.
\end{solution}

\section{Evolving 3D Morphology}
\begin{question}
Discussion of the paper Evolving 3D morphology and behavior by competition by K. Sims. The fitness function is
different from the fitness functions we are used to. Explain how and why.
\end{question}
\begin{solution}
In a natural evolutionary system, the fitness is not constant but depends on environmental factors including the
evolution of other organisms. This idea distinguishes between natural evolution an optimization. Sustaining
evolutionary change is obtained by having an organism's fitness determined by the behavior of the other organism in the
population. More specifically, the individuals of the population competes against each other, with winner receiving a
higher relative fitness score. The relative fitness functions for the two creates is given in the two equations below, with $d_i$ the final shortest distance of creature $i$.

\begin{equation}
    f_1 = 1.0 + \frac{d_2-d_1}{d_1 + d_2}
\end{equation}

\begin{equation}
    f_2 = 1.0 + \frac{d_1-d_2}{d_1 + d_2}
\end{equation}
This formulation puts all fitness values in the limited range of $0.0$ to $2.0$. If the two distances are equal the
contestants receive tie scores of $1.0$ each, and in all cases the scores will average $1.0$.
\end{solution}

\section{Constraints}
\begin{question}
Handling constraints: Explain the difference between algorithms based on repair methods and algorithms based on
decoders. Why these strategies can lead to a better performance compared with algorithms based on penalty functions?
\end{question}
\begin{solution}
Algorithms based on repair methods correct infeasible solutions, so that they never become part of the population.
However, the repair process can be computationally intensive or even as difficult as solving the original problem.

Decoder on the other hand use a representation which guarantees to always generate a feasible solution. They too can be
computationally intensive and it is not always possible to model all constraints. An example of such representation is the ordinal representation where each item is encoded as it's position in a well-ordered set.

Both methods are especially effective compared to penalty functions when the ration between feasible parts of the
search space and the whole search space is smaller, because it is harder for the penalty function to provide feasible
results.
\end{solution}

\section{Roulette Wheel Selection}
\begin{question}
Discuss some drawbacks of the roulette wheel selection mechanism, and describe some methods to avoid (or to minimize)
these drawbacks.
\end{question}
\begin{solution}
Fitness proportionate select can cause premature convergence because outstanding individuals quickly take over the
entire population. The dominance of a single group of highly fit individuals (``super individuals'') can be reduced by
stochastic sampling techniques. The second drawback is caused when the fitness values are close together,leading to low
selection pressure. This can be mitigated by so called ``windowing techniques'' to make the selection independent of
the dimension of the fitness value.
\end{solution}

\section{Genetic Programming}
\begin{question}
What is evolutionary programming? Can this still be considered a genetic algorithm? Give one ore two examples to
illustrate the approach.
\end{question}
\begin{solution}
Genetic programming (GP), an extension of the genetic algorithm, is a domain-independent, biologically inspired method
that is able to create computer programs from a high-level problem statement. The same principles of selection,
crossover and mutation are applied to the population to come to a solution.

The most common approach represents programs as structured syntax trees. Here, all tree nodes are either \emph{functions} or \emph{terminals}. The later are evaluated directly, while the child nodes of functions are evaluated first, using their return values as the input for the parent's evaluation. This representation has the advantage that:

\begin{enumerate}
    \item many programming languages use trees as their internal representation,
    \item the recursive nature allows parts of the program to be (re)evaluated immediately, and
    \item the representation's size and shape can vary dynamically.
\end{enumerate}

Other representation include linear and graphical genetic programming. With linear GP, a program is represented as a list that is executed linearly. The big advantage is that they are more similar to a regular GA and easily enable the representation of stack-based and register-based machine code. With graphical GP, programs are represented as graphs. Nodes represent functions and terminals while connections indicate the control flow.

A notable difference between GP and GA is that in GP, crossover and mutation (or a simple
copy) are executed independently. Each time new offspring is to be created, one of these variants is chosen
probabilistically, as opposed to GA, where they are applied sequentially.

\end{solution}

\section{Varying Population Size}
\begin{question}
Consider varying population sizes for GA's. Discuss (1) the purpose, (2) the importance of the life parameter and (3)
the relevant figure in the book.
\end{question}
\begin{solution}
Assuming this questions regards RAPGA and Figure~4.3 from the book by Affenzeller \cite{affenzeller2009genetic}, and
that the life parameter is the minimum and maximum population size. The purpose of the varying population size is
maintaining as much genetic diversity while making as much progress as possible from the actual population. The
population size requires a upper limit because the population would otherwise explode in the first rounds which would
be very inefficient. The lower limit is intended to maintain a sufficient amount of chromosomes to outperform their
parents. Reaching the lower bound can be used as an indicator for convergence. Figure~3.4 shows how the population size
changes between the lower and upper bound.
\end{solution}

\end{document}

% \section{}
% \begin{question}
% \end{question}
% \begin{solution}
% \end{solution}