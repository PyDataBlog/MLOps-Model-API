% ====================================================================
\section{Science Analysis}
\label{sec:twinkles1:science}
% ====================================================================

\contact{Phil Marshall}{@drphilmarshall},
\contact{Michael Wood-Vasey}{@wmwv},

Below we describe the supernova and strong lensing science analysis
that we want to do with the \TwinklesOne data, and that can be done
in the 2016--2017 time frame using available simulation and analysis
technology and computing infrastructure. In each case we first
introducing the measurement issues we face, and then define the
investigations of them that we want to do. These then dictate the
requirements we have on the challenge dataset design.

A note on terminology: we refer to the process of light curve
extraction as ``Monitoring.'' Supernova light curve extraction will be
performed by a  tool referred to as \SNMonitor, and strong lens light
curve extraction  by a related piece of software called \SLMonitor.
For strong lenses, the key parameter to be inferred  from a set of
light curves is the time delay, and so we refer to the software tool
that  performs that inference as \SLTimer. Supernova light curve
parameters  are typically inferred with tools known as
``light curve fitters,'' to be deployed by the code \SNDistance.


% --------------------------------------------------------------------

\subsection{Supernovae}
\label{sec:twinkles1:science:supernovae}

Introduction to supernova analysis in \TwinklesOne.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\subsubsection{Proposed Analyses}
\label{sec:twinkles1:science:supernovae:analyses}

We propose to answer the following questions:

\begin{itemize}
\item Are current image differencing algorithms sufficient to recover supernovae on simulated images?
\item Can we extract robust, accurate, and correctly precise light curves of supernovae?
\end{itemize}

For this we will need the \TwinklesOne survey to have the following
properties:
\begin{itemize}
\item The field should contain at least 100 active SNeIa with the expectation of at least 5 observations at SNR$>5$ during the simulated time period, and 100 active SNeIa that we expect to fall below a SNR$>5$ threshold.  This should be a loosely continuous distribution of apparent brightness.
\item Supernovae should be placed on galaxies or galaxy locations with different surface brightness.
\item A cadence that provides samples at least on a few-day cadence.  E.g., a deep drilling field would satisfy this.
\item Image difference processing should be run using whatever DM algorithms are currently available.
\end{itemize}

{\bf Move to future ``Validation of DM'' section.} \\
This includes all of the goals in CX-CD1-Monitor:SW1. \\
Object detection and light-curve extraction:
\begin{itemize}
\item Does brightness of recovered simulated source match input catalog brightness to within Poisson uncertainty?
\item Does the recovery efficiency as a function of background brightness of sky and astrophysical sources make sense?
\item Is forced photometry for variable sources in difference images correct in its precision?
    \begin{itemize}
    \item Does (measured flux / reported uncertainty) have mean of 0 and sigma of 1 for blank regions on (a) images; (b) subtracted images.
    \item Does the (measured flux / reported uncertainty) for a static point source behave correctly?
    \item Does the (measured flux / reported uncertainty) for a variable point source behave correctly?
    \item Do the recovered lightcurves of supernova match the input simulation specification to the expected precision?
    \end{itemize}
\item Is forced photometry for variable sources in difference images accurate in its calibration?
\end{itemize}



% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


% --------------------------------------------------------------------

\subsection{Strong Lensing}
\label{sec:twinkles1:science:stronglensing}

From the first Time Delay Challenge we know that around 400 lensed
quasars (defined here as the ``Gold Sample'') should be measurable
with cosmological accuracy with LSST, provided that a) 6 day cadence
can be achieved and b) the light curves extracted from the LSST images
are as clean as those in the challenge, which used a particular {\it noise
model} for the image fluxes.

Reaching 6-day cadence  in the WFD survey (where most lenses will
reside) will require all 6 filters to be used: the second time delay
challenge, TDC2, will test assumption a) above, that  a 5--6 filter
light curve can be modeled as accurately as a single filter light
curve. The fidelity of the multi-filter light curves will depend on
our ability to extract them, and this requires image simulations of
very high realism to be analyzed with the tools of sufficient
sharpness. In \TwinklesOne we will test assumption b), and assess the
fidelity of lensed quasar multi-filter light curves {\it as observed and
measured with the LSST system.} Is the TDC1/TDC2 noise model correct?

The are a number of possible sources of light curve error, that we can
investigate using the \TwinklesOne dataset, including basic photometric
accuracy (including calibration), point image separation (deblending), and
lens galaxy light contamination. (The AGN host light will also be a contaminant,
but at a lower level.)

One way to evaluate the quality of a set of light curves is to assess the accuracy of
model parameters inferred, or summary statistics derived, from them
Correlated photometric error accuracy and mitigation. For strong lenses,
the natural model parameter is the time delay between light curves.

We propose to answer the following questions using the \TwinklesOne dataset:
\begin{itemize}
\item Was the quality of the TDC1 Gold Sample photometry realistic?
\item Was the noise model assumed in TDC1 realistic?
\item Is the current LSST DM implementation of light curve extraction
      sufficient for lensed quasar time delay measurement?
\item How can we better model LSST lensed quasar photometry in
      future time delay challenges?
\end{itemize}


For this investigation we will need the \TwinklesOne survey to have the following
properties:
\begin{itemize}
\item The field should contain a significant random fraction (at least
25\%,  and preferably 100\%) of the TDC1 Gold Sample of 400 lensed
quasars,  which should vary in the same way as the TDC1 objects (at
least with regard to their  AGN variability, which dominates over
microlensing).
\item The survey should simulate several years of realistic LSST observing in
wide-fast-deep (WFD) strategy, with with mean night-to-night
cadence of around 6 days, to allow time delays to be estimated
and a meaningful comparison with TDC1.
\end{itemize}


After light curve extraction we will then perform the following tests:
\begin{itemize}
\item The noise properties of the \TwinklesOne and TDC1 light curves
will be summarized and compared.
\item Time delays will be measured for each system using the fiducial
TDC1 algorithm, and the mean accuracy compared against that in TDC1.
\end{itemize}


% ====================================================================
