\chapter{Data Filtering}

In the analysis of data we want to extract those signal components that are interesting to us, and eliminate artifacts that may distort our data. For example, in Fig. \ref{fig:Filters}(top) we have a 1-dimensional data signal. The original data contain not only the sine-wave we are interested in, but also a low-frequency drift and high-frequency noise. Ideally, our \emph{Filter} should eliminate all the undesired components. In other cases, we may want to use a \emph{Filter }to extract the outlines from 2-dimensional images (Fig. \ref{fig:Filters}, bottom).

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{../Images/Filters.jpg}\\
  \caption{Filters applied to 1-dimensional (top) and two-dimensional (bottom) signals.}\label{fig:Filters}
\end{figure}

The following chapter will describe how such 1-dimensional and 2-dimensional filters work.

\clearpage

\section{Transfer Function}\index{transfer function}

To analyse biomedical data, you have to modify them. If the incoming data are called x, and the resulting/outgoing data y, this can be indicated schematically by the diagram in Fig. \ref{fig:transferFcn}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.3\textwidth]{../Images/DataFilter.jpg}\\
  \caption{Transfer function}\label{fig:transferFcn}
\end{figure}

The box modifying the signal, here labelled \emph{G}, is often called the \emph{transfer function}.

A simple case is the amplification of a signal

\begin{equation}
  y = g \ast x
\end{equation}

\emph{g} is the \emph{gain}\index{gain} of this transfer function, and a simple amplification is commonly indicated as shown in Fig. \ref{fig:amplification}.

\begin{figure}[ht]
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.3\textwidth]{../Images/amplifier.png}\\
  \caption{Amplification}\label{fig:amplification}
\end{figure}

For discrete valued signals, the output only depends on the instantaneous input:

\begin{equation}
  y(n) = g \cdot x(n)
\end{equation}

Since the gain of many systems covers many orders of magnitude, it is often expressed on a logarithmic scale \index{dB|see{decibel}}\index{decibel}\index{attenuation}:

\begin{equation}\label{eq:db}
  attenuation = 20 \cdot log_{10} \left( \frac{a_{out}}{a_{in}} \right) dB .
\end{equation}

For example, an amplitude reduction by a factor of 2 corresponds to an attenuation of $6 dB$, and a reduction by a factor of 10 to $20\, dB$.


\clearpage

\section{Finite Impulse Response (FIR) filters}\index{filter!FIR}\index{Finite Impulse Response (FIR)}

More options become available if the output values are obtained by weighting the last k incoming data points:

\begin{align}\label{eq:fir}
    y(n) &= \sum\limits_{i = 0}^{k-1} {{w_i}*x(n - i)}  \\
    \nonumber &= {w_0}x(n) + {w_1}x(n - 1) + ... + {w_{k-1}}x(n - k)
\end{align}

This can be seen as a \emph{moving window filter}, which is moved over the incoming data points from beginning to end (Fig. \ref{fig:fir}), and is called \emph{finite impulse response (FIR}) filter.

\subsection{Matlab Notes}

The choice of coefficients in Eq.\ref{eq:fir} reflects conventions in the area of \emph{Digital Signal Processing (DSP)}. Watch out, though, because vectors in Matlab start with \emph{x(1)}!

We can implement Eq.\ref{eq:fir} in Matlab as

\begin{lstlisting}
    y = filter(w, 1, x)
\end{lstlisting}

where $w$ is a vector containing the weights, and $x$ a vector containing the input. The $1$ will become clear when we discuss the more general IIR-filters below.

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{../Images/FIR_Filter.jpg}\\
  \caption{FIR filter, for online analysis. Note the response delay.}\label{fig:fir}
\end{figure}

\subsection{DSP Terminology}

In DSP, Eq. \ref{eq:fir} is sometimes expressed as \index{convolution}

\begin{equation}\label{eq:convolution}
  y(n) = w(k) * x(n)
\end{equation}

and interpreted as \emph{y of n equals the convolution of (w of k) and (x of n)}. So don't get nervous about the complicated sounding term \emph{convolution}: it is nothing else but the application of an FIR filter.

Another expression that is used in DSP is \emph{impulse response} \index{impulse response}: If the input consists of

\begin{eqnarray*}
  x(i) &=& 1 \; for \; i=k  \\
  x(i) &=& 0 \; for \; i \neq k
\end{eqnarray*}

then the output around $y(k)$ equals the weight coefficients. The impulse response of a filter is the filter's output time-domain sequence when the input is a single unity-valued sample (impulse) preceded and followed by zero-valued samples.

Coming from the hardware design of filters, DSP textbooks also tend to use a different depiction of FIR filters (Fig. \ref{fig:DSPfir}). Keep in mind, though, that this is equivalent to our Figure \ref{fig:fir}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{../Images/DSP_FIR.jpg}\\
  \caption{DSP representation of an FIR filter.}\label{fig:DSPfir}
\end{figure}


\subsection{Offline Analysis}

When your data needs to be analysed in real-time and online, you only have “older” values of x available: $x(m)$, with $m \le n$. This induces a \emph{time-delay} in your output signal. For offline analysis, it is therefore more convenient to use a window that is centred about your current position (Fig. \ref{fig:centered}). This reduces or eliminates the problem of time delays in the output signal y relative to the input signal x.

\begin{equation}\label{eq:fir_centered}
  {y_n} = \sum\limits_{m =  - k}^k {{w_m}{x_{n + m}}}
\end{equation}

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{../Images/FIR_centered.jpg}\\
  \caption{Filter using a centered window (offline analysis).}\label{fig:centered}
\end{figure}


\subsection{FIR Filter 1: Moving average}\index{filter!moving average}\index{smoothing!moving average}

If the filter values are chosen as

\begin{equation}
  {w_i} = \frac{1}{k},\,\,\,\,i = 0:k-1
\end{equation}

the filter averages over the last k data points.
For example, with k=3 and n=10, we get

\begin{equation}
  w = \left[ {\begin{array}{*{20}{c}}
{\frac{1}{3}}&{\frac{1}{3}}&{\frac{1}{3}}
\end{array}} \right]
\end{equation}

and

\begin{equation}
  y(10) = {w_0} \cdot x(10) + {w_1} \cdot x(9) + {w_2} \cdot x(8) = \frac{{x(10) + x(9) + x(8)}}{3}
\end{equation}

\subsection{FIR Filter 2: Differentiation} \index{differentiation}

\subsubsection{First-difference Differentiation}\index{differentiation!first-difference}

A differentiation of an incoming signal, with $\Delta(t)=1$

\begin{equation}
    y(n) = \frac{\Delta x}{\Delta t} = \frac{x(n) - x(n - 1)}{\Delta t}
\end{equation}

gives us the filter weights (Fig. \ref{fig:differentiator}, top)

\begin{equation}
  \vec w = \left[ 1 \; -1 \right] / \Delta t
\end{equation}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{../Images/Differentiators.jpg}\\
  \caption{Top) First-difference differentiator. Bottom) Central-difference differentiator.}
  \label{fig:differentiator}
\end{figure}

\subsubsection{Central-difference Differentiator}\index{differentiation!central-difference}


For offline analysis, a centered filter may be preferable (Fig. \ref{fig:differentiator}, bottom):

\begin{equation}
  \vec w = \left[ 1 \;0 \; -1 \right] * \frac{1}{2*\Delta t}
\end{equation}

\subsubsection{Cubic Differentiator}\index{differentiation!cubic}


We can also differentiate a curve by taking two samples before and after each point, and taking the slope of the best cubic fit to these data points. This can be achieved with a weight vector of:

\begin{equation}\label{eq:cubicFIRfilter}
  \vec w = \left[ 1\; -8\;\; 0\;\; 8\; -1 \right] * \frac{1}{12*\Delta t}
\end{equation}

\textbf{Note:} This is essentially equivalent to a Savitzky-Golay filter with a \emph{polynomialOrder n=3}, a \emph{windowSize=5}, and a \emph{derivativeOrder=1}. The only difference is that the Savitzky-Golay filter uses a centered window, i.e. it compensates for the time-lag of the FIR-filter.

\subsubsection{Specialized Differentiators}

To optimize the noise and the frequency response, a number of differentiation algorithms have been published, which we won't discuss here:

\begin{itemize}
  \item Lanczos differentiators
  \item Parks-McClellan differentiators
  \item ...
\end{itemize}


\subsection{FIR Filter 3: Savitzky-Golay Filter}\index{filter!Savitzky-Golay}

The moving average is very simple, and can induce a bias in the output. For example, it systematically underestimates the value around the peak of a signal.
To overcome this problem, the idea of the Savitzky-Golay filter is to fit a polynomial of order $q$ to the surrounding $2m + 1$ data points, and use its value at the centre for data smoothing\index{smoothing!Savitzky-Golay}, its first derivative for calculating the derivative\index{differentiation!Savitzky-Golay}, etc. One of the best things about the Savitzky-Golay filter is that you only have to determine the values $\vec{w}$ once at the beginning of your analysis; the \emph{same} values can then be used to estimate the derivatives of order up to $q-1$.

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1.0\textwidth]{../Images/savgol.png}\\
  \caption{The principle of the Savitzky-Golay filter. A moving average filter for smoothing underestimates peaks.}\label{fig:savgol}
\end{figure}

Figure \ref{fig:savgol} shows the principle of the Savitzky Golay filter:

\begin{enumerate}
  \item For a given x-value …
  \item you take a symmetric window of your data set, then …
  \item calculate the best polynomial fit to these data, and …
  \item if you want to smooth the data, take the center-point of the fitted curve; or if you want to differentiate the data, take the first derivative at that location.
\end{enumerate}

In addition, you also see that a moving average filter (dashed line) would underestimate peak value of the curve.

So to use the Savitzky-Golay filter, you have to define the:

\begin{itemize}
  \item  \emph{input data}	(e.g., “x”)
  \item  \emph{order of the polynomial fit}	(e.g., “2” for quadratic fits)
  \item  \emph{size of the data window}		(must be odd, e.g., “9”)
  \item  \emph{order of derivative}		(e.g., “0” for smoothing, “1” for 1st derivative)
  \item \emph{sampling rate	}(in Hz, e.g., “100”)
\end{itemize}

For example, to smooth data by finding the best-fit second-order polynomial ($q=2$) to the data in a five point window ($m=2$, as $2*2 + 1 = 5$), you would need the coefficients

\begin{equation*}
  \vec w = \left[ {\begin{array}{*{20}{c}}
{ - 0.086}&{0.343}&{0.486}&{0.343}&{ - 0.086}
\end{array}} \right]
\end{equation*}

For general values of q and m, you can use the Matlab command \emph{sgolay} to find the corresponding values of $\vec{w}$. For our example ($q=2$ and $m=2$), the command

\begin{equation*}
   [b,g] = sgolay(2,5);
\end{equation*}

gives you the smoothing coefficients in the middle line of b,  and the derivative coefficients in the columns of g.

For simple smoothing, you can also use the Matlab command \emph{sgolayfilt}:
\begin{equation*}
  y = sgolayfilt(x, q, 2*m + 1);
\end{equation*}

If you want to avoid dealing with the details of applying the weights, use the function \emph{savgol} (by Thomas Haslwanter).

\MatImg "savgol.m" (p \pageref{mat:savgol}) Utility for data smoothing, and for calculating derivatives.

%\\~\\
\textbf{Reasons to use the Savitzky-Golay filter:}

\begin{itemize}
  \item It is an efficient way of smoothing data.
  \item It is a convenient way to find higher derivatives.
  \item Smoothing and calculating the higher derivatives can be done simultaneously.
\end{itemize}

\textbf{Reasons not to use the Savitzky-Golay filter:}

\begin{itemize}
  \item It does not have a crisp frequency response. In other words, the gain decreases only gradually as frequency increases. For example, if you know that you only need frequency components below 200 Hz, other filtering techniques are preferable.

  \item If you are fitting data to a \emph{parametric model}, it is almost always better to use raw data than pre-smoothed data, since the smoothing may cause important information to be lost.

  \item If you know the ideal signal characteristic, the \emph{Wiener filter}, though more complex to apply, may produce better results.

\end{itemize}

\textbf{Further information}

\begin{itemize}
  \item Brandt, S. (1999) Datenanalyse. Spektrum Akademischer Verlag.

  \item Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P. (1992) Numerical Recipes in C (2nd Ed.): the Art of Scientific Computing (pp. 650-655). Cambridge University Press.

  \item Savitzky, A., Golay, M. J. E., Smoothing and differentiation of data by simplified least squares procedures, Anal. Chem. 36 (1964) 1627–1639.

  \item Madden, H. H., Comments on Savitzky-Golay convolution method for least-squares fit smoothing and differentiation of digital data, Anal. Chem. 50 (1978) 1383–1386.

\end{itemize}


\clearpage

\section{Infinite Impulse Response (IIR) filters}\index{filter!IIR}\index{Infinite Impulse Response (IIR)}

We have seen that the output of a FIR filter only depends on the incoming signal:

\begin{equation*}
  y(n) = \sum\limits_{i = 0}^{k-1} {{w_i}*x(n - i)}
\end{equation*}

In general, though, the output of a filter may also depend on the $m$ most recent values of the output signal. In this case,

\begin{equation}
  y(n) + {a_1}y(n - 1) + ... + {a_{m-1}}y(n - m) = {b_0}x(n) + {b_1}x(n - 1) + ... + {b_n}x(n - k )
\end{equation}

or

\begin{equation}
  \sum\limits_{j = 0}^{m-1} {{a_j}y(n - j)}  = \sum\limits_{i = 0}^{k-1} {{b_i}x(n - i)}
\end{equation}

where $a_0 = 1$. In other words, the coefficients $a_i$ and $b_j$ uniquely determine this type of filter. This type of filter is sometimes referred to as an \emph{infinite impulse response (IIR)} filter. The \emph{feedback character} of these filters can be made more obvious by re-shuffling the equation:

\begin{equation}\label{eq:IIR}
  y(n) = \left[{b_0}x(n) + {b_1}x(n - 1) + ... + {b_{k-1}}x(n - k) \right] - \left[ {{a_1}y(n - 1) + ... + {a_m}y(n - m)} \right]
\end{equation}

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{../Images/IIR_filter.jpg}\\
  \caption{Infinite Impulse Response Filter (IIR Filter)}\label{fig:iir}
\end{figure}

While it is more difficult to find the desired coefficients $a,b$ for IIR filters than for FIR filters, IIR filters have the advantage that they are more efficient computationally, and achieve a better frequency selection with fewer coefficients.


\subsubsection{IIR Filter 1: Exponential Decay}

When the change in a signal is proportional to the magnitude of the signal, the signal changes exponentially. For example

\begin{equation}\label{eq:expDecay}
  y_n = \alpha * y_{n-1}
\end{equation}

For $\alpha > 1$  the signal grows exponentially, and for  $\alpha < 1$ it decreases exponentially. For example, for $\alpha=1/2$ we get

\begin{equation*}
  {y_i} = {y_0} \cdot [1,\frac{1}{2},\frac{1}{4},\frac{1}{8},...]
\end{equation*}

\paragraph{Matlab Implementation}

In Matlab, IIR filters can be implemented very easily by simply specifying the coefficients $a_i$  and $b_i$ (For FIR-filters $a=1$):

\begin{lstlisting}
  y = filter(b,a,x)
\end{lstlisting}

Comparing Eq.\ref{eq:IIR} with Eq.\ref{eq:expDecay}, we see that we can implement an \emph{Exponential Decay Filter} as follows:

\begin{lstlisting}
    % Dummy inData and parameters
    x = randn(1,1000);
    alpha = 0.5;

    % IIR filter coefficients
    a = [1 -0.5];
    b = [];

    % Apply the filter
    y = filter(b,a,x);
\end{lstlisting}

\subsubsection{IIR Filter 2: Leaky Integrator}\index{leaky integrator}

The exponential decay is a special case of the \emph{Exponential Averaging Filter}\index{filter!exponential averaging}, defined as

\begin{equation}\label{eq:expAvg}
  y(n) = \alpha x(n) + (1-\alpha) y(n-1)
\end{equation}

You see: the exponential decay is the impulse response of an exponential averaging filter.

The nice thing about this filter is that it is a smoothing filter with a single parameter: by tuning $\alpha$, you can determine the output's sensitivity to input noise.

\subsubsection{IIR Filter 3: Butterworth lowpass filter}\index{filter!Butterworth}

The Matlab command \emph{butter} provides the $[b,a]$ coefficients of an IIR filter corresponding to Butterworth filters. The Butterworth filter is a type of signal processing filter designed to have as flat a frequency response as possible in the pass band. It is also referred to as a \emph{maximally flat magnitude} filter.

\textbf{Note:} Applying a low-pass filter is equivalent to smoothing the data.\index{smoothing!Butterworth}

For example, if you have a sampling rate of 1 kHz (and thus a Nyquist frequency of 500 Hz), and you want to design an IIR lowpass filter with
a 3dB cut-off frequency of 40 Hz
and a filter of order 5,
you get the corresponding $[b,a]$ coefficients as follows:

\begin{lstlisting}
    nyq = 500;
    cutoff = 40;
    order_filter = 5;
    [b,a] = butter(order_filter, cutoff/nyq);
\end{lstlisting}

\textbf{Warning:} Be careful with low filter frequencies and higher order ($n \ge 4$) Butterworth filters: there the \emph{[b,a]} syntax may lead to numerical problems due to round-off errors. In that case you should switch to the \emph{[z,p,k]} syntax, which we don't discuss here.


\clearpage

\section{Difference between FIR and IIR filters}

The two names \emph{finite impulse response filter} and \emph{infinite impulse response filter} are derived from the differing behaviour of each type of filter to an impulse input. To demonstrate this graphically, we implement an example of each type of filter in Matlab.

\begin{lstlisting}
    % Input spike at 5 sec:
    xx = zeros(1,20);
    xx(5) = 1;
    tt = 1:20;

    data.before    = xx;
    data.after_fir = filter(ones(1,5)/5 , 1, xx);
    data.after_iir = filter([1] , [1 -0.5], xx);

    % Graph
    ph = plot(tt, data.before,    'bo', ...
         tt, data.after_fir, 'rx-', ...
         tt, data.after_iir, 'b.:');
    for ii = 1:3
        set(ph(ii), 'LineWidth', 2);
    end
    legend('input', 'FIR-filtered', 'IIR-filtered');
\end{lstlisting}

This Matlab code produces the following graph:

\begin{figure}[ht]
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.7\textwidth]{../Images/fir_iir_demo.jpg}\\
  \caption{Comparison of FIR and IIR filter behaviour.}
\end{figure}

In this graph, we can see:
\begin{itemize}
  \item the time delay of the FIR filter
  \item the finite effect of an impulse on FIR-filtered data
  \item the instant response of the IIR filter
  \item the infinite effect of an impulse on IIR-filtered data
\end{itemize}

For offline analysis, the Matlab command \emph{filtfilt} filters each signal twice, once forward and once backward. This way time delays are eliminated.


\clearpage

\section{Median Filter}\index{filter!median}

FIR-filters and IIR-filters are both \emph{linear filters}\index{filter!linear}, since the filter coefficients enter the transfer through simple multiplications. While such linear filters are good at eliminating noise that has a Gaussian distribution, it fails when you have extreme outliers. Such spikes in the data can be caused e.g. by faulty sensors, or by loose connections in the analysis setup. For such outliers, a median filter offers a better noise suppression than linear filters. In Fig. \ref{fig:median} the signal has two outliers, one at t=5, and one at t=15. The averaging filter data have been adjusted to compensate for the delay, and both averaging and median filter have a window size of 3.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{../Images/MedianFilter.jpg}\\
  \caption{Data with extreme outliers, average filtered, and median filtered.}\label{fig:median}
\end{figure}

\begin{lstlisting}
    % Create data
    x = zeros(1,20);
    x(10:20) = 1;

    % Add some spikes, at t=5 and t=15
    x(15) = 3;
    x(5) = 3;

    % Median filtered data
    xMed = medfilt1(x, 3);

    % Average filtered data
    b = ones(1,3)/3;
    xFilt = filter(b,1,x);

    % Plot the data
    plot(xFilt(2:end), 'g', 'LineWidth', 2); % shift to compensate delay
    hold on
    plot(x, '-.o', 'LineWidth', 2)
    plot(xMed, 'r', 'LineWidth', 2)
    legend('Average', 'Rawdata', 'Median')
\end{lstlisting}

\clearpage

\section{Filtering images (2-D filtering)}\index{filter!2-dimensional}

\subsection{Representation of Grayscale Images}

The simplest image-type is grayscale\index{image!grayscale} images: there each pixel is given a gray-level

\begin{equation*}
  0 < gray\_level < g_{max}
\end{equation*}

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{../Images/ImageRepresentation_Grayscale.png}\\
  \caption{Example,  with $0 < gray\_levels < 255$. I have used the Matlab command \emph{imtool} to obtain these images.}
\end{figure}

Here it is up to you which maximum level is used. For many images, 8-bit is sufficient, giving you $2^8 = 256$ gray levels. Note that a higher image depth only makes sense if your sensing devices can show differences at a higher level!
Also keep in mind that Matlab uses – by default – double precision values with 64 bit. This requires 8 times as much memory, and is ok for small images. For larger images you should stick to the format with the lower memory requirements, and use the appropriate functions of the Matlab \emph{Image Processing Toolbox}.

\subsection{Color images}\index{image!color}

A color image is nothing more than a stack of three grayscale images: one representing the "red" channel, one the "green" channel, and one the "blue" channel. If the three colors are stacked in this sequence, the image is referred to as an \emph{RGB-image}\index{image!RGB}.

\begin{lstlisting}
    img = imread('peppers.png');
    size(img)
    >>> ans =
        384     512     3
\end{lstlisting}

\subsection{2D-Filtering}\index{image!filtering}

Filtering can also be performed on two-dimensional signals, like images. Instead of a one-dimensional input and a weight vector, we now have a two-dimensional input, and a weight matrix (Fig. \ref{fig:imageFiltering}). The output is still obtained by summing up the weighted input.

\begin{figure}[ht]
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{../Images/Filter_2D_Principle.png}\\
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{../Images/Morphological_ImProc.jpg}\\
        \end{subfigure}%
                \caption{Left) A two-dimensional filter applied to a two-dimensional window. Right) Definition of "Structural Element". Note that a structural element does not have to be a square; it can also be a circle, a rectangle, etc. }\label{fig:imageFiltering}
\end{figure}

\begin{equation}
  y(n,m) = \sum\limits_{i = 1}^k {} \sum\limits_{j = 1}^l {{w_{ij}}*x(n - 1 + i,m - 1 + j)}
\end{equation}

The moving window interpretation still holds, except now, the window extends in both dimensions.

If the image is a grayscale image, you could use the command \emph{filter2}. However, it is recommendable to stick with the functions of the \emph{Matlab Image Processing Toolbox}; in this case, \emph{imfilter} would be the corresponding command.
Using commands from the image processing toolbox has two advantages: where possible, it does not convert the data to a larger format (i.e., 8-bit unsigned integers are not converted to double); and it also works on RGB data (where \emph{filter2} would not work).
For example, in order to blur an image, enhance horizontal lines, or enhance vertical lines, you can use the following lines of code:

\begin{lstlisting}
    % Get the data
    data = imread('pout.tif');

    % Design the filters
    Filter1 = ones(7)/7^2;
    Filter2 = [1 1 1; 0 0 0; -1 -1 -1];
    Filter3 = Filter2';

    % Apply the filters (the "*4" is only to enhance the visibility)
    subplot(221), imshow(data);
    subplot(222), imshow(imfilter(data, Filter1));
    subplot(223), imshow(imfilter(data, Filter2)*4);
    subplot(224), imshow(imfilter(data, Filter3)*4);
\end{lstlisting}

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{../Images/pout4.jpg}\\
  \caption{Original image (top-left), blurred version (top-right), horizontal edges enhanced (bottom-left), and vertical edges enhanced (bottom-right)}
\end{figure}

\textbf{Tip:} Before you create your own filter, first check if the Matlab command \emph{fspecial} already provides the filter that you need.


\clearpage

\section{The Next Level}

Curve smoothing is a huge topic, and depending on the requirements, a number of solutions are available. For example you may have data sampled at equal intervals, or you may have recorded them randomly. In the former case, you can use Savitzky-Golay filters or IIR-filters. In the latter case you need other approaches. Some of them are listed below.

\subsection{Lowess and Loess Smoothing}\index{lowess}\index{loess}\index{smoothing!lowess}\index{smoothing!loess}

When you have irregularly sampled data points, you cannot apply a Savitzky-Golay filter.
LOESS (which can be interpreted as \emph{LOcal regrESSion}, and LOWESS (\emph{LOcally WEighted Scatterplot Smoothing}) are two strongly related non-parametric regression methods that combine multiple regression models in a k-nearest-neighbor-based meta-model. \emph{loess} is a later generalization of \emph{lowess}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{../Images/loess.jpg}\\
  \caption{LOWESS and LOESS smoothing of noisy data.}\label{fig:loess}
\end{figure}

In short, you specify the percentage of the data that you want to include. For these data, a weighted linear regression is applied. The traditional weight function used for LOESS is the tri-cube weight function,

\begin{equation}
  w(x) = (1 - |x|^3)^3 \operatorname{I}_{\left[\left| x\right| < 1\right]}
\end{equation}

$\operatorname{I}_{...}$ is the \emph{indicator function}, indicating the range over which the function is different from 0.

The methods are just differentiated by the model used in the regression: \emph{lowess} uses a linear polynomial, while \emph{loess} uses a quadratic polynomial. An example of lowess and loess smoothing is shown in Fig.\ref{fig:loess}.

\begin{lstlisting}
    % Generate the data
    x = 0:0.1:10;
    y = sin(x)+0.2*randn(size(x));

    % Eliminate some, so that we don't have equal sampling distances
    curInd = (x>5) & (x<6);
    x(curInd) = [];
    y(curInd) = [];

    % Smooth the data
    sm_lowess = smooth(x,y, 0.1, 'lowess');
    sm_loess = smooth(x,y, 0.1, 'loess');

    % Show the results
    close
    plot(x,y,'*')
    hold on
    lh(1) = plot(x, sm_lowess, 'r');
    set(lh(1), 'LineWidth', 3);
    lh(2) = plot(x,sm_loess, 'g--');
    set(lh(2), 'LineWidth', 3);
    legend('raw data', 'lowess', 'loess');
    shg
\end{lstlisting}

\subsection{Splines}\index{Splines}

The interpolation methods described on page \pageref{sec:interpolation} all go through the given data points. But this feature is not always required, and so-called \emph{splines} can be used not only for interpolation, but also for data smoothing and differentiation.

The ideas of splines have their roots in the aircraft and shipbuilding industries. For example, the British aircraft industry during World War II used to construct templates for airplanes by passing thin wooden strips (called "splines") through points laid out on the floor of a large design loft, a technique borrowed from ship-hull design (Fig. \ref{fig:Spline}). In the late 1950s and 60s, the computational use of splines was developed for modeling automobile bodies.
In the computer science subfields of computer-aided design and computer graphics, splines are popular because of the simplicity of their construction, their ease and accuracy of evaluation, and their capacity to approximate complex shapes through curve fitting and interactive curve design.

A \emph{spline}-function is nowadays defined as a \emph{piecewise polynomial function }of degree $<k$ in a variable $x$.


\begin{figure}[ht]
  \centering
  \includegraphics[width=0.25\textwidth]{../Images/Spline.png}\\
  \caption{A wooden spline.  (From the archives of Pearson Scott Foresman, donated to the Wikimedia Foundation)}\label{fig:Spline}
\end{figure}


\subsubsection{B-Splines}\index{B-splines}

One particularly simple and powerful option to construct smooth, piecewise polynomial 2-D and 3-D trajectories are so-called ``B-splines''. The term \emph{B-splines} stands for \emph{basis splines}, since any spline function of given degree can be expressed as a linear combination of B-splines of that degree.

For a given trajectory, the \emph{spline-knots} separate the piecewise polynomial parts ot the trajectory. If the knots are equidistant, the spline is called \emph{cardinal B-spline}, and the definition of B-splines then becomes remarkably simple:

With a B-spline of degree $p$ ($p \in \mathbb{N}_0$), the convolution operator $*$, and the indicator function $\mathbf{b^0} = \mathbf{1}_{[0,1)}$ of the half-open unit interval $[0,1)$ , the corresponding cardinal B-splines is given by

\begin{equation}\label{eq:defBSpline}
  \mathbf{b^p} := \underbrace{\mathbf{1}_{[0,1)} * ... * \mathbf{1}_{[0,1)}}_{p+1 - times}
\end{equation}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{../Images/BSplines.jpg}\\
  \caption{The first four B-splines}\label{fig:bsplines}
\end{figure}

Note that B-splines have what is called \emph{minimal support}: linear B-splines only have an effect over two adjacent knots, quadratic B-splines over three knots, etc.

A B-spline curve $ C(u),\ u\in [\tau_{p},\tau_{n-p-1}[$ of grade $p$ with knot vector $\tau$ and control points $P_i\ (i=0,\ldots,n-p-2)$ (also called ''De-Boor-points'') is given by

\begin{equation}\label{eq:bsplineCurve}
  C(u) = \sum_{i=0}^{n-p-2}\; P_i\,N_{i,p,\tau}(u)
\end{equation}

In one dimension, the construction of a linear spline by three control points can be easily visualized:

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{../Images/explain_bspline.jpg}\\
  \caption{Explanation of B-spline curves. This example shows three control points, and the three corresponding linear B-splines. Multiplying each point with the corresponding (dotted) B-spline, and summing up the results, gives the solid line. Note that each point only contributes to a limited interval of the total curve.}\label{fig:bsplines}
\end{figure}


\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{../Images/bspline.jpg}\\
  \caption{B-spline with control points/control polygon, and marked component curves.}\label{fig:Bspline}
\end{figure}

A different formulation, which also works for knots that are \emph{not} equidistant, as been given by DeBoor. That formulation involves recursive equations, and is implemented in the file:

\MatImg "deboor.m" (p \pageref{mat:deboor}) Code to generate B-splines. That file is use by "bspline.m" (p \pageref{mat:deboor}) to generate the 2-D cubic B-spline in Fig. \ref{fig:Bspline}. (Confusingly, a B-spline of \emph{order n} contains \emph{polynomials of degree n-1!}

\subsection{Kernel Density Estimation}\index{kernel density estimation}

Another type of smoothing can be needed when you want to know the \emph{frequency} \index{frequency} of events. Such information is often displayed with histograms \index{histogram}. However, it is possible to smooth histogram data systematically, with a technique called \emph{Kernel Density Estimation (KDE)}.

For example, your friends, the \emph{Birdlife Austria}, give you a list with the observations of bearded vultures ("Laemmergeier"), and ask you to represent this as a smooth curve. You could do this, by representing every observation by a Gaussian function

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{../Images/kde.jpg}\\
  \caption{\textbf{Kernel Density Estimation: }The "*" on the x-axis indicate individual events, and the thin blue lines the corresponding Gaussians. The thick red line is the sum of the thin blue lines, and provides a "density estimate" for the event rate.}
\end{figure}

\begin{equation}\label{eq:Gauss}
    g(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{ -\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2 }.
\end{equation}

and then sum all the resulting functions.

\begin{lstlisting}
    % Define the smoothness and the Gaussian functions
    sigma = 1;  % bandwidth
    gauss = @(x,mu) 1/(sigma*sqrt(2*pi))*exp(-0.5*((x-mu)/sigma).^2)

    % Define the input and output parameters
    x = -10:0.1:10;
    mu = [-5, -3, 2, 3,3.5, 4, 6]
    total = zeros(size(x));

    % Calculate and plot the individual exponentials, and the sum total
    hold on
    set(gca, 'XTickMode', 'manual', ...
        'XTick',[]);
    for ii = 1:length(mu)
        out = gauss(x, mu(ii));
        plot(x, out)
        total = total + out;
    end
    lh(1) = plot(mu, zeros(size(mu)), '*');
    set(lh(1), 'MarkerSize', 10);
    lh(2) = plot(x, total, 'r');
    set(lh(2), 'LineWidth', 2);

    xlabel('X');
    ylabel('Y');
    hold off
    shg
\end{lstlisting}

\clearpage

\subsection{Morphological Operations in Image Processing}\index{filter!morphological}

\subsubsection{Erosion and Dilation of Images}\index{image!erosion}\index{image!dilation}

For linear filters as seen before, it holds that they are commutative. Cite from wikipedia: \emph{One says that x commutes with y under "*" if:}

\begin{equation}\label{eq:commutativity}
  x * y = y * x
\end{equation}


In other words, it does not matter how many and in which sequence different linear filters you use. E.g. if a Savitzky-Golay filter is applied to some date, and then a second Savitzky-Golay filter for calculating the first derivative, the result is the same if the sequence of filters is reversed. It even holds, that there would have been one filter, which does the same as the two applied.

In contrast \emph{morphological operations} on an image are non-linear operations and the final result depends on the sequence. If we think of any image, it is defined by pixels with values $x_{ij}$. Further this image is assumed to be a black-and-white image, so we have

\begin{equation}
    x_{ij}= 0\;or\;1, \forall i,j
\end{equation}

To define a morphological operation we have to set a \emph{structural element SE}\index{structural element}. As example, a 3x3-Matrix as a part of the image.

The definition of \emph{erosion}\index{morphological operations!erosion} E says:

\begin{equation}\label{eq:erosion}
    E(M) = \left\{ {\begin{array}{*{20}{l}}
    {0,}&{if\sum\limits_{i,j = 0}^3 {{{(se)}_{ij}} < 9} } \\
    {1,}&{else}
    \end{array}} \right.\,,\,\,with\,{(se)_{ij}},\,M \in \,SE
\end{equation}

So in words, if any of the pixels in the structural element M has value 0, the erosion sets the value of M, a specific pixel in M, to zero. Otherwise E(M)=1.

And for the \emph{dilation}\index{morphological operations!dilation} D it holds, if any value in SE is 1, the dilation of M, D(M), is set to 1.

\begin{equation}\label{eq:dilation}
    D(M) = \left\{ {\begin{array}{*{20}{l}}
    {1,}&{if\sum\limits_{i,j = 0}^3 {{{(se)}_{ij}} >= 9} } \\
    {0,}&{else}
    \end{array}} \right.\,,\,\,with\,{(se)_{ij}},\,M \in \,SE
\end{equation}

\subsubsection{Opening and Closing of Images}\index{image!opening}\index{image!closing}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.3\textwidth]{../Images/Square.jpg}\\
  \caption{Sample image for demonstrating the effect of "opening" and "closing" of binary images.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.9\textwidth]{../Images/Square_Morphological.jpg}\\
  \caption{Compositions of Dilation and Erosion: Opening and Closing of Images.}
  \label{fig:morphological}
\end{figure}

There are two compositions of dilation and erosion. One called opening the other called closing. It holds:

\begin{equation}
    \begin{array}{*{20}{l}}
        opening &= dilation \circ erosion \\
        closing &= erosion \circ dilation
    \end{array}
\end{equation}

\MatImg "ShowMorph.m" (p \pageref{mat:ShowMorph}) gives the Matlab code that generates Fig. \ref{fig:morphological}.

\clearpage

\section{Exercises}

\begin{itemize}
  \item (As in the Exercise in the previous chapter:) Create a noisy sine wave, with an amplitude of 1, a frequency of 0.3 Hz, a sampling rate of 100 Hz, a duration of 10 sec, and a Gaussian random noise with a standard deviation of 0.5.

  \item Using a Savitzky Golay filter, calculate the first derivative using a $2^{nd}$ order polynomial. Try different window sizes, and superpose the results in a plot. Make sure that the axes of the plot are correctly labelled.

  \item Generate a dummy dataset consisting of the sum of three sine-waves, with frequencies of \emph{[2, 30, 400] Hz}, and amplitudes of \emph{[0.5, 1, 0.1]}. The signal should have a sampling rate of \emph{5 kHz}, and a duration of \emph{2 sec}. Now generate a \emph{Butterworth low-pass filter}, for the frequency band between \emph{10 Hz} and \emph{100 Hz}. When you apply that filter to your data, you should obtain a pure sine-wave with \emph{30 Hz}.

  \item Apply the \emph{exponential averaging filter} to a step-input. Plot the response for different values of $\alpha$, to show why this filter is in some fields referred to as \emph{leaky integrator}.
\end{itemize}
