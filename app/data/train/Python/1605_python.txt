import novaclient
from novaclient.exceptions import NotFound
import novaclient.client
from keystoneauth1 import loading
from keystoneauth1 import session

import neutronclient.v2_0.client
import cinderclient.v2.client

from osc_lib.utils import wait_for_delete

import taskflow.engines
from taskflow.patterns import linear_flow as lf
from taskflow.patterns import graph_flow as gf
from taskflow import task

import logging
import os
import json
import time

NOVACLIENT_VERSION = "2.37"


def get_openstack_nova_client(config):
    return get_openstack_clients(config)[0]


def get_openstack_neutron_client(config):
    return get_openstack_clients(config)[1]


def get_openstack_cinder_client(config):
    return get_openstack_clients(config)[2]


def get_openstack_clients(config):
    """ gets a tuple of various openstack clients.
        (novaclient, neutronclient, cinderclient).
        Caller can pick up one or all of the returned clients.
    """
    if config:
        if config.get('M2M_CREDENTIAL_STORE'):
            logging.debug("loading credentials from %s" % config.get('M2M_CREDENTIAL_STORE'))
            m2m_config = json.load(open(config.get('M2M_CREDENTIAL_STORE')))
            source_config = m2m_config
        else:
            logging.debug("using config as provided")
            source_config = config
    else:
        logging.debug("no config, trying environment vars")
        source_config = os.environ
    os_username = source_config['OS_USERNAME']
    os_password = source_config['OS_PASSWORD']
    os_tenant_name = source_config['OS_TENANT_NAME']
    os_auth_url = source_config['OS_AUTH_URL']

    loader = loading.get_plugin_loader('password')
    auth = loader.load_from_options(auth_url=os_auth_url,
                                    username=os_username,
                                    password=os_password,
                                    project_name=os_tenant_name
                                    )
    sess = session.Session(auth=auth, verify=False)

    return (novaclient.client.Client(NOVACLIENT_VERSION,
                                     session=sess),
            neutronclient.v2_0.client.Client(session=sess),
            cinderclient.v2.client.Client(NOVACLIENT_VERSION, session=sess)
            )


def _format_nics(nics):
    """ Create a networks data structure for python-novaclient.


    **Note** "auto" is the safest default to pass to novaclient

    :param nics: either None, one of strings "auto" or "none"or string with a
    comma-separated list of nic IDs from OpenStack.
    :return: A data structure that can be passed as Nics
    """
    if not nics:
        return "auto"
    if nics == "none":
        return "none"
    if nics.lower() == "auto":
        return "auto"
    return [{"net-id": item, "v4-fixed-ip": ""}
            for item in nics.strip().split(",")]


class GetServer(task.Task):
    def execute(self, server_id, config):
        logging.debug("getting server %s" % server_id)
        nc = get_openstack_nova_client(config)
        return nc.servers.get(server_id)


class GetImage(task.Task):
    def execute(self, image_name, config):
        logging.debug("getting image %s" % image_name)
        nc = get_openstack_nova_client(config)
        return nc.glance.find_image(image_name)

    def revert(self, *args, **kwargs):
        pass


class ListImages(task.Task):
    def execute(self, image_name, config):
        logging.debug("getting images")
        nc = get_openstack_nova_client(config)
        return nc.glance.list()

    def revert(self, *args, **kwargs):
        pass


class GetFlavor(task.Task):
    def execute(self, flavor_name, config):
        logging.debug("getting flavor %s" % flavor_name)
        nc = get_openstack_nova_client(config)
        return nc.flavors.find(name=flavor_name)

    def revert(self, *args, **kwargs):
        pass


class ListFlavors(task.Task):
    def execute(self, flavor_name, config):
        logging.debug("getting flavors")
        nc = get_openstack_nova_client(config)
        return nc.flavors.list()

    def revert(self, *args, **kwargs):
        pass


class CreateSecurityGroup(task.Task):
    # note this uses neutron client
    secgroup_id = ""

    def execute(self, display_name, master_sg_name, config):
        logging.debug("create security group %s" % display_name)
        security_group_name = display_name
        nc = get_openstack_neutron_client(config)

        self.secgroup = nc.create_security_group({"security_group": {
            "name": security_group_name,
            "description": "Security group generated by Pebbles"
        }})

        self.secgroup_id = self.secgroup["security_group"]["id"]
        self.secgroup_name = self.secgroup["security_group"]["name"]
        if master_sg_name:
            master_sg = nc.find_resource("security_group", master_sg_name)
            nc.create_security_group_rule({"security_group_rule": dict(
                security_group_id=self.secgroup_id,
                protocol='tcp',
                ethertype='ipv4',
                port_range_min=1,
                direction='ingress',
                port_range_max=65535,
                remote_group_id=master_sg["id"]
            )})
            nc.create_security_group_rule({"security_group_rule": dict(
                security_group_id=self.secgroup_id,
                protocol='udp',
                ethertype='ipv4',
                port_range_min=1,
                direction='ingress',
                port_range_max=65535,
                remote_group_id=master_sg["id"]
            )})
            nc.create_security_group_rule({"security_group_rule": dict(
                security_group_id=self.secgroup_id,
                protocol='icmp',
                ethertype='ipv4',
                port_range_min=1,
                direction='ingress',
                port_range_max=255,
                remote_group_id=master_sg["id"]
            )})

        logging.info("Created security group %s" % self.secgroup_id)

        return self.secgroup_id

    def revert(self, config, **kwargs):
        logging.debug("revert: delete security group")
        nc = get_openstack_neutron_client(config)
        nc.delete_security_group(self.secgroup_id)


class CreateRootVolume(task.Task):
    def execute(self, display_name, image, root_volume_size, config):
        if root_volume_size:
            logging.debug("creating a root volume for instance %s from image %s" % (display_name, image))
            nc = get_openstack_cinder_client(config)
            volume_name = '%s-root' % display_name

            volume = nc.volumes.create(
                size=root_volume_size,
                imageRef=image.id,
                name=volume_name
            )
            self.volume_id = volume.id
            retries = 0
            while nc.volumes.get(volume.id).status not in ('available',):
                logging.debug("...waiting for volume to be ready")
                time.sleep(5)
                retries += 1
                if retries > 30:
                    raise RuntimeError('Volume creation %s is stuck')

            return volume.id
        else:
            logging.debug("no root volume defined")
            return ""

    def revert(self, config, **kwargs):
        logging.debug("revert: delete root volume")

        try:
            if getattr(self, 'volume_id', None):
                nc = get_openstack_cinder_client(config)
                nc.volumes.delete(
                    nc.volumes.get(self.volume_id))
            else:
                logging.debug("revert: no volume_id stored, unable to revert")
        except Exception as e:
            logging.error('revert: deleting volume failed: %s' % e)


class CreateDataVolume(task.Task):
    def execute(self, display_name, data_volume_size, data_volume_type, config):
        if data_volume_size:
            logging.debug("creating a data volume for instance %s, %d" % (display_name, data_volume_size))
            nc = get_openstack_cinder_client(config)
            volume_name = '%s-data' % display_name

            volume = nc.volumes.create(
                size=data_volume_size,
                name=volume_name,
                volume_type=data_volume_type,
            )
            self.volume_id = volume.id
            retries = 0
            while nc.volumes.get(volume.id).status not in ('available',):
                logging.debug("...waiting for volume to be ready")
                time.sleep(5)
                retries += 1
                if retries > 30:
                    raise RuntimeError('Volume creation %s is stuck')

            return volume.id
        else:
            logging.debug("no root volume defined")
            return None

    def revert(self, config, **kwargs):
        logging.debug("revert: delete root volume")

        try:
            if getattr(self, 'volume_id', None):
                nc = get_openstack_cinder_client(config)
                nc.volumes.delete(
                    nc.volumes.get(self.volume_id))
            else:
                logging.debug("revert: no volume_id stored, unable to revert")
        except Exception as e:
            logging.error('revert: deleting volume failed: %s' % e)


class ProvisionInstance(task.Task):
    def execute(self, display_name, image, flavor, security_group, extra_sec_groups,
                root_volume_id, nics, userdata, config):
        logging.debug("provisioning instance %s" % display_name)
        nc = get_openstack_nova_client(config)
        sgs = [security_group]
        if extra_sec_groups:
            sgs.extend(extra_sec_groups)
        try:
            if len(root_volume_id):
                bdm = {'vda': '%s:::1' % (root_volume_id)}
            else:
                bdm = None
            instance = nc.servers.create(
                display_name,
                image.id,
                flavor.id,
                key_name=display_name,
                security_groups=sgs,
                block_device_mapping=bdm,
                nics=_format_nics(nics),
                userdata=userdata,)

        except Exception as e:
            logging.error("error provisioning instance: %s" % e)
            raise e

        self.instance_id = instance.id
        logging.debug("instance provisioning successful")
        return instance.id

    def revert(self, config, **kwargs):
        logging.debug("revert: deleting instance %s", kwargs)
        try:
            if getattr(self, 'instance_id', None):
                nc = get_openstack_nova_client(config)
                nc.servers.delete(self.instance_id)
            else:
                logging.debug("revert: no instance_id stored, unable to revert")
        except Exception as e:
            logging.error('revert: deleting instance failed: %s' % e)


class DeprovisionInstance(task.Task):
    def execute(self, server_id, config):
        logging.debug("deprovisioning instance %s" % server_id)
        nc = get_openstack_nova_client(config)
        try:
            server = nc.servers.get(server_id)
        except NotFound:
            logging.warn("Server %s not found" % server_id)
            return
        if hasattr(server, "security_groups"):
            for sg in server.security_groups:
                try:
                    server.remove_security_group(sg['name'])
                except:
                    logging.warn("Unable to remove security group from server (%s)" % sg)
        else:
            logging.warn("no security groups on server!")
        try:
            nc.servers.delete(server_id)
            wait_for_delete(nc.servers, server_id)
        except Exception as e:
            logging.warn("Unable to deprovision server %s" % e)
        return server.name

    def revert(self, *args, **kwargs):
        logging.debug("revert: deprovisioning instance failed")


class AllocateIPForInstance(task.Task):
    # user beware, i have not done comprehensive testing on this
    # but the parts of the refactoring should be correct
    # suvileht -2017-08-24
    def execute(self, server_id, allocate_public_ip, config):
        logging.info("Allocate IP for server %s" % server_id)

        novaclient = get_openstack_nova_client(config)
        neutronclient = get_openstack_neutron_client(config)

        retries = 0
        while novaclient.servers.get(server_id).status is "BUILDING" or not novaclient.servers.get(server_id).networks:
            logging.debug("...waiting for server to be ready")
            time.sleep(5)
            retries += 1
            if retries > 30:
                raise RuntimeError('Server %s is stuck in building' % server_id)

        server = novaclient.servers.get(server_id)
        if allocate_public_ip:

            ips = neutronclient.list_floatingips()
            allocated_from_pool = False
            free_ips = [ip for ip in ips["floatingips"] if ip["status"] != "ACTIVE"]
            if not free_ips:
                logging.debug("No allocated free IPs left, trying to allocate one")
                try:
                    # for backwards compatibility reasons we assume the
                    # network is called "public"
                    network_id = neutronclient.find_resource("network",
                                                             "public")
                    ip = neutronclient.create_floatingip({
                        "floating_network_id": network_id})
                    allocated_from_pool = True
                except neutronclient.exceptions.ClientException as e:
                    logging.warning("Cannot allocate IP, quota exceeded?")
                    raise e
            else:
                ip = free_ips[0]["floating_ip_address"]
                logging.info("IP assigned IS %s" % ip)
            try:
                server.add_floating_ip(ip)
            except Exception as e:
                logging.error(e)

            address_data = {
                'public_ip': ip,
                'allocated_from_pool': allocated_from_pool,
                'private_ip': list(server.networks.values())[0][0],
            }
        else:
            address_data = {
                'public_ip': None,
                'allocated_from_pool': False,
                'private_ip': list(server.networks.values())[0][0],
            }

        return address_data

    def revert(self, *args, **kwargs):
        pass


class ListInstanceVolumes(task.Task):
    def execute(self, server_id, config):
        nc = get_openstack_nova_client(config)
        return nc.volumes.get_server_volumes(server_id)

    def revert(self):
        pass


class AttachDataVolume(task.Task):
    def execute(self, server_id, data_volume_id, config):
        logging.debug("Attach data volume for server %s" % server_id)

        if data_volume_id:
            nc = get_openstack_nova_client(config)
            retries = 0

            while nc.servers.get(server_id).status is "BUILDING" or not nc.servers.get(server_id).networks:
                logging.debug("...waiting for server to be ready")
                time.sleep(5)
                retries += 1
                if retries > 30:
                    raise RuntimeError('Server %s is stuck in building' % server_id)

            nc.volumes.create_server_volume(server_id, data_volume_id, '/dev/vdc')

    def revert(self, *args, **kwargs):
        pass


class AddUserPublicKey(task.Task):
    def execute(self, display_name, public_key, config):
        logging.debug("adding user public key")
        nc = get_openstack_nova_client(config)
        self.keypair_added = False
        nc.keypairs.create(display_name, public_key)
        self.keypair_added = True

    def revert(self, display_name, public_key, config, **kwargs):
        logging.debug("revert: remove user public key")
        if getattr(self, 'keypair_added', None):
            nc = get_openstack_nova_client(config)
            nc.keypairs.find(name=display_name).delete()


class RemoveUserPublicKey(task.Task):
    def execute(self, display_name, config):
        logging.debug("removing user public key")
        nc = get_openstack_nova_client(config)
        try:
            nc.keypairs.find(name=display_name).delete()
        except:
            pass

    def revert(self, *args, **kwargs):
        pass


class DeleteSecurityGroup(task.Task):
    def execute(self, server, config):
        logging.debug("delete security group")
        nc = get_openstack_neutron_client(config)
        security_group = nc.find_resource("security_group",
                                          server.name)
        try:
            if security_group:
                nc.delete_security_group(security_group["id"])
        except Exception as e:
            logging.warn("Could not delete security group: %s" % e)

    def revert(self, *args, **kwargs):
        pass


class DeleteVolumes(task.Task):
    def execute(self, server, config):
        nova = get_openstack_nova_client(config)
        cinder = get_openstack_cinder_client(config)
        for volume in nova.volumes.get_server_volumes(server.id):
            retries = 0
            while cinder.volumes.get(volume.id).status not in \
                    ('available', 'error'):
                logging.debug("...waiting for volume to be ready")
                time.sleep(5)
                retries += 1
                if retries > 30:
                    raise RuntimeError('Volume %s is stuck' % volume.id)

            try:
                cinder.volumes.delete(volume.id)
            except NotFound:
                pass

    def revert(self, *args, **kwargs):
        pass


def get_provision_flow():
    """
    Provisioning flow consisting of three graph flows, each consisting of set of
    tasks that can execute in parallel.

    Returns tuple consisting of the whole flow and a dictionary including
    references to three graph flows for pre-execution customisations.
    """
    pre_flow = gf.Flow('PreBootInstance').add(
        AddUserPublicKey('add_user_public_key'),
        GetImage('get_image', provides='image'),
        GetFlavor('get_flavor', provides='flavor'),
        CreateRootVolume('create_root_volume', provides='root_volume_id')
    )
    main_flow = gf.Flow('BootInstance').add(
        CreateSecurityGroup('create_security_group', provides='security_group'),
        CreateDataVolume('create_data_volume', provides='data_volume_id'),
        ProvisionInstance('provision_instance', provides='server_id')
    )
    post_flow = gf.Flow('PostBootInstance').add(
        AllocateIPForInstance('allocate_ip_for_instance', provides='address_data'),
        AttachDataVolume('attach_data_volume'),
        RemoveUserPublicKey('remove_user_public_key')
    )
    return (lf.Flow('ProvisionInstance').add(pre_flow, main_flow, post_flow),
            {'pre': pre_flow, 'main': main_flow, 'post': post_flow})


def get_deprovision_flow():
    pre_flow = gf.Flow('PreDestroyInstance').add(
        GetServer('get_server', provides="server")
    )
    main_flow = gf.Flow('DestroyInstance').add(
        DeprovisionInstance('deprovision_instance')
    )
    post_flow = gf.Flow('PostDestroyInstance').add(
        DeleteSecurityGroup('delete_security_group')
    )

    return (lf.Flow('DeprovisionInstance').add(pre_flow, main_flow, post_flow),
            {'pre': pre_flow, 'main': main_flow, 'post': post_flow})


def get_upload_key_flow():
    return lf.Flow('UploadKey').add(
        AddUserPublicKey('upload_key')
    )


class OpenStackService(object):
    def __init__(self, config=None):
        self._config = config

    def provision_instance(self, display_name, image_name, flavor_name, public_key, extra_sec_groups=None,
                           master_sg_name=None, allocate_public_ip=True, root_volume_size=0,
                           data_volume_size=0, data_volume_type=None,
                           nics=None,
                           userdata=None):
        try:
            flow, _ = get_provision_flow()
            return taskflow.engines.run(flow, engine='parallel', store=dict(
                image_name=image_name,
                flavor_name=flavor_name,
                display_name=display_name,
                master_sg_name=master_sg_name,
                public_key=public_key,
                extra_sec_groups=extra_sec_groups,
                allocate_public_ip=allocate_public_ip,
                root_volume_size=root_volume_size,
                data_volume_size=data_volume_size,
                data_volume_type=data_volume_type,
                nics=nics,
                userdata=userdata,
                config=self._config))
        except Exception as e:
            logging.error(e)
            return {'error': 'flow failed due to: %s' % e}

    def deprovision_instance(self, server_id, display_name=None, delete_attached_volumes=False):
        flow, subflows = get_deprovision_flow()
        if delete_attached_volumes:
            subflows['main'].add(DeleteVolumes())

        try:
            return taskflow.engines.run(flow, engine='parallel', store=dict(
                server_id=server_id,
                config=self._config))
        except Exception as e:
            logging.error(e)
            return {'error': 'flow failed due to: %s' % (e)}

    def get_instance_state(self, instance_id):
        nc = get_openstack_nova_client(self._config)
        return nc.servers.get(instance_id).status

    def get_instance_networks(self, instance_id):
        nc = get_openstack_nova_client(self._config)
        return nc.servers.get(instance_id).networks

    def list_images(self):
        nc = get_openstack_nova_client(self._config)
        return nc.glance.list()

    def list_flavors(self):
        nc = get_openstack_nova_client(self._config)
        return nc.flavors.list()

    def upload_key(self, key_name, public_key):
        try:
            return taskflow.engines.run(
                get_upload_key_flow(),
                engine='parallel',
                store=dict(
                    config=self._config,
                    display_name=key_name,
                    public_key=public_key
                )
            )
        except Exception as e:
            logging.error(e)
            return {'error': 'flow failed'}

    def delete_key(self, key_name):
        logging.debug('Deleting key: %s' % key_name)
        nc = get_openstack_nova_client(self._config)
        try:
            key = nc.keypairs.find(name=key_name)
            key.delete()
        except:
            logging.warning('Key not found: %s' % key_name)

    def clear_security_group_rules(self, group_id):
        nc = get_openstack_neutron_client(self._config)
        sg = nc.show_security_group(group_id)
        sec_group_rules = sg['security_group']['security_group_rules']
        for rule in sec_group_rules:
            if rule['direction'] == 'ingress':
                nc.delete_security_group_rule(rule['id'])

    def create_security_group(self, security_group_name, security_group_description):
        nc = get_openstack_neutron_client(self._config)
        nc.security_groups.create(
            security_group_name,
            "Security group generated by Pebbles")

    def create_security_group_rule(self, security_group_id, from_port, to_port, cidr, ip_protocol='tcp',
                                   group_id=None):
        nc = get_openstack_neutron_client(self._config)
        nc.create_security_group_rule({"security_group_rule": dict(
            security_group_id=security_group_id,
            protocol=ip_protocol,
            ethertype='ipv4',
            port_range_min=from_port,
            direction='ingress',
            port_range_max=to_port,
            remote_ip_prefix=cidr,
            remote_group_id=group_id
        )})
