use scanner::tokenize;
use scanner::tokens::Token;
use scanner::tokens::Token::*;

#[test]
fn scan_terminals() {
    let expected = vec![Lparen, Rparen, Dot];
    let actual = tokenize("().");

    assert_eq!(expected, actual);
}

#[test]
fn scan_base_command() {
    let expected: Vec<Token> = vec![
        Base, 
        Ident("name".to_string()), 
        Lparen, 
        Ident("A50".to_string()), 
        Rparen, 
        Dot];
    let actual = tokenize("base name (A50).");

    assert_eq!(expected, actual);
}

#[test]
fn scan_end_command() {
    let expected = vec![End, Dot];
    let actual = tokenize("end.");

    assert_eq!(expected, actual);
}

#[test]
fn scan_unicode_ident() {
    // todo: add some unicode characters to the test
    let expected = vec![Lparen, Ident("abc1231".to_string()), Rparen];
    let actual = tokenize("(abc1231)");

    assert_eq!(expected, actual);
}

#[test]
fn scan_keywords() {
    let expected = vec![Database, Base, Type, End];
    let actual = tokenize("database base type end");

    assert_eq!(expected, actual);
}

