
extern crate vect;
extern crate argparse;
use vect::termcounts;
use vect::ingestion;
use vect::dictionary::Dictionary;
use argparse::{ArgumentParser, Store};
use vect::huffman;
use vect::base::split_words;
use std::io;

// This is labeled public to shut up the linter about dead code
pub fn main() {
    let mut input_filename = "word2vec_input".to_string();
    let mut output_filename = "word2vec_termcounts".to_string();
    {  // Limit the scope of ap.refer()
        let mut ap = ArgumentParser::new();
        ap.set_description("Create vanilla word2vec vectors for a given dataset.");
        ap.refer(&mut input_filename)
            .add_argument("input_filename", Store,
            "Input corpus, formatted one document per line");
        ap.refer(&mut output_filename)
            .add_argument("output", Store,
            "Output term count table");
        ap.parse_args_or_exit();
    }
    let input_file = ingestion::ingest_lines(&input_filename).ok()
        .expect("Failed to load input file. Is it missing?");
	let counts = termcounts::count_terms(1, input_file).ok()
        .expect("Problems while reading the input file.");

    let tree = huffman::create_huffman_tree(&counts);
	termcounts::export_dictionary(&counts, &output_filename);
    let mut dictionary = Dictionary::new(&counts);
    train(&mut dictionary, &input_filename);
	//println!("Huffman Tree: {:?}", huffman::create_huffman_tree(&term_counts));
}

fn train(dictionary: &mut Dictionary, input_filename: &str) -> io::Result<()> {
    for line in try!(ingestion::ingest_lines(&input_filename)) {
        let line = try!(line);
        let words = split_words(&line);
        for i in 0..words.len()-1 {
            dictionary.update_both(&words[i], &words[i+1]);
        }
    }
    Ok(())
}
