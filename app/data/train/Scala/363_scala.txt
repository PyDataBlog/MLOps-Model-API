package uk.me.arseni.tokenizers

import uk.me.arseni.filters.StopWordsFilter
import org.scalatest.FlatSpec

/**
  * @author aanisimovich
  * @since 24/03/16
  */
class TestTokenizerWithFilters extends FlatSpec {
  val t = new TokenizerWithFilters(tokenizer = new RegexBITokenizer(),
                                    filters = Array(new StopWordsFilter("/stopwords/stopwords.txt")))
  "TokenizerWithFilters" should "remove stop words" in {
    assert(t.tokenize("we do what we must because we can mustard")
      === Array("we", "do", "what", "we", "must", "because", "we", "can"))
    assert(t.tokenize("meat goes well with wine and ketchup")
      === Array("meat", "goes", "well", "with", "wine"))
  }
}
