package inputdata

import org.apache.spark.mllib.recommendation.Rating
import org.apache.spark.rdd.RDD
import recommender.startSpark



class DoubanDataHolder(dataDirectoryPath: String) extends DataHolder with Serializable {

  protected val ratings = loadRatingsFromADirectory()
  protected val productsIDsToNameMap = loadIDsToProductnameMapFromADirectory(dataDirectoryPath)


  protected def loadRatingsFromADirectory(): RDD[Rating] = {

    val ratings = startSpark.sc.textFile(dataDirectoryPath + "/hot_movies.csv").map { line =>
      val fields = line.split(",")
      // format: Rating(userID, movieID, rating)
      (Rating(fields(0).toInt, fields(1).toInt, fields(2).toDouble))
    }
    ratings
  }

  protected def loadIDsToProductnameMapFromADirectory(dataDirectoryPath: String): Map[Int, String] = {
    val movies = startSpark.sc.textFile(dataDirectoryPath + "/user_movies.csv").map { line =>
      val fields = line.split(",")
      // format: (movieID, movieName)
      (fields(0).toInt, fields(1))
    }.collect.toMap
    movies
  }
}